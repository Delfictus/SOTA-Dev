//! Integration tests for Dendritic Reservoir GPU kernel
//!
//! TESTING STRATEGY:
//! 1. Small synthetic graphs (5-50 vertices)
//! 2. Compare GPU output against CPU reference implementation (Phase0 fallback)
//! 3. Verify output ranges: difficulty and uncertainty in [0, 1]
//! 4. Check symmetric graph property: similar difficulty for similar-degree vertices
//! 5. Edge cases: isolated vertices, complete graphs, star graphs
//! 6. Performance benchmarks on DSJC250
//!
//! TEST FIXTURES:
//! - Complete graphs (K5, K10) - all vertices have equal degree
//! - Star graphs (1 hub, n-1 leaves) - hub has high difficulty
//! - Path graphs (linear chains) - ends have low difficulty
//! - Random graphs with known properties
//!
//! REFERENCE: PRISM GPU Plan ยง4.1 (Phase 0 Dendritic Reservoir Testing)

use cudarc::driver::CudaContext;
use prism_gpu::DendriticReservoirGpu;
use std::sync::Arc;

/// Tolerance for f32 floating-point comparison
const F32_TOLERANCE: f32 = 0.1; // Relaxed tolerance for neuromorphic computation

/// CPU reference implementation using simple heuristics
///
/// Matches the fallback implementation in Phase0DendriticReservoir.
fn dendritic_reservoir_cpu_reference(
    adjacency: &[Vec<usize>],
    num_vertices: usize,
) -> (Vec<f32>, Vec<f32>) {
    let mut difficulty = Vec::with_capacity(num_vertices);
    let mut uncertainty = Vec::with_capacity(num_vertices);

    // Find max degree for normalization
    let max_degree = adjacency
        .iter()
        .map(|neighbors| neighbors.len())
        .max()
        .unwrap_or(1);

    for vertex in 0..num_vertices {
        let degree = adjacency[vertex].len();

        // Difficulty: Normalized degree
        let diff = if max_degree > 0 {
            degree as f32 / max_degree as f32
        } else {
            0.0
        };
        difficulty.push(diff);

        // Uncertainty: Based on neighbor degree variance
        if degree > 0 {
            let neighbor_degrees: Vec<f32> = adjacency[vertex]
                .iter()
                .map(|&n| adjacency[n].len() as f32)
                .collect();

            let mean_neighbor_deg: f32 =
                neighbor_degrees.iter().sum::<f32>() / neighbor_degrees.len() as f32;
            let variance: f32 = neighbor_degrees
                .iter()
                .map(|&d| (d - mean_neighbor_deg).powi(2))
                .sum::<f32>()
                / neighbor_degrees.len() as f32;

            let std_dev = variance.sqrt();
            let uncert = (std_dev / max_degree as f32).min(1.0);
            uncertainty.push(uncert);
        } else {
            uncertainty.push(0.0);
        }
    }

    (difficulty, uncertainty)
}

/// Verifies metrics are in valid [0, 1] range
fn assert_metrics_valid(difficulty: &[f32], uncertainty: &[f32], num_vertices: usize) {
    assert_eq!(difficulty.len(), num_vertices, "Difficulty length mismatch");
    assert_eq!(
        uncertainty.len(),
        num_vertices,
        "Uncertainty length mismatch"
    );

    for (i, &d) in difficulty.iter().enumerate() {
        assert!(
            d >= 0.0 && d <= 1.0,
            "Difficulty[{}] = {} out of range [0, 1]",
            i,
            d
        );
    }

    for (i, &u) in uncertainty.iter().enumerate() {
        assert!(
            u >= 0.0 && u <= 1.0,
            "Uncertainty[{}] = {} out of range [0, 1]",
            i,
            u
        );
    }
}

/// Compares GPU and CPU metrics for approximate equivalence
///
/// Note: GPU reservoir uses neuromorphic dynamics, so exact match is not expected.
/// We verify correlation and general trends instead.
fn assert_metrics_correlation(
    gpu_diff: &[f32],
    cpu_diff: &[f32],
    name: &str,
    min_correlation: f32,
) {
    assert_eq!(gpu_diff.len(), cpu_diff.len(), "{} length mismatch", name);

    let n = gpu_diff.len();
    if n < 2 {
        return; // Skip correlation for tiny graphs
    }

    // Compute Pearson correlation coefficient
    let mean_gpu: f32 = gpu_diff.iter().sum::<f32>() / n as f32;
    let mean_cpu: f32 = cpu_diff.iter().sum::<f32>() / n as f32;

    let mut numerator = 0.0f32;
    let mut sum_sq_gpu = 0.0f32;
    let mut sum_sq_cpu = 0.0f32;

    for i in 0..n {
        let diff_gpu = gpu_diff[i] - mean_gpu;
        let diff_cpu = cpu_diff[i] - mean_cpu;

        numerator += diff_gpu * diff_cpu;
        sum_sq_gpu += diff_gpu * diff_gpu;
        sum_sq_cpu += diff_cpu * diff_cpu;
    }

    let correlation = if sum_sq_gpu > 0.0 && sum_sq_cpu > 0.0 {
        numerator / (sum_sq_gpu.sqrt() * sum_sq_cpu.sqrt())
    } else {
        1.0 // Both constant -> perfect correlation
    };

    println!("{} correlation: {:.3}", name, correlation);

    assert!(
        correlation >= min_correlation,
        "{} correlation too low: {:.3} < {}",
        name,
        correlation,
        min_correlation
    );
}

/// TEST: Complete graph K5 (all vertices have equal degree)
///
/// Expected: All vertices should have similar difficulty (symmetric graph)
#[test]
#[ignore] // Requires GPU hardware
fn test_complete_graph_k5() {
    env_logger::builder().is_test(true).try_init().ok();

    let device = CudaContext::new(0).expect("CUDA device not available");
    let reservoir =
        DendriticReservoirGpu::new(Arc::new(device), "target/ptx/dendritic_reservoir.ptx")
            .expect("Failed to create DendriticReservoirGpu");

    let n = 5;
    let mut adjacency = vec![vec![]; n];

    // Connect all vertices (complete graph K5)
    for i in 0..n {
        for j in 0..n {
            if i != j {
                adjacency[i].push(j);
            }
        }
    }

    // Compute on GPU
    let (gpu_diff, gpu_uncert) = reservoir
        .compute_metrics(&adjacency, n)
        .expect("GPU reservoir failed");

    // Verify validity
    assert_metrics_valid(&gpu_diff, &gpu_uncert, n);

    // For complete graph, all vertices should have similar difficulty
    let mean_diff = gpu_diff.iter().sum::<f32>() / n as f32;
    for (i, &d) in gpu_diff.iter().enumerate() {
        let deviation = (d - mean_diff).abs();
        assert!(
            deviation < 0.3,
            "Vertex {} difficulty {} deviates too much from mean {} in symmetric graph",
            i,
            d,
            mean_diff
        );
    }

    // Compute on CPU for reference
    let (cpu_diff, cpu_uncert) = dendritic_reservoir_cpu_reference(&adjacency, n);

    // Should have positive correlation (not exact match due to reservoir dynamics)
    assert_metrics_correlation(&gpu_diff, &cpu_diff, "Difficulty", 0.5);
    assert_metrics_correlation(&gpu_uncert, &cpu_uncert, "Uncertainty", 0.3);

    println!("PASS: Complete graph K5 test");
    println!("  GPU difficulty: {:?}", gpu_diff);
    println!("  GPU uncertainty: {:?}", gpu_uncert);
}

/// TEST: Star graph (1 hub connected to n-1 leaves)
///
/// Expected: Hub has highest difficulty (highest degree)
#[test]
#[ignore]
fn test_star_graph() {
    env_logger::builder().is_test(true).try_init().ok();

    let device = CudaContext::new(0).expect("CUDA device not available");
    let reservoir =
        DendriticReservoirGpu::new(Arc::new(device), "target/ptx/dendritic_reservoir.ptx")
            .expect("Failed to create DendriticReservoirGpu");

    let n = 10;
    let hub = 0;
    let mut adjacency = vec![vec![]; n];

    // Create star: hub (0) connected to all others
    for i in 1..n {
        adjacency[hub].push(i);
        adjacency[i].push(hub);
    }

    // Compute on GPU
    let (gpu_diff, gpu_uncert) = reservoir
        .compute_metrics(&adjacency, n)
        .expect("GPU reservoir failed");

    // Verify validity
    assert_metrics_valid(&gpu_diff, &gpu_uncert, n);

    // Hub should have highest or near-highest difficulty
    let hub_diff = gpu_diff[hub];
    let max_diff = gpu_diff.iter().cloned().fold(0.0f32, f32::max);

    assert!(
        hub_diff >= max_diff - 0.2,
        "Hub difficulty {} should be highest or near-highest (max={})",
        hub_diff,
        max_diff
    );

    // Leaves should have similar lower difficulty
    let leaf_diffs: Vec<f32> = gpu_diff[1..].to_vec();
    let mean_leaf_diff = leaf_diffs.iter().sum::<f32>() / leaf_diffs.len() as f32;

    for (i, &d) in leaf_diffs.iter().enumerate() {
        let deviation = (d - mean_leaf_diff).abs();
        assert!(
            deviation < 0.3,
            "Leaf {} difficulty {} deviates too much from mean {} in symmetric leaves",
            i + 1,
            d,
            mean_leaf_diff
        );
    }

    println!("PASS: Star graph test");
    println!("  Hub difficulty: {:.3}", hub_diff);
    println!("  Mean leaf difficulty: {:.3}", mean_leaf_diff);
}

/// TEST: Path graph (linear chain)
///
/// Expected: Middle vertices harder than endpoints
#[test]
#[ignore]
fn test_path_graph() {
    env_logger::builder().is_test(true).try_init().ok();

    let device = CudaContext::new(0).expect("CUDA device not available");
    let reservoir =
        DendriticReservoirGpu::new(Arc::new(device), "target/ptx/dendritic_reservoir.ptx")
            .expect("Failed to create DendriticReservoirGpu");

    let n = 10;
    let mut adjacency = vec![vec![]; n];

    // Create path: 0-1-2-...-9
    for i in 0..n - 1 {
        adjacency[i].push(i + 1);
        adjacency[i + 1].push(i);
    }

    // Compute on GPU
    let (gpu_diff, gpu_uncert) = reservoir
        .compute_metrics(&adjacency, n)
        .expect("GPU reservoir failed");

    // Verify validity
    assert_metrics_valid(&gpu_diff, &gpu_uncert, n);

    // Endpoints (0, n-1) should have lower difficulty than middle vertices
    let endpoint_diff = (gpu_diff[0] + gpu_diff[n - 1]) / 2.0;
    let middle_diff = (gpu_diff[4] + gpu_diff[5]) / 2.0;

    // Note: Relaxed assertion since reservoir dynamics may vary
    println!("Endpoint difficulty: {:.3}", endpoint_diff);
    println!("Middle difficulty: {:.3}", middle_diff);

    // Just verify endpoints have degree 1, middle have degree 2
    // This should be reflected in difficulty (though reservoir may smooth it)
    assert_eq!(adjacency[0].len(), 1, "Endpoint should have degree 1");
    assert_eq!(adjacency[4].len(), 2, "Middle should have degree 2");

    println!("PASS: Path graph test");
}

/// TEST: Graph with isolated vertex
///
/// Expected: Isolated vertex has zero difficulty and uncertainty
#[test]
#[ignore]
fn test_isolated_vertex() {
    env_logger::builder().is_test(true).try_init().ok();

    let device = CudaContext::new(0).expect("CUDA device not available");
    let reservoir =
        DendriticReservoirGpu::new(Arc::new(device), "target/ptx/dendritic_reservoir.ptx")
            .expect("Failed to create DendriticReservoirGpu");

    let n = 5;
    let mut adjacency = vec![vec![]; n];

    // Create triangle (0-1-2-0) + isolated vertex 3 + isolated vertex 4
    adjacency[0] = vec![1, 2];
    adjacency[1] = vec![0, 2];
    adjacency[2] = vec![0, 1];
    // adjacency[3] and adjacency[4] remain empty

    // Compute on GPU
    let (gpu_diff, gpu_uncert) = reservoir
        .compute_metrics(&adjacency, n)
        .expect("GPU reservoir failed");

    // Verify validity
    assert_metrics_valid(&gpu_diff, &gpu_uncert, n);

    // Isolated vertices should have low or zero difficulty
    assert!(
        gpu_diff[3] < 0.3,
        "Isolated vertex 3 should have low difficulty, got {:.3}",
        gpu_diff[3]
    );
    assert!(
        gpu_diff[4] < 0.3,
        "Isolated vertex 4 should have low difficulty, got {:.3}",
        gpu_diff[4]
    );

    // Triangle vertices should have higher difficulty
    let triangle_diff = (gpu_diff[0] + gpu_diff[1] + gpu_diff[2]) / 3.0;
    assert!(
        triangle_diff > gpu_diff[3] && triangle_diff > gpu_diff[4],
        "Triangle vertices should have higher difficulty than isolated"
    );

    println!("PASS: Isolated vertex test");
    println!("  Triangle difficulty: {:.3}", triangle_diff);
    println!(
        "  Isolated vertices: {:.3}, {:.3}",
        gpu_diff[3], gpu_diff[4]
    );
}

/// TEST: Compare with CPU reference on small random graph
#[test]
#[ignore]
fn test_cpu_gpu_correlation() {
    env_logger::builder().is_test(true).try_init().ok();

    let device = CudaContext::new(0).expect("CUDA device not available");
    let reservoir =
        DendriticReservoirGpu::new(Arc::new(device), "target/ptx/dendritic_reservoir.ptx")
            .expect("Failed to create DendriticReservoirGpu");

    let n = 20;
    let mut adjacency = vec![vec![]; n];

    // Create pseudo-random graph (deterministic for testing)
    for i in 0..n {
        for j in (i + 1)..n {
            // Connect if (i + j) % 3 == 0 (deterministic pattern)
            if (i + j) % 3 == 0 {
                adjacency[i].push(j);
                adjacency[j].push(i);
            }
        }
    }

    // Compute on GPU
    let (gpu_diff, gpu_uncert) = reservoir
        .compute_metrics(&adjacency, n)
        .expect("GPU reservoir failed");

    // Compute on CPU
    let (cpu_diff, cpu_uncert) = dendritic_reservoir_cpu_reference(&adjacency, n);

    // Verify validity
    assert_metrics_valid(&gpu_diff, &gpu_uncert, n);
    assert_metrics_valid(&cpu_diff, &cpu_uncert, n);

    // Check correlation (GPU reservoir should correlate with degree-based heuristics)
    assert_metrics_correlation(&gpu_diff, &cpu_diff, "Difficulty", 0.6);
    assert_metrics_correlation(&gpu_uncert, &cpu_uncert, "Uncertainty", 0.4);

    println!("PASS: CPU-GPU correlation test");
}

/// TEST: Custom parameters (branches, leak rate, iterations)
#[test]
#[ignore]
fn test_custom_parameters() {
    env_logger::builder().is_test(true).try_init().ok();

    let device = CudaContext::new(0).expect("CUDA device not available");

    // Test with 16 branches, leak rate 0.2, 100 iterations
    let reservoir = DendriticReservoirGpu::new_with_params(
        Arc::new(device),
        "target/ptx/dendritic_reservoir.ptx",
        16,
        0.2,
        100,
    )
    .expect("Failed to create DendriticReservoirGpu with custom params");

    let n = 10;
    let mut adjacency = vec![vec![]; n];

    // Create complete graph K10
    for i in 0..n {
        for j in 0..n {
            if i != j {
                adjacency[i].push(j);
            }
        }
    }

    // Compute on GPU
    let (gpu_diff, gpu_uncert) = reservoir
        .compute_metrics(&adjacency, n)
        .expect("GPU reservoir failed");

    // Verify validity
    assert_metrics_valid(&gpu_diff, &gpu_uncert, n);

    // Verify parameters were applied
    assert_eq!(reservoir.num_branches(), 16);
    assert!((reservoir.leak_rate() - 0.2).abs() < 1e-6);
    assert_eq!(reservoir.iterations(), 100);

    println!("PASS: Custom parameters test");
    println!("  Branches: {}", reservoir.num_branches());
    println!("  Leak rate: {}", reservoir.leak_rate());
    println!("  Iterations: {}", reservoir.iterations());
}

/// BENCHMARK: DSJC250-like graph (250 vertices, ~15k edges)
///
/// Target: < 100ms on RTX 3060
#[test]
#[ignore]
fn benchmark_dsjc250_like() {
    env_logger::builder().is_test(true).try_init().ok();

    let device = CudaContext::new(0).expect("CUDA device not available");
    let reservoir =
        DendriticReservoirGpu::new(Arc::new(device), "target/ptx/dendritic_reservoir.ptx")
            .expect("Failed to create DendriticReservoirGpu");

    let n = 250;
    let mut adjacency = vec![vec![]; n];

    // Create pseudo-random graph with density ~0.5
    for i in 0..n {
        for j in (i + 1)..n {
            // Connect if hash(i, j) % 2 == 0
            if ((i * 997 + j * 991) % 2) == 0 {
                adjacency[i].push(j);
                adjacency[j].push(i);
            }
        }
    }

    let edge_count: usize = adjacency.iter().map(|v| v.len()).sum::<usize>() / 2;
    println!("Benchmark graph: {} vertices, {} edges", n, edge_count);

    // Warmup run
    reservoir
        .compute_metrics(&adjacency, n)
        .expect("Warmup failed");

    // Benchmark run
    let start = std::time::Instant::now();
    let (gpu_diff, gpu_uncert) = reservoir
        .compute_metrics(&adjacency, n)
        .expect("GPU reservoir failed");
    let elapsed = start.elapsed();

    // Verify validity
    assert_metrics_valid(&gpu_diff, &gpu_uncert, n);

    println!("BENCHMARK: DSJC250-like graph");
    println!("  Runtime: {:.2}ms", elapsed.as_secs_f64() * 1000.0);
    println!(
        "  Mean difficulty: {:.3}",
        gpu_diff.iter().sum::<f32>() / n as f32
    );
    println!(
        "  Mean uncertainty: {:.3}",
        gpu_uncert.iter().sum::<f32>() / n as f32
    );

    // Target: < 100ms
    assert!(
        elapsed.as_millis() < 100,
        "Performance target missed: {}ms > 100ms",
        elapsed.as_millis()
    );

    println!("PASS: Performance target met!");
}
