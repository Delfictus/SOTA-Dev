//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-37061995
// Cuda compilation tools, release 13.1, V13.1.115
// Based on NVVM 21.0.0
//

.version 9.1
.target sm_120
.address_size 64

	// .globl	stage1_dms_escape_scores_v2
.const .align 4 .b8 c_aa_props[320];
.const .align 4 .b8 c_escape_matrix[672144];
.const .align 4 .b8 c_antibody_epitopes[3344];
// _ZZ27stage1_dms_escape_scores_v2E16smem_warp_escape has been demoted
// _ZZ27stage1_dms_escape_scores_v2E10smem_final has been demoted
// _ZZ25batch_fitness_combined_v2E16smem_warp_escape has been demoted
// _ZZ25batch_fitness_combined_v2E17smem_final_escape has been demoted
// _ZZ25compute_population_mean_SE9smem_warp has been demoted

.visible .entry stage1_dms_escape_scores_v2(
	.param .u64 .ptr .align 1 stage1_dms_escape_scores_v2_param_0,
	.param .u64 .ptr .align 1 stage1_dms_escape_scores_v2_param_1,
	.param .u64 .ptr .align 1 stage1_dms_escape_scores_v2_param_2,
	.param .u32 stage1_dms_escape_scores_v2_param_3,
	.param .u64 .ptr .align 1 stage1_dms_escape_scores_v2_param_4
)
.maxntid 256
.minnctapersm 4
{
	.local .align 16 .b8 	__local_depot0[80];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<133>;
	.reg .b32 	%r<394>;
	.reg .b64 	%rd<37>;
	// demoted variable
	.shared .align 4 .b8 _ZZ27stage1_dms_escape_scores_v2E16smem_warp_escape[320];
	// demoted variable
	.shared .align 4 .b8 _ZZ27stage1_dms_escape_scores_v2E10smem_final[40];
	mov.b64 	%SPL, __local_depot0;
	ld.param.b64 	%rd5, [stage1_dms_escape_scores_v2_param_0];
	ld.param.b64 	%rd6, [stage1_dms_escape_scores_v2_param_2];
	ld.param.b32 	%r94, [stage1_dms_escape_scores_v2_param_3];
	ld.param.b64 	%rd7, [stage1_dms_escape_scores_v2_param_4];
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p1, %r1, %r94;
	@%p1 bra 	$L__BB0_53;
	cvta.to.global.u64 	%rd9, %rd6;
	mov.u32 	%r2, %tid.x;
	and.b32 	%r3, %r2, 31;
	st.local.v4.b32 	[%rd1], {0f00000000, 0f00000000, 0f00000000, 0f00000000};
	st.local.v4.b32 	[%rd1+16], {0f00000000, 0f00000000, 0f00000000, 0f00000000};
	st.local.v4.b32 	[%rd1+32], {0f00000000, 0f00000000, 0f00000000, 0f00000000};
	st.local.v4.b32 	[%rd1+48], {0f00000000, 0f00000000, 0f00000000, 0f00000000};
	st.local.v4.b32 	[%rd1+64], {0f00000000, 0f00000000, 0f00000000, 0f00000000};
	mul.wide.u32 	%rd10, %r1, 4;
	add.s64 	%rd11, %rd9, %rd10;
	ld.global.nc.b32 	%r4, [%rd11];
	setp.ge.s32 	%p2, %r2, %r4;
	mov.b32 	%r365, 0f00000000;
	mov.b32 	%r366, %r365;
	mov.b32 	%r367, %r365;
	mov.b32 	%r368, %r365;
	mov.b32 	%r369, %r365;
	mov.b32 	%r370, %r365;
	mov.b32 	%r371, %r365;
	mov.b32 	%r372, %r365;
	mov.b32 	%r373, %r365;
	mov.b32 	%r374, %r365;
	mov.b32 	%r375, %r365;
	mov.b32 	%r376, %r365;
	mov.b32 	%r377, %r365;
	mov.b32 	%r378, %r365;
	mov.b32 	%r379, %r365;
	mov.b32 	%r380, %r365;
	mov.b32 	%r381, %r365;
	mov.b32 	%r382, %r365;
	mov.b32 	%r383, %r365;
	@%p2 bra 	$L__BB0_8;
	mov.u32 	%r5, %ntid.x;
	cvta.to.global.u64 	%rd2, %rd5;
	mul.lo.s32 	%r6, %r1, 50;
	mov.b32 	%r362, %r2;
$L__BB0_3:
	add.s32 	%r96, %r362, %r6;
	mul.wide.s32 	%rd12, %r96, 4;
	add.s64 	%rd13, %rd2, %rd12;
	ld.global.nc.b32 	%r8, [%rd13];
	add.s32 	%r97, %r8, -532;
	setp.lt.u32 	%p3, %r97, -201;
	@%p3 bra 	$L__BB0_6;
	mov.b64 	%rd15, c_antibody_epitopes;
	add.s64 	%rd36, %rd15, 8;
	add.s32 	%r363, %r8, 272;
	mov.b32 	%r364, 272;
$L__BB0_5:
	add.s32 	%r99, %r363, -603;
	mul.wide.u32 	%rd16, %r99, 4;
	mov.b64 	%rd17, c_escape_matrix;
	add.s64 	%rd18, %rd17, %rd16;
	ld.const.b32 	%r100, [%rd18];
	ld.const.b32 	%r101, [%rd36+-8];
	mul.wide.s32 	%rd19, %r101, 8;
	add.s64 	%rd20, %rd1, %rd19;
	ld.local.v2.b32 	{%r102, %r103}, [%rd20];
	add.ftz.f32 	%r104, %r100, %r102;
	abs.ftz.f32 	%r105, %r102;
	abs.ftz.f32 	%r106, %r100;
	setp.ltu.ftz.f32 	%p4, %r105, %r106;
	selp.f32 	%r107, %r102, %r100, %p4;
	selp.f32 	%r108, %r100, %r102, %p4;
	sub.ftz.f32 	%r109, %r108, %r104;
	add.ftz.f32 	%r110, %r107, %r109;
	add.ftz.f32 	%r111, %r103, %r110;
	st.local.v2.b32 	[%rd20], {%r104, %r111};
	add.s32 	%r112, %r363, -402;
	mul.wide.u32 	%rd21, %r112, 4;
	add.s64 	%rd22, %rd17, %rd21;
	ld.const.b32 	%r113, [%rd22];
	ld.const.b32 	%r114, [%rd36+-4];
	mul.wide.s32 	%rd23, %r114, 8;
	add.s64 	%rd24, %rd1, %rd23;
	ld.local.v2.b32 	{%r115, %r116}, [%rd24];
	add.ftz.f32 	%r117, %r113, %r115;
	abs.ftz.f32 	%r118, %r115;
	abs.ftz.f32 	%r119, %r113;
	setp.ltu.ftz.f32 	%p5, %r118, %r119;
	selp.f32 	%r120, %r115, %r113, %p5;
	selp.f32 	%r121, %r113, %r115, %p5;
	sub.ftz.f32 	%r122, %r121, %r117;
	add.ftz.f32 	%r123, %r120, %r122;
	add.ftz.f32 	%r124, %r116, %r123;
	st.local.v2.b32 	[%rd24], {%r117, %r124};
	add.s32 	%r125, %r363, -201;
	mul.wide.u32 	%rd25, %r125, 4;
	add.s64 	%rd26, %rd17, %rd25;
	ld.const.b32 	%r126, [%rd26];
	ld.const.b32 	%r127, [%rd36];
	mul.wide.s32 	%rd27, %r127, 8;
	add.s64 	%rd28, %rd1, %rd27;
	ld.local.v2.b32 	{%r128, %r129}, [%rd28];
	add.ftz.f32 	%r130, %r126, %r128;
	abs.ftz.f32 	%r131, %r128;
	abs.ftz.f32 	%r132, %r126;
	setp.ltu.ftz.f32 	%p6, %r131, %r132;
	selp.f32 	%r133, %r128, %r126, %p6;
	selp.f32 	%r134, %r126, %r128, %p6;
	sub.ftz.f32 	%r135, %r134, %r130;
	add.ftz.f32 	%r136, %r133, %r135;
	add.ftz.f32 	%r137, %r129, %r136;
	st.local.v2.b32 	[%rd28], {%r130, %r137};
	mul.wide.u32 	%rd29, %r363, 4;
	add.s64 	%rd30, %rd17, %rd29;
	ld.const.b32 	%r138, [%rd30];
	ld.const.b32 	%r139, [%rd36+4];
	mul.wide.s32 	%rd31, %r139, 8;
	add.s64 	%rd32, %rd1, %rd31;
	ld.local.v2.b32 	{%r140, %r141}, [%rd32];
	add.ftz.f32 	%r142, %r138, %r140;
	abs.ftz.f32 	%r143, %r140;
	abs.ftz.f32 	%r144, %r138;
	setp.ltu.ftz.f32 	%p7, %r143, %r144;
	selp.f32 	%r145, %r140, %r138, %p7;
	selp.f32 	%r146, %r138, %r140, %p7;
	sub.ftz.f32 	%r147, %r146, %r142;
	add.ftz.f32 	%r148, %r145, %r147;
	add.ftz.f32 	%r149, %r141, %r148;
	st.local.v2.b32 	[%rd32], {%r142, %r149};
	add.s32 	%r364, %r364, 804;
	add.s64 	%rd36, %rd36, 16;
	add.s32 	%r363, %r363, 804;
	setp.ne.s32 	%p8, %r364, 168308;
	@%p8 bra 	$L__BB0_5;
$L__BB0_6:
	add.s32 	%r362, %r362, %r5;
	setp.lt.s32 	%p9, %r362, %r4;
	@%p9 bra 	$L__BB0_3;
	ld.local.v4.b32 	{%r150, %r151, %r382, %r381}, [%rd1];
	ld.local.v4.b32 	{%r380, %r379, %r378, %r377}, [%rd1+16];
	ld.local.v4.b32 	{%r376, %r375, %r374, %r373}, [%rd1+32];
	ld.local.v4.b32 	{%r372, %r371, %r370, %r369}, [%rd1+48];
	ld.local.v4.b32 	{%r368, %r367, %r366, %r365}, [%rd1+64];
	add.ftz.f32 	%r383, %r150, %r151;
$L__BB0_8:
	shfl.sync.bfly.b32 	%r152|%p10, %r383, 16, 31, -1;
	add.ftz.f32 	%r153, %r383, %r152;
	shfl.sync.bfly.b32 	%r154|%p11, %r153, 8, 31, -1;
	add.ftz.f32 	%r155, %r153, %r154;
	shfl.sync.bfly.b32 	%r156|%p12, %r155, 4, 31, -1;
	add.ftz.f32 	%r157, %r155, %r156;
	shfl.sync.bfly.b32 	%r158|%p13, %r157, 2, 31, -1;
	add.ftz.f32 	%r159, %r157, %r158;
	shfl.sync.bfly.b32 	%r160|%p14, %r159, 1, 31, -1;
	add.ftz.f32 	%r53, %r159, %r160;
	add.ftz.f32 	%r161, %r382, %r381;
	shfl.sync.bfly.b32 	%r162|%p15, %r161, 16, 31, -1;
	add.ftz.f32 	%r163, %r161, %r162;
	shfl.sync.bfly.b32 	%r164|%p16, %r163, 8, 31, -1;
	add.ftz.f32 	%r165, %r163, %r164;
	shfl.sync.bfly.b32 	%r166|%p17, %r165, 4, 31, -1;
	add.ftz.f32 	%r167, %r165, %r166;
	shfl.sync.bfly.b32 	%r168|%p18, %r167, 2, 31, -1;
	add.ftz.f32 	%r169, %r167, %r168;
	shfl.sync.bfly.b32 	%r170|%p19, %r169, 1, 31, -1;
	add.ftz.f32 	%r54, %r169, %r170;
	add.ftz.f32 	%r171, %r380, %r379;
	shfl.sync.bfly.b32 	%r172|%p20, %r171, 16, 31, -1;
	add.ftz.f32 	%r173, %r171, %r172;
	shfl.sync.bfly.b32 	%r174|%p21, %r173, 8, 31, -1;
	add.ftz.f32 	%r175, %r173, %r174;
	shfl.sync.bfly.b32 	%r176|%p22, %r175, 4, 31, -1;
	add.ftz.f32 	%r177, %r175, %r176;
	shfl.sync.bfly.b32 	%r178|%p23, %r177, 2, 31, -1;
	add.ftz.f32 	%r179, %r177, %r178;
	shfl.sync.bfly.b32 	%r180|%p24, %r179, 1, 31, -1;
	add.ftz.f32 	%r55, %r179, %r180;
	add.ftz.f32 	%r181, %r378, %r377;
	shfl.sync.bfly.b32 	%r182|%p25, %r181, 16, 31, -1;
	add.ftz.f32 	%r183, %r181, %r182;
	shfl.sync.bfly.b32 	%r184|%p26, %r183, 8, 31, -1;
	add.ftz.f32 	%r185, %r183, %r184;
	shfl.sync.bfly.b32 	%r186|%p27, %r185, 4, 31, -1;
	add.ftz.f32 	%r187, %r185, %r186;
	shfl.sync.bfly.b32 	%r188|%p28, %r187, 2, 31, -1;
	add.ftz.f32 	%r189, %r187, %r188;
	shfl.sync.bfly.b32 	%r190|%p29, %r189, 1, 31, -1;
	add.ftz.f32 	%r56, %r189, %r190;
	add.ftz.f32 	%r191, %r376, %r375;
	shfl.sync.bfly.b32 	%r192|%p30, %r191, 16, 31, -1;
	add.ftz.f32 	%r193, %r191, %r192;
	shfl.sync.bfly.b32 	%r194|%p31, %r193, 8, 31, -1;
	add.ftz.f32 	%r195, %r193, %r194;
	shfl.sync.bfly.b32 	%r196|%p32, %r195, 4, 31, -1;
	add.ftz.f32 	%r197, %r195, %r196;
	shfl.sync.bfly.b32 	%r198|%p33, %r197, 2, 31, -1;
	add.ftz.f32 	%r199, %r197, %r198;
	shfl.sync.bfly.b32 	%r200|%p34, %r199, 1, 31, -1;
	add.ftz.f32 	%r57, %r199, %r200;
	add.ftz.f32 	%r201, %r374, %r373;
	shfl.sync.bfly.b32 	%r202|%p35, %r201, 16, 31, -1;
	add.ftz.f32 	%r203, %r201, %r202;
	shfl.sync.bfly.b32 	%r204|%p36, %r203, 8, 31, -1;
	add.ftz.f32 	%r205, %r203, %r204;
	shfl.sync.bfly.b32 	%r206|%p37, %r205, 4, 31, -1;
	add.ftz.f32 	%r207, %r205, %r206;
	shfl.sync.bfly.b32 	%r208|%p38, %r207, 2, 31, -1;
	add.ftz.f32 	%r209, %r207, %r208;
	shfl.sync.bfly.b32 	%r210|%p39, %r209, 1, 31, -1;
	add.ftz.f32 	%r58, %r209, %r210;
	add.ftz.f32 	%r211, %r372, %r371;
	shfl.sync.bfly.b32 	%r212|%p40, %r211, 16, 31, -1;
	add.ftz.f32 	%r213, %r211, %r212;
	shfl.sync.bfly.b32 	%r214|%p41, %r213, 8, 31, -1;
	add.ftz.f32 	%r215, %r213, %r214;
	shfl.sync.bfly.b32 	%r216|%p42, %r215, 4, 31, -1;
	add.ftz.f32 	%r217, %r215, %r216;
	shfl.sync.bfly.b32 	%r218|%p43, %r217, 2, 31, -1;
	add.ftz.f32 	%r219, %r217, %r218;
	shfl.sync.bfly.b32 	%r220|%p44, %r219, 1, 31, -1;
	add.ftz.f32 	%r59, %r219, %r220;
	add.ftz.f32 	%r221, %r370, %r369;
	shfl.sync.bfly.b32 	%r222|%p45, %r221, 16, 31, -1;
	add.ftz.f32 	%r223, %r221, %r222;
	shfl.sync.bfly.b32 	%r224|%p46, %r223, 8, 31, -1;
	add.ftz.f32 	%r225, %r223, %r224;
	shfl.sync.bfly.b32 	%r226|%p47, %r225, 4, 31, -1;
	add.ftz.f32 	%r227, %r225, %r226;
	shfl.sync.bfly.b32 	%r228|%p48, %r227, 2, 31, -1;
	add.ftz.f32 	%r229, %r227, %r228;
	shfl.sync.bfly.b32 	%r230|%p49, %r229, 1, 31, -1;
	add.ftz.f32 	%r60, %r229, %r230;
	add.ftz.f32 	%r231, %r368, %r367;
	shfl.sync.bfly.b32 	%r232|%p50, %r231, 16, 31, -1;
	add.ftz.f32 	%r233, %r231, %r232;
	shfl.sync.bfly.b32 	%r234|%p51, %r233, 8, 31, -1;
	add.ftz.f32 	%r235, %r233, %r234;
	shfl.sync.bfly.b32 	%r236|%p52, %r235, 4, 31, -1;
	add.ftz.f32 	%r237, %r235, %r236;
	shfl.sync.bfly.b32 	%r238|%p53, %r237, 2, 31, -1;
	add.ftz.f32 	%r239, %r237, %r238;
	shfl.sync.bfly.b32 	%r240|%p54, %r239, 1, 31, -1;
	add.ftz.f32 	%r61, %r239, %r240;
	add.ftz.f32 	%r241, %r366, %r365;
	shfl.sync.bfly.b32 	%r242|%p55, %r241, 16, 31, -1;
	add.ftz.f32 	%r243, %r241, %r242;
	shfl.sync.bfly.b32 	%r244|%p56, %r243, 8, 31, -1;
	add.ftz.f32 	%r245, %r243, %r244;
	shfl.sync.bfly.b32 	%r246|%p57, %r245, 4, 31, -1;
	add.ftz.f32 	%r247, %r245, %r246;
	shfl.sync.bfly.b32 	%r248|%p58, %r247, 2, 31, -1;
	add.ftz.f32 	%r249, %r247, %r248;
	shfl.sync.bfly.b32 	%r250|%p59, %r249, 1, 31, -1;
	add.ftz.f32 	%r62, %r249, %r250;
	setp.ne.s32 	%p60, %r3, 0;
	@%p60 bra 	$L__BB0_10;
	shr.u32 	%r251, %r2, 3;
	and.b32 	%r252, %r251, 28;
	mov.b32 	%r253, _ZZ27stage1_dms_escape_scores_v2E16smem_warp_escape;
	add.s32 	%r254, %r253, %r252;
	st.shared.b32 	[%r254], %r53;
	st.shared.b32 	[%r254+32], %r54;
	st.shared.b32 	[%r254+64], %r55;
	st.shared.b32 	[%r254+96], %r56;
	st.shared.b32 	[%r254+128], %r57;
	st.shared.b32 	[%r254+160], %r58;
	st.shared.b32 	[%r254+192], %r59;
	st.shared.b32 	[%r254+224], %r60;
	st.shared.b32 	[%r254+256], %r61;
	st.shared.b32 	[%r254+288], %r62;
$L__BB0_10:
	bar.sync 	0;
	setp.gt.u32 	%p61, %r2, 31;
	@%p61 bra 	$L__BB0_51;
	setp.gt.u32 	%p62, %r3, 7;
	shl.b32 	%r256, %r3, 2;
	mov.b32 	%r257, _ZZ27stage1_dms_escape_scores_v2E16smem_warp_escape;
	add.s32 	%r63, %r257, %r256;
	mov.b32 	%r384, 0f00000000;
	@%p62 bra 	$L__BB0_13;
	ld.shared.b32 	%r384, [%r63];
$L__BB0_13:
	setp.ne.s32 	%p63, %r3, 0;
	shfl.sync.bfly.b32 	%r258|%p64, %r384, 16, 31, -1;
	add.ftz.f32 	%r259, %r384, %r258;
	shfl.sync.bfly.b32 	%r260|%p65, %r259, 8, 31, -1;
	add.ftz.f32 	%r261, %r259, %r260;
	shfl.sync.bfly.b32 	%r262|%p66, %r261, 4, 31, -1;
	add.ftz.f32 	%r263, %r261, %r262;
	shfl.sync.bfly.b32 	%r264|%p67, %r263, 2, 31, -1;
	add.ftz.f32 	%r265, %r263, %r264;
	shfl.sync.bfly.b32 	%r266|%p68, %r265, 1, 31, -1;
	add.ftz.f32 	%r66, %r265, %r266;
	@%p63 bra 	$L__BB0_15;
	st.shared.b32 	[_ZZ27stage1_dms_escape_scores_v2E10smem_final], %r66;
$L__BB0_15:
	setp.gt.u32 	%p69, %r3, 7;
	mov.b32 	%r385, 0f00000000;
	@%p69 bra 	$L__BB0_17;
	ld.shared.b32 	%r385, [%r63+32];
$L__BB0_17:
	setp.ne.s32 	%p70, %r3, 0;
	shfl.sync.bfly.b32 	%r268|%p71, %r385, 16, 31, -1;
	add.ftz.f32 	%r269, %r385, %r268;
	shfl.sync.bfly.b32 	%r270|%p72, %r269, 8, 31, -1;
	add.ftz.f32 	%r271, %r269, %r270;
	shfl.sync.bfly.b32 	%r272|%p73, %r271, 4, 31, -1;
	add.ftz.f32 	%r273, %r271, %r272;
	shfl.sync.bfly.b32 	%r274|%p74, %r273, 2, 31, -1;
	add.ftz.f32 	%r275, %r273, %r274;
	shfl.sync.bfly.b32 	%r276|%p75, %r275, 1, 31, -1;
	add.ftz.f32 	%r69, %r275, %r276;
	@%p70 bra 	$L__BB0_19;
	st.shared.b32 	[_ZZ27stage1_dms_escape_scores_v2E10smem_final+4], %r69;
$L__BB0_19:
	setp.gt.u32 	%p76, %r3, 7;
	mov.b32 	%r386, 0f00000000;
	@%p76 bra 	$L__BB0_21;
	ld.shared.b32 	%r386, [%r63+64];
$L__BB0_21:
	setp.ne.s32 	%p77, %r3, 0;
	shfl.sync.bfly.b32 	%r278|%p78, %r386, 16, 31, -1;
	add.ftz.f32 	%r279, %r386, %r278;
	shfl.sync.bfly.b32 	%r280|%p79, %r279, 8, 31, -1;
	add.ftz.f32 	%r281, %r279, %r280;
	shfl.sync.bfly.b32 	%r282|%p80, %r281, 4, 31, -1;
	add.ftz.f32 	%r283, %r281, %r282;
	shfl.sync.bfly.b32 	%r284|%p81, %r283, 2, 31, -1;
	add.ftz.f32 	%r285, %r283, %r284;
	shfl.sync.bfly.b32 	%r286|%p82, %r285, 1, 31, -1;
	add.ftz.f32 	%r72, %r285, %r286;
	@%p77 bra 	$L__BB0_23;
	st.shared.b32 	[_ZZ27stage1_dms_escape_scores_v2E10smem_final+8], %r72;
$L__BB0_23:
	setp.gt.u32 	%p83, %r3, 7;
	mov.b32 	%r387, 0f00000000;
	@%p83 bra 	$L__BB0_25;
	ld.shared.b32 	%r387, [%r63+96];
$L__BB0_25:
	setp.ne.s32 	%p84, %r3, 0;
	shfl.sync.bfly.b32 	%r288|%p85, %r387, 16, 31, -1;
	add.ftz.f32 	%r289, %r387, %r288;
	shfl.sync.bfly.b32 	%r290|%p86, %r289, 8, 31, -1;
	add.ftz.f32 	%r291, %r289, %r290;
	shfl.sync.bfly.b32 	%r292|%p87, %r291, 4, 31, -1;
	add.ftz.f32 	%r293, %r291, %r292;
	shfl.sync.bfly.b32 	%r294|%p88, %r293, 2, 31, -1;
	add.ftz.f32 	%r295, %r293, %r294;
	shfl.sync.bfly.b32 	%r296|%p89, %r295, 1, 31, -1;
	add.ftz.f32 	%r75, %r295, %r296;
	@%p84 bra 	$L__BB0_27;
	st.shared.b32 	[_ZZ27stage1_dms_escape_scores_v2E10smem_final+12], %r75;
$L__BB0_27:
	setp.gt.u32 	%p90, %r3, 7;
	mov.b32 	%r388, 0f00000000;
	@%p90 bra 	$L__BB0_29;
	ld.shared.b32 	%r388, [%r63+128];
$L__BB0_29:
	setp.ne.s32 	%p91, %r3, 0;
	shfl.sync.bfly.b32 	%r298|%p92, %r388, 16, 31, -1;
	add.ftz.f32 	%r299, %r388, %r298;
	shfl.sync.bfly.b32 	%r300|%p93, %r299, 8, 31, -1;
	add.ftz.f32 	%r301, %r299, %r300;
	shfl.sync.bfly.b32 	%r302|%p94, %r301, 4, 31, -1;
	add.ftz.f32 	%r303, %r301, %r302;
	shfl.sync.bfly.b32 	%r304|%p95, %r303, 2, 31, -1;
	add.ftz.f32 	%r305, %r303, %r304;
	shfl.sync.bfly.b32 	%r306|%p96, %r305, 1, 31, -1;
	add.ftz.f32 	%r78, %r305, %r306;
	@%p91 bra 	$L__BB0_31;
	st.shared.b32 	[_ZZ27stage1_dms_escape_scores_v2E10smem_final+16], %r78;
$L__BB0_31:
	setp.gt.u32 	%p97, %r3, 7;
	mov.b32 	%r389, 0f00000000;
	@%p97 bra 	$L__BB0_33;
	ld.shared.b32 	%r389, [%r63+160];
$L__BB0_33:
	setp.ne.s32 	%p98, %r3, 0;
	shfl.sync.bfly.b32 	%r308|%p99, %r389, 16, 31, -1;
	add.ftz.f32 	%r309, %r389, %r308;
	shfl.sync.bfly.b32 	%r310|%p100, %r309, 8, 31, -1;
	add.ftz.f32 	%r311, %r309, %r310;
	shfl.sync.bfly.b32 	%r312|%p101, %r311, 4, 31, -1;
	add.ftz.f32 	%r313, %r311, %r312;
	shfl.sync.bfly.b32 	%r314|%p102, %r313, 2, 31, -1;
	add.ftz.f32 	%r315, %r313, %r314;
	shfl.sync.bfly.b32 	%r316|%p103, %r315, 1, 31, -1;
	add.ftz.f32 	%r81, %r315, %r316;
	@%p98 bra 	$L__BB0_35;
	st.shared.b32 	[_ZZ27stage1_dms_escape_scores_v2E10smem_final+20], %r81;
$L__BB0_35:
	setp.gt.u32 	%p104, %r3, 7;
	mov.b32 	%r390, 0f00000000;
	@%p104 bra 	$L__BB0_37;
	ld.shared.b32 	%r390, [%r63+192];
$L__BB0_37:
	setp.ne.s32 	%p105, %r3, 0;
	shfl.sync.bfly.b32 	%r318|%p106, %r390, 16, 31, -1;
	add.ftz.f32 	%r319, %r390, %r318;
	shfl.sync.bfly.b32 	%r320|%p107, %r319, 8, 31, -1;
	add.ftz.f32 	%r321, %r319, %r320;
	shfl.sync.bfly.b32 	%r322|%p108, %r321, 4, 31, -1;
	add.ftz.f32 	%r323, %r321, %r322;
	shfl.sync.bfly.b32 	%r324|%p109, %r323, 2, 31, -1;
	add.ftz.f32 	%r325, %r323, %r324;
	shfl.sync.bfly.b32 	%r326|%p110, %r325, 1, 31, -1;
	add.ftz.f32 	%r84, %r325, %r326;
	@%p105 bra 	$L__BB0_39;
	st.shared.b32 	[_ZZ27stage1_dms_escape_scores_v2E10smem_final+24], %r84;
$L__BB0_39:
	setp.gt.u32 	%p111, %r3, 7;
	mov.b32 	%r391, 0f00000000;
	@%p111 bra 	$L__BB0_41;
	ld.shared.b32 	%r391, [%r63+224];
$L__BB0_41:
	setp.ne.s32 	%p112, %r3, 0;
	shfl.sync.bfly.b32 	%r328|%p113, %r391, 16, 31, -1;
	add.ftz.f32 	%r329, %r391, %r328;
	shfl.sync.bfly.b32 	%r330|%p114, %r329, 8, 31, -1;
	add.ftz.f32 	%r331, %r329, %r330;
	shfl.sync.bfly.b32 	%r332|%p115, %r331, 4, 31, -1;
	add.ftz.f32 	%r333, %r331, %r332;
	shfl.sync.bfly.b32 	%r334|%p116, %r333, 2, 31, -1;
	add.ftz.f32 	%r335, %r333, %r334;
	shfl.sync.bfly.b32 	%r336|%p117, %r335, 1, 31, -1;
	add.ftz.f32 	%r87, %r335, %r336;
	@%p112 bra 	$L__BB0_43;
	st.shared.b32 	[_ZZ27stage1_dms_escape_scores_v2E10smem_final+28], %r87;
$L__BB0_43:
	setp.gt.u32 	%p118, %r3, 7;
	mov.b32 	%r392, 0f00000000;
	@%p118 bra 	$L__BB0_45;
	ld.shared.b32 	%r392, [%r63+256];
$L__BB0_45:
	setp.ne.s32 	%p119, %r3, 0;
	shfl.sync.bfly.b32 	%r338|%p120, %r392, 16, 31, -1;
	add.ftz.f32 	%r339, %r392, %r338;
	shfl.sync.bfly.b32 	%r340|%p121, %r339, 8, 31, -1;
	add.ftz.f32 	%r341, %r339, %r340;
	shfl.sync.bfly.b32 	%r342|%p122, %r341, 4, 31, -1;
	add.ftz.f32 	%r343, %r341, %r342;
	shfl.sync.bfly.b32 	%r344|%p123, %r343, 2, 31, -1;
	add.ftz.f32 	%r345, %r343, %r344;
	shfl.sync.bfly.b32 	%r346|%p124, %r345, 1, 31, -1;
	add.ftz.f32 	%r90, %r345, %r346;
	@%p119 bra 	$L__BB0_47;
	st.shared.b32 	[_ZZ27stage1_dms_escape_scores_v2E10smem_final+32], %r90;
$L__BB0_47:
	setp.gt.u32 	%p125, %r3, 7;
	mov.b32 	%r393, 0f00000000;
	@%p125 bra 	$L__BB0_49;
	ld.shared.b32 	%r393, [%r63+288];
$L__BB0_49:
	setp.ne.s32 	%p126, %r3, 0;
	shfl.sync.bfly.b32 	%r348|%p127, %r393, 16, 31, -1;
	add.ftz.f32 	%r349, %r393, %r348;
	shfl.sync.bfly.b32 	%r350|%p128, %r349, 8, 31, -1;
	add.ftz.f32 	%r351, %r349, %r350;
	shfl.sync.bfly.b32 	%r352|%p129, %r351, 4, 31, -1;
	add.ftz.f32 	%r353, %r351, %r352;
	shfl.sync.bfly.b32 	%r354|%p130, %r353, 2, 31, -1;
	add.ftz.f32 	%r355, %r353, %r354;
	shfl.sync.bfly.b32 	%r356|%p131, %r355, 1, 31, -1;
	add.ftz.f32 	%r93, %r355, %r356;
	@%p126 bra 	$L__BB0_51;
	st.shared.b32 	[_ZZ27stage1_dms_escape_scores_v2E10smem_final+36], %r93;
$L__BB0_51:
	bar.sync 	0;
	setp.gt.u32 	%p132, %r2, 9;
	@%p132 bra 	$L__BB0_53;
	mad.lo.s32 	%r357, %r1, 10, %r2;
	shl.b32 	%r358, %r2, 2;
	mov.b32 	%r359, _ZZ27stage1_dms_escape_scores_v2E10smem_final;
	add.s32 	%r360, %r359, %r358;
	ld.shared.b32 	%r361, [%r360];
	cvta.to.global.u64 	%rd33, %rd7;
	mul.wide.s32 	%rd34, %r357, 4;
	add.s64 	%rd35, %rd33, %rd34;
	st.global.b32 	[%rd35], %r361;
$L__BB0_53:
	ret;

}
	// .globl	stage2_stability_calc
.visible .entry stage2_stability_calc(
	.param .u64 .ptr .align 1 stage2_stability_calc_param_0,
	.param .u64 .ptr .align 1 stage2_stability_calc_param_1,
	.param .u64 .ptr .align 1 stage2_stability_calc_param_2,
	.param .u64 .ptr .align 1 stage2_stability_calc_param_3,
	.param .u32 stage2_stability_calc_param_4,
	.param .u32 stage2_stability_calc_param_5,
	.param .u64 .ptr .align 1 stage2_stability_calc_param_6,
	.param .u64 .ptr .align 1 stage2_stability_calc_param_7
)
.maxntid 256
.minnctapersm 4
{
	.reg .pred 	%p<11>;
	.reg .b32 	%r<45>;
	.reg .b64 	%rd<26>;

	ld.param.b64 	%rd3, [stage2_stability_calc_param_0];
	ld.param.b64 	%rd4, [stage2_stability_calc_param_1];
	ld.param.b64 	%rd5, [stage2_stability_calc_param_2];
	ld.param.b64 	%rd6, [stage2_stability_calc_param_3];
	ld.param.b32 	%r17, [stage2_stability_calc_param_4];
	ld.param.b32 	%r16, [stage2_stability_calc_param_5];
	ld.param.b64 	%rd7, [stage2_stability_calc_param_7];
	cvta.to.global.u64 	%rd1, %rd7;
	mov.u32 	%r18, %ctaid.x;
	mov.u32 	%r19, %ntid.x;
	mov.u32 	%r20, %tid.x;
	mad.lo.s32 	%r1, %r18, %r19, %r20;
	setp.ge.s32 	%p1, %r1, %r17;
	@%p1 bra 	$L__BB1_12;
	cvta.to.global.u64 	%rd8, %rd3;
	mul.lo.s32 	%r21, %r1, 3;
	mul.wide.s32 	%rd9, %r21, 4;
	add.s64 	%rd2, %rd8, %rd9;
	ld.global.nc.b32 	%r2, [%rd2];
	setp.gt.s32 	%p2, %r2, -1;
	setp.lt.s32 	%p3, %r2, %r16;
	and.pred 	%p4, %p2, %p3;
	@%p4 bra 	$L__BB1_3;
	mul.wide.s32 	%rd24, %r1, 4;
	add.s64 	%rd25, %rd1, %rd24;
	st.global.b32 	[%rd25], 0;
	bra.uni 	$L__BB1_12;
$L__BB1_3:
	ld.global.nc.b32 	%r22, [%rd2+8];
	ld.global.nc.b32 	%r23, [%rd2+4];
	cvta.to.global.u64 	%rd10, %rd4;
	mul.wide.u32 	%rd11, %r2, 4;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.nc.b32 	%r3, [%rd12];
	cvta.to.global.u64 	%rd13, %rd5;
	add.s64 	%rd14, %rd13, %rd11;
	ld.global.nc.b32 	%r4, [%rd14];
	cvta.to.global.u64 	%rd15, %rd6;
	add.s64 	%rd16, %rd15, %rd11;
	ld.global.nc.b32 	%r5, [%rd16];
	mul.wide.s32 	%rd17, %r22, 16;
	mov.b64 	%rd18, c_aa_props;
	add.s64 	%rd19, %rd18, %rd17;
	ld.const.b32 	%r6, [%rd19];
	mul.wide.s32 	%rd20, %r23, 16;
	add.s64 	%rd21, %rd18, %rd20;
	ld.const.b32 	%r7, [%rd21];
	sub.ftz.f32 	%r8, %r6, %r7;
	ld.const.b32 	%r24, [%rd19+4];
	ld.const.b32 	%r25, [%rd21+4];
	sub.ftz.f32 	%r9, %r24, %r25;
	setp.leu.ftz.f32 	%p5, %r9, 0f00000000;
	@%p5 bra 	$L__BB1_5;
	mov.b32 	%r30, 0f42480000;
	div.approx.ftz.f32 	%r31, %r9, %r30;
	mul.ftz.f32 	%r32, %r3, %r31;
	fma.rn.ftz.f32 	%r43, %r3, %r31, %r32;
	bra.uni 	$L__BB1_6;
$L__BB1_5:
	mov.b32 	%r26, 0f42480000;
	div.approx.ftz.f32 	%r27, %r9, %r26;
	abs.ftz.f32 	%r28, %r27;
	mul.ftz.f32 	%r29, %r3, %r28;
	mul.ftz.f32 	%r43, %r29, 0f3F000000;
$L__BB1_6:
	mov.b32 	%r44, 0f00000000;
	setp.eq.s32 	%p6, %r5, 2;
	@%p6 bra 	$L__BB1_10;
	setp.ne.s32 	%p7, %r5, 1;
	@%p7 bra 	$L__BB1_11;
	setp.geu.ftz.f32 	%p9, %r6, 0f3E99999A;
	@%p9 bra 	$L__BB1_11;
	setp.gt.ftz.f32 	%p10, %r7, 0f3F000000;
	selp.f32 	%r44, 0f3FC00000, 0f00000000, %p10;
	bra.uni 	$L__BB1_11;
$L__BB1_10:
	abs.ftz.f32 	%r34, %r8;
	setp.gt.ftz.f32 	%p8, %r34, 0f3E99999A;
	selp.f32 	%r44, 0f3F800000, 0f00000000, %p8;
$L__BB1_11:
	cvt.rn.f32.s32 	%r36, %r4;
	mov.b32 	%r37, 0f41400000;
	div.approx.ftz.f32 	%r38, %r36, %r37;
	min.ftz.f32 	%r39, %r38, 0f3FC00000;
	mul.ftz.f32 	%r40, %r3, %r8;
	fma.rn.ftz.f32 	%r41, %r40, 0f40200000, %r43;
	fma.rn.ftz.f32 	%r42, %r44, %r39, %r41;
	mul.wide.s32 	%rd22, %r1, 4;
	add.s64 	%rd23, %rd1, %rd22;
	st.global.b32 	[%rd23], %r42;
$L__BB1_12:
	ret;

}
	// .globl	batch_fitness_combined_v2
.visible .entry batch_fitness_combined_v2(
	.param .u64 .ptr .align 1 batch_fitness_combined_v2_param_0,
	.param .u64 .ptr .align 1 batch_fitness_combined_v2_param_1,
	.param .u64 .ptr .align 1 batch_fitness_combined_v2_param_2,
	.param .u64 .ptr .align 1 batch_fitness_combined_v2_param_3,
	.param .u64 .ptr .align 1 batch_fitness_combined_v2_param_4,
	.param .u32 batch_fitness_combined_v2_param_5,
	.param .u64 .ptr .align 1 batch_fitness_combined_v2_param_6,
	.param .u64 .ptr .align 1 batch_fitness_combined_v2_param_7,
	.param .u64 .ptr .align 1 batch_fitness_combined_v2_param_8,
	.param .u64 .ptr .align 1 batch_fitness_combined_v2_param_9
)
.maxntid 256
.minnctapersm 2
{
	.local .align 16 .b8 	__local_depot2[80];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<134>;
	.reg .b32 	%r<439>;
	.reg .b64 	%rd<48>;
	// demoted variable
	.shared .align 4 .b8 _ZZ25batch_fitness_combined_v2E16smem_warp_escape[320];
	// demoted variable
	.shared .align 4 .b8 _ZZ25batch_fitness_combined_v2E17smem_final_escape[40];
	mov.b64 	%SPL, __local_depot2;
	ld.param.b64 	%rd5, [batch_fitness_combined_v2_param_0];
	ld.param.b64 	%rd6, [batch_fitness_combined_v2_param_2];
	ld.param.b64 	%rd7, [batch_fitness_combined_v2_param_3];
	ld.param.b64 	%rd8, [batch_fitness_combined_v2_param_4];
	ld.param.b32 	%r94, [batch_fitness_combined_v2_param_5];
	ld.param.b64 	%rd9, [batch_fitness_combined_v2_param_6];
	ld.param.b64 	%rd10, [batch_fitness_combined_v2_param_7];
	ld.param.b64 	%rd11, [batch_fitness_combined_v2_param_8];
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r1, %ctaid.x;
	setp.ge.s32 	%p1, %r1, %r94;
	@%p1 bra 	$L__BB2_55;
	cvta.to.global.u64 	%rd13, %rd6;
	mov.u32 	%r2, %tid.x;
	and.b32 	%r3, %r2, 31;
	mul.wide.u32 	%rd14, %r1, 4;
	add.s64 	%rd15, %rd13, %rd14;
	ld.global.nc.b32 	%r4, [%rd15];
	st.local.v4.b32 	[%rd1], {0f00000000, 0f00000000, 0f00000000, 0f00000000};
	st.local.v4.b32 	[%rd1+16], {0f00000000, 0f00000000, 0f00000000, 0f00000000};
	st.local.v4.b32 	[%rd1+32], {0f00000000, 0f00000000, 0f00000000, 0f00000000};
	st.local.v4.b32 	[%rd1+48], {0f00000000, 0f00000000, 0f00000000, 0f00000000};
	st.local.v4.b32 	[%rd1+64], {0f00000000, 0f00000000, 0f00000000, 0f00000000};
	setp.ge.s32 	%p2, %r2, %r4;
	mov.b32 	%r410, 0f00000000;
	mov.b32 	%r411, %r410;
	mov.b32 	%r412, %r410;
	mov.b32 	%r413, %r410;
	mov.b32 	%r414, %r410;
	mov.b32 	%r415, %r410;
	mov.b32 	%r416, %r410;
	mov.b32 	%r417, %r410;
	mov.b32 	%r418, %r410;
	mov.b32 	%r419, %r410;
	mov.b32 	%r420, %r410;
	mov.b32 	%r421, %r410;
	mov.b32 	%r422, %r410;
	mov.b32 	%r423, %r410;
	mov.b32 	%r424, %r410;
	mov.b32 	%r425, %r410;
	mov.b32 	%r426, %r410;
	mov.b32 	%r427, %r410;
	mov.b32 	%r428, %r410;
	@%p2 bra 	$L__BB2_8;
	mov.u32 	%r5, %ntid.x;
	cvta.to.global.u64 	%rd2, %rd5;
	mul.lo.s32 	%r6, %r1, 50;
	mov.b32 	%r407, %r2;
$L__BB2_3:
	add.s32 	%r96, %r407, %r6;
	mul.wide.s32 	%rd16, %r96, 4;
	add.s64 	%rd17, %rd2, %rd16;
	ld.global.nc.b32 	%r8, [%rd17];
	add.s32 	%r97, %r8, -532;
	setp.lt.u32 	%p3, %r97, -201;
	@%p3 bra 	$L__BB2_6;
	mov.b64 	%rd19, c_antibody_epitopes;
	add.s64 	%rd47, %rd19, 8;
	add.s32 	%r408, %r8, 272;
	mov.b32 	%r409, 272;
$L__BB2_5:
	add.s32 	%r99, %r408, -603;
	mul.wide.u32 	%rd20, %r99, 4;
	mov.b64 	%rd21, c_escape_matrix;
	add.s64 	%rd22, %rd21, %rd20;
	ld.const.b32 	%r100, [%rd22];
	ld.const.b32 	%r101, [%rd47+-8];
	mul.wide.s32 	%rd23, %r101, 8;
	add.s64 	%rd24, %rd1, %rd23;
	ld.local.v2.b32 	{%r102, %r103}, [%rd24];
	add.ftz.f32 	%r104, %r100, %r102;
	abs.ftz.f32 	%r105, %r102;
	abs.ftz.f32 	%r106, %r100;
	setp.ltu.ftz.f32 	%p4, %r105, %r106;
	selp.f32 	%r107, %r102, %r100, %p4;
	selp.f32 	%r108, %r100, %r102, %p4;
	sub.ftz.f32 	%r109, %r108, %r104;
	add.ftz.f32 	%r110, %r107, %r109;
	add.ftz.f32 	%r111, %r103, %r110;
	st.local.v2.b32 	[%rd24], {%r104, %r111};
	add.s32 	%r112, %r408, -402;
	mul.wide.u32 	%rd25, %r112, 4;
	add.s64 	%rd26, %rd21, %rd25;
	ld.const.b32 	%r113, [%rd26];
	ld.const.b32 	%r114, [%rd47+-4];
	mul.wide.s32 	%rd27, %r114, 8;
	add.s64 	%rd28, %rd1, %rd27;
	ld.local.v2.b32 	{%r115, %r116}, [%rd28];
	add.ftz.f32 	%r117, %r113, %r115;
	abs.ftz.f32 	%r118, %r115;
	abs.ftz.f32 	%r119, %r113;
	setp.ltu.ftz.f32 	%p5, %r118, %r119;
	selp.f32 	%r120, %r115, %r113, %p5;
	selp.f32 	%r121, %r113, %r115, %p5;
	sub.ftz.f32 	%r122, %r121, %r117;
	add.ftz.f32 	%r123, %r120, %r122;
	add.ftz.f32 	%r124, %r116, %r123;
	st.local.v2.b32 	[%rd28], {%r117, %r124};
	add.s32 	%r125, %r408, -201;
	mul.wide.u32 	%rd29, %r125, 4;
	add.s64 	%rd30, %rd21, %rd29;
	ld.const.b32 	%r126, [%rd30];
	ld.const.b32 	%r127, [%rd47];
	mul.wide.s32 	%rd31, %r127, 8;
	add.s64 	%rd32, %rd1, %rd31;
	ld.local.v2.b32 	{%r128, %r129}, [%rd32];
	add.ftz.f32 	%r130, %r126, %r128;
	abs.ftz.f32 	%r131, %r128;
	abs.ftz.f32 	%r132, %r126;
	setp.ltu.ftz.f32 	%p6, %r131, %r132;
	selp.f32 	%r133, %r128, %r126, %p6;
	selp.f32 	%r134, %r126, %r128, %p6;
	sub.ftz.f32 	%r135, %r134, %r130;
	add.ftz.f32 	%r136, %r133, %r135;
	add.ftz.f32 	%r137, %r129, %r136;
	st.local.v2.b32 	[%rd32], {%r130, %r137};
	mul.wide.u32 	%rd33, %r408, 4;
	add.s64 	%rd34, %rd21, %rd33;
	ld.const.b32 	%r138, [%rd34];
	ld.const.b32 	%r139, [%rd47+4];
	mul.wide.s32 	%rd35, %r139, 8;
	add.s64 	%rd36, %rd1, %rd35;
	ld.local.v2.b32 	{%r140, %r141}, [%rd36];
	add.ftz.f32 	%r142, %r138, %r140;
	abs.ftz.f32 	%r143, %r140;
	abs.ftz.f32 	%r144, %r138;
	setp.ltu.ftz.f32 	%p7, %r143, %r144;
	selp.f32 	%r145, %r140, %r138, %p7;
	selp.f32 	%r146, %r138, %r140, %p7;
	sub.ftz.f32 	%r147, %r146, %r142;
	add.ftz.f32 	%r148, %r145, %r147;
	add.ftz.f32 	%r149, %r141, %r148;
	st.local.v2.b32 	[%rd36], {%r142, %r149};
	add.s32 	%r409, %r409, 804;
	add.s64 	%rd47, %rd47, 16;
	add.s32 	%r408, %r408, 804;
	setp.ne.s32 	%p8, %r409, 168308;
	@%p8 bra 	$L__BB2_5;
$L__BB2_6:
	add.s32 	%r407, %r407, %r5;
	setp.lt.s32 	%p9, %r407, %r4;
	@%p9 bra 	$L__BB2_3;
	ld.local.v4.b32 	{%r150, %r151, %r427, %r426}, [%rd1];
	ld.local.v4.b32 	{%r425, %r424, %r423, %r422}, [%rd1+16];
	ld.local.v4.b32 	{%r421, %r420, %r419, %r418}, [%rd1+32];
	ld.local.v4.b32 	{%r417, %r416, %r415, %r414}, [%rd1+48];
	ld.local.v4.b32 	{%r413, %r412, %r411, %r410}, [%rd1+64];
	add.ftz.f32 	%r428, %r150, %r151;
$L__BB2_8:
	shfl.sync.bfly.b32 	%r152|%p10, %r428, 16, 31, -1;
	add.ftz.f32 	%r153, %r428, %r152;
	shfl.sync.bfly.b32 	%r154|%p11, %r153, 8, 31, -1;
	add.ftz.f32 	%r155, %r153, %r154;
	shfl.sync.bfly.b32 	%r156|%p12, %r155, 4, 31, -1;
	add.ftz.f32 	%r157, %r155, %r156;
	shfl.sync.bfly.b32 	%r158|%p13, %r157, 2, 31, -1;
	add.ftz.f32 	%r159, %r157, %r158;
	shfl.sync.bfly.b32 	%r160|%p14, %r159, 1, 31, -1;
	add.ftz.f32 	%r53, %r159, %r160;
	add.ftz.f32 	%r161, %r427, %r426;
	shfl.sync.bfly.b32 	%r162|%p15, %r161, 16, 31, -1;
	add.ftz.f32 	%r163, %r161, %r162;
	shfl.sync.bfly.b32 	%r164|%p16, %r163, 8, 31, -1;
	add.ftz.f32 	%r165, %r163, %r164;
	shfl.sync.bfly.b32 	%r166|%p17, %r165, 4, 31, -1;
	add.ftz.f32 	%r167, %r165, %r166;
	shfl.sync.bfly.b32 	%r168|%p18, %r167, 2, 31, -1;
	add.ftz.f32 	%r169, %r167, %r168;
	shfl.sync.bfly.b32 	%r170|%p19, %r169, 1, 31, -1;
	add.ftz.f32 	%r54, %r169, %r170;
	add.ftz.f32 	%r171, %r425, %r424;
	shfl.sync.bfly.b32 	%r172|%p20, %r171, 16, 31, -1;
	add.ftz.f32 	%r173, %r171, %r172;
	shfl.sync.bfly.b32 	%r174|%p21, %r173, 8, 31, -1;
	add.ftz.f32 	%r175, %r173, %r174;
	shfl.sync.bfly.b32 	%r176|%p22, %r175, 4, 31, -1;
	add.ftz.f32 	%r177, %r175, %r176;
	shfl.sync.bfly.b32 	%r178|%p23, %r177, 2, 31, -1;
	add.ftz.f32 	%r179, %r177, %r178;
	shfl.sync.bfly.b32 	%r180|%p24, %r179, 1, 31, -1;
	add.ftz.f32 	%r55, %r179, %r180;
	add.ftz.f32 	%r181, %r423, %r422;
	shfl.sync.bfly.b32 	%r182|%p25, %r181, 16, 31, -1;
	add.ftz.f32 	%r183, %r181, %r182;
	shfl.sync.bfly.b32 	%r184|%p26, %r183, 8, 31, -1;
	add.ftz.f32 	%r185, %r183, %r184;
	shfl.sync.bfly.b32 	%r186|%p27, %r185, 4, 31, -1;
	add.ftz.f32 	%r187, %r185, %r186;
	shfl.sync.bfly.b32 	%r188|%p28, %r187, 2, 31, -1;
	add.ftz.f32 	%r189, %r187, %r188;
	shfl.sync.bfly.b32 	%r190|%p29, %r189, 1, 31, -1;
	add.ftz.f32 	%r56, %r189, %r190;
	add.ftz.f32 	%r191, %r421, %r420;
	shfl.sync.bfly.b32 	%r192|%p30, %r191, 16, 31, -1;
	add.ftz.f32 	%r193, %r191, %r192;
	shfl.sync.bfly.b32 	%r194|%p31, %r193, 8, 31, -1;
	add.ftz.f32 	%r195, %r193, %r194;
	shfl.sync.bfly.b32 	%r196|%p32, %r195, 4, 31, -1;
	add.ftz.f32 	%r197, %r195, %r196;
	shfl.sync.bfly.b32 	%r198|%p33, %r197, 2, 31, -1;
	add.ftz.f32 	%r199, %r197, %r198;
	shfl.sync.bfly.b32 	%r200|%p34, %r199, 1, 31, -1;
	add.ftz.f32 	%r57, %r199, %r200;
	add.ftz.f32 	%r201, %r419, %r418;
	shfl.sync.bfly.b32 	%r202|%p35, %r201, 16, 31, -1;
	add.ftz.f32 	%r203, %r201, %r202;
	shfl.sync.bfly.b32 	%r204|%p36, %r203, 8, 31, -1;
	add.ftz.f32 	%r205, %r203, %r204;
	shfl.sync.bfly.b32 	%r206|%p37, %r205, 4, 31, -1;
	add.ftz.f32 	%r207, %r205, %r206;
	shfl.sync.bfly.b32 	%r208|%p38, %r207, 2, 31, -1;
	add.ftz.f32 	%r209, %r207, %r208;
	shfl.sync.bfly.b32 	%r210|%p39, %r209, 1, 31, -1;
	add.ftz.f32 	%r58, %r209, %r210;
	add.ftz.f32 	%r211, %r417, %r416;
	shfl.sync.bfly.b32 	%r212|%p40, %r211, 16, 31, -1;
	add.ftz.f32 	%r213, %r211, %r212;
	shfl.sync.bfly.b32 	%r214|%p41, %r213, 8, 31, -1;
	add.ftz.f32 	%r215, %r213, %r214;
	shfl.sync.bfly.b32 	%r216|%p42, %r215, 4, 31, -1;
	add.ftz.f32 	%r217, %r215, %r216;
	shfl.sync.bfly.b32 	%r218|%p43, %r217, 2, 31, -1;
	add.ftz.f32 	%r219, %r217, %r218;
	shfl.sync.bfly.b32 	%r220|%p44, %r219, 1, 31, -1;
	add.ftz.f32 	%r59, %r219, %r220;
	add.ftz.f32 	%r221, %r415, %r414;
	shfl.sync.bfly.b32 	%r222|%p45, %r221, 16, 31, -1;
	add.ftz.f32 	%r223, %r221, %r222;
	shfl.sync.bfly.b32 	%r224|%p46, %r223, 8, 31, -1;
	add.ftz.f32 	%r225, %r223, %r224;
	shfl.sync.bfly.b32 	%r226|%p47, %r225, 4, 31, -1;
	add.ftz.f32 	%r227, %r225, %r226;
	shfl.sync.bfly.b32 	%r228|%p48, %r227, 2, 31, -1;
	add.ftz.f32 	%r229, %r227, %r228;
	shfl.sync.bfly.b32 	%r230|%p49, %r229, 1, 31, -1;
	add.ftz.f32 	%r60, %r229, %r230;
	add.ftz.f32 	%r231, %r413, %r412;
	shfl.sync.bfly.b32 	%r232|%p50, %r231, 16, 31, -1;
	add.ftz.f32 	%r233, %r231, %r232;
	shfl.sync.bfly.b32 	%r234|%p51, %r233, 8, 31, -1;
	add.ftz.f32 	%r235, %r233, %r234;
	shfl.sync.bfly.b32 	%r236|%p52, %r235, 4, 31, -1;
	add.ftz.f32 	%r237, %r235, %r236;
	shfl.sync.bfly.b32 	%r238|%p53, %r237, 2, 31, -1;
	add.ftz.f32 	%r239, %r237, %r238;
	shfl.sync.bfly.b32 	%r240|%p54, %r239, 1, 31, -1;
	add.ftz.f32 	%r61, %r239, %r240;
	add.ftz.f32 	%r241, %r411, %r410;
	shfl.sync.bfly.b32 	%r242|%p55, %r241, 16, 31, -1;
	add.ftz.f32 	%r243, %r241, %r242;
	shfl.sync.bfly.b32 	%r244|%p56, %r243, 8, 31, -1;
	add.ftz.f32 	%r245, %r243, %r244;
	shfl.sync.bfly.b32 	%r246|%p57, %r245, 4, 31, -1;
	add.ftz.f32 	%r247, %r245, %r246;
	shfl.sync.bfly.b32 	%r248|%p58, %r247, 2, 31, -1;
	add.ftz.f32 	%r249, %r247, %r248;
	shfl.sync.bfly.b32 	%r250|%p59, %r249, 1, 31, -1;
	add.ftz.f32 	%r62, %r249, %r250;
	setp.ne.s32 	%p60, %r3, 0;
	@%p60 bra 	$L__BB2_10;
	shr.u32 	%r251, %r2, 3;
	and.b32 	%r252, %r251, 28;
	mov.b32 	%r253, _ZZ25batch_fitness_combined_v2E16smem_warp_escape;
	add.s32 	%r254, %r253, %r252;
	st.shared.b32 	[%r254], %r53;
	st.shared.b32 	[%r254+32], %r54;
	st.shared.b32 	[%r254+64], %r55;
	st.shared.b32 	[%r254+96], %r56;
	st.shared.b32 	[%r254+128], %r57;
	st.shared.b32 	[%r254+160], %r58;
	st.shared.b32 	[%r254+192], %r59;
	st.shared.b32 	[%r254+224], %r60;
	st.shared.b32 	[%r254+256], %r61;
	st.shared.b32 	[%r254+288], %r62;
$L__BB2_10:
	bar.sync 	0;
	setp.gt.u32 	%p61, %r2, 31;
	@%p61 bra 	$L__BB2_51;
	setp.gt.u32 	%p62, %r3, 7;
	shl.b32 	%r256, %r3, 2;
	mov.b32 	%r257, _ZZ25batch_fitness_combined_v2E16smem_warp_escape;
	add.s32 	%r63, %r257, %r256;
	mov.b32 	%r429, 0f00000000;
	@%p62 bra 	$L__BB2_13;
	ld.shared.b32 	%r429, [%r63];
$L__BB2_13:
	setp.ne.s32 	%p63, %r3, 0;
	shfl.sync.bfly.b32 	%r258|%p64, %r429, 16, 31, -1;
	add.ftz.f32 	%r259, %r429, %r258;
	shfl.sync.bfly.b32 	%r260|%p65, %r259, 8, 31, -1;
	add.ftz.f32 	%r261, %r259, %r260;
	shfl.sync.bfly.b32 	%r262|%p66, %r261, 4, 31, -1;
	add.ftz.f32 	%r263, %r261, %r262;
	shfl.sync.bfly.b32 	%r264|%p67, %r263, 2, 31, -1;
	add.ftz.f32 	%r265, %r263, %r264;
	shfl.sync.bfly.b32 	%r266|%p68, %r265, 1, 31, -1;
	add.ftz.f32 	%r66, %r265, %r266;
	@%p63 bra 	$L__BB2_15;
	st.shared.b32 	[_ZZ25batch_fitness_combined_v2E17smem_final_escape], %r66;
$L__BB2_15:
	setp.gt.u32 	%p69, %r3, 7;
	mov.b32 	%r430, 0f00000000;
	@%p69 bra 	$L__BB2_17;
	ld.shared.b32 	%r430, [%r63+32];
$L__BB2_17:
	setp.ne.s32 	%p70, %r3, 0;
	shfl.sync.bfly.b32 	%r268|%p71, %r430, 16, 31, -1;
	add.ftz.f32 	%r269, %r430, %r268;
	shfl.sync.bfly.b32 	%r270|%p72, %r269, 8, 31, -1;
	add.ftz.f32 	%r271, %r269, %r270;
	shfl.sync.bfly.b32 	%r272|%p73, %r271, 4, 31, -1;
	add.ftz.f32 	%r273, %r271, %r272;
	shfl.sync.bfly.b32 	%r274|%p74, %r273, 2, 31, -1;
	add.ftz.f32 	%r275, %r273, %r274;
	shfl.sync.bfly.b32 	%r276|%p75, %r275, 1, 31, -1;
	add.ftz.f32 	%r69, %r275, %r276;
	@%p70 bra 	$L__BB2_19;
	st.shared.b32 	[_ZZ25batch_fitness_combined_v2E17smem_final_escape+4], %r69;
$L__BB2_19:
	setp.gt.u32 	%p76, %r3, 7;
	mov.b32 	%r431, 0f00000000;
	@%p76 bra 	$L__BB2_21;
	ld.shared.b32 	%r431, [%r63+64];
$L__BB2_21:
	setp.ne.s32 	%p77, %r3, 0;
	shfl.sync.bfly.b32 	%r278|%p78, %r431, 16, 31, -1;
	add.ftz.f32 	%r279, %r431, %r278;
	shfl.sync.bfly.b32 	%r280|%p79, %r279, 8, 31, -1;
	add.ftz.f32 	%r281, %r279, %r280;
	shfl.sync.bfly.b32 	%r282|%p80, %r281, 4, 31, -1;
	add.ftz.f32 	%r283, %r281, %r282;
	shfl.sync.bfly.b32 	%r284|%p81, %r283, 2, 31, -1;
	add.ftz.f32 	%r285, %r283, %r284;
	shfl.sync.bfly.b32 	%r286|%p82, %r285, 1, 31, -1;
	add.ftz.f32 	%r72, %r285, %r286;
	@%p77 bra 	$L__BB2_23;
	st.shared.b32 	[_ZZ25batch_fitness_combined_v2E17smem_final_escape+8], %r72;
$L__BB2_23:
	setp.gt.u32 	%p83, %r3, 7;
	mov.b32 	%r432, 0f00000000;
	@%p83 bra 	$L__BB2_25;
	ld.shared.b32 	%r432, [%r63+96];
$L__BB2_25:
	setp.ne.s32 	%p84, %r3, 0;
	shfl.sync.bfly.b32 	%r288|%p85, %r432, 16, 31, -1;
	add.ftz.f32 	%r289, %r432, %r288;
	shfl.sync.bfly.b32 	%r290|%p86, %r289, 8, 31, -1;
	add.ftz.f32 	%r291, %r289, %r290;
	shfl.sync.bfly.b32 	%r292|%p87, %r291, 4, 31, -1;
	add.ftz.f32 	%r293, %r291, %r292;
	shfl.sync.bfly.b32 	%r294|%p88, %r293, 2, 31, -1;
	add.ftz.f32 	%r295, %r293, %r294;
	shfl.sync.bfly.b32 	%r296|%p89, %r295, 1, 31, -1;
	add.ftz.f32 	%r75, %r295, %r296;
	@%p84 bra 	$L__BB2_27;
	st.shared.b32 	[_ZZ25batch_fitness_combined_v2E17smem_final_escape+12], %r75;
$L__BB2_27:
	setp.gt.u32 	%p90, %r3, 7;
	mov.b32 	%r433, 0f00000000;
	@%p90 bra 	$L__BB2_29;
	ld.shared.b32 	%r433, [%r63+128];
$L__BB2_29:
	setp.ne.s32 	%p91, %r3, 0;
	shfl.sync.bfly.b32 	%r298|%p92, %r433, 16, 31, -1;
	add.ftz.f32 	%r299, %r433, %r298;
	shfl.sync.bfly.b32 	%r300|%p93, %r299, 8, 31, -1;
	add.ftz.f32 	%r301, %r299, %r300;
	shfl.sync.bfly.b32 	%r302|%p94, %r301, 4, 31, -1;
	add.ftz.f32 	%r303, %r301, %r302;
	shfl.sync.bfly.b32 	%r304|%p95, %r303, 2, 31, -1;
	add.ftz.f32 	%r305, %r303, %r304;
	shfl.sync.bfly.b32 	%r306|%p96, %r305, 1, 31, -1;
	add.ftz.f32 	%r78, %r305, %r306;
	@%p91 bra 	$L__BB2_31;
	st.shared.b32 	[_ZZ25batch_fitness_combined_v2E17smem_final_escape+16], %r78;
$L__BB2_31:
	setp.gt.u32 	%p97, %r3, 7;
	mov.b32 	%r434, 0f00000000;
	@%p97 bra 	$L__BB2_33;
	ld.shared.b32 	%r434, [%r63+160];
$L__BB2_33:
	setp.ne.s32 	%p98, %r3, 0;
	shfl.sync.bfly.b32 	%r308|%p99, %r434, 16, 31, -1;
	add.ftz.f32 	%r309, %r434, %r308;
	shfl.sync.bfly.b32 	%r310|%p100, %r309, 8, 31, -1;
	add.ftz.f32 	%r311, %r309, %r310;
	shfl.sync.bfly.b32 	%r312|%p101, %r311, 4, 31, -1;
	add.ftz.f32 	%r313, %r311, %r312;
	shfl.sync.bfly.b32 	%r314|%p102, %r313, 2, 31, -1;
	add.ftz.f32 	%r315, %r313, %r314;
	shfl.sync.bfly.b32 	%r316|%p103, %r315, 1, 31, -1;
	add.ftz.f32 	%r81, %r315, %r316;
	@%p98 bra 	$L__BB2_35;
	st.shared.b32 	[_ZZ25batch_fitness_combined_v2E17smem_final_escape+20], %r81;
$L__BB2_35:
	setp.gt.u32 	%p104, %r3, 7;
	mov.b32 	%r435, 0f00000000;
	@%p104 bra 	$L__BB2_37;
	ld.shared.b32 	%r435, [%r63+192];
$L__BB2_37:
	setp.ne.s32 	%p105, %r3, 0;
	shfl.sync.bfly.b32 	%r318|%p106, %r435, 16, 31, -1;
	add.ftz.f32 	%r319, %r435, %r318;
	shfl.sync.bfly.b32 	%r320|%p107, %r319, 8, 31, -1;
	add.ftz.f32 	%r321, %r319, %r320;
	shfl.sync.bfly.b32 	%r322|%p108, %r321, 4, 31, -1;
	add.ftz.f32 	%r323, %r321, %r322;
	shfl.sync.bfly.b32 	%r324|%p109, %r323, 2, 31, -1;
	add.ftz.f32 	%r325, %r323, %r324;
	shfl.sync.bfly.b32 	%r326|%p110, %r325, 1, 31, -1;
	add.ftz.f32 	%r84, %r325, %r326;
	@%p105 bra 	$L__BB2_39;
	st.shared.b32 	[_ZZ25batch_fitness_combined_v2E17smem_final_escape+24], %r84;
$L__BB2_39:
	setp.gt.u32 	%p111, %r3, 7;
	mov.b32 	%r436, 0f00000000;
	@%p111 bra 	$L__BB2_41;
	ld.shared.b32 	%r436, [%r63+224];
$L__BB2_41:
	setp.ne.s32 	%p112, %r3, 0;
	shfl.sync.bfly.b32 	%r328|%p113, %r436, 16, 31, -1;
	add.ftz.f32 	%r329, %r436, %r328;
	shfl.sync.bfly.b32 	%r330|%p114, %r329, 8, 31, -1;
	add.ftz.f32 	%r331, %r329, %r330;
	shfl.sync.bfly.b32 	%r332|%p115, %r331, 4, 31, -1;
	add.ftz.f32 	%r333, %r331, %r332;
	shfl.sync.bfly.b32 	%r334|%p116, %r333, 2, 31, -1;
	add.ftz.f32 	%r335, %r333, %r334;
	shfl.sync.bfly.b32 	%r336|%p117, %r335, 1, 31, -1;
	add.ftz.f32 	%r87, %r335, %r336;
	@%p112 bra 	$L__BB2_43;
	st.shared.b32 	[_ZZ25batch_fitness_combined_v2E17smem_final_escape+28], %r87;
$L__BB2_43:
	setp.gt.u32 	%p118, %r3, 7;
	mov.b32 	%r437, 0f00000000;
	@%p118 bra 	$L__BB2_45;
	ld.shared.b32 	%r437, [%r63+256];
$L__BB2_45:
	setp.ne.s32 	%p119, %r3, 0;
	shfl.sync.bfly.b32 	%r338|%p120, %r437, 16, 31, -1;
	add.ftz.f32 	%r339, %r437, %r338;
	shfl.sync.bfly.b32 	%r340|%p121, %r339, 8, 31, -1;
	add.ftz.f32 	%r341, %r339, %r340;
	shfl.sync.bfly.b32 	%r342|%p122, %r341, 4, 31, -1;
	add.ftz.f32 	%r343, %r341, %r342;
	shfl.sync.bfly.b32 	%r344|%p123, %r343, 2, 31, -1;
	add.ftz.f32 	%r345, %r343, %r344;
	shfl.sync.bfly.b32 	%r346|%p124, %r345, 1, 31, -1;
	add.ftz.f32 	%r90, %r345, %r346;
	@%p119 bra 	$L__BB2_47;
	st.shared.b32 	[_ZZ25batch_fitness_combined_v2E17smem_final_escape+32], %r90;
$L__BB2_47:
	setp.gt.u32 	%p125, %r3, 7;
	mov.b32 	%r438, 0f00000000;
	@%p125 bra 	$L__BB2_49;
	ld.shared.b32 	%r438, [%r63+288];
$L__BB2_49:
	setp.ne.s32 	%p126, %r3, 0;
	shfl.sync.bfly.b32 	%r348|%p127, %r438, 16, 31, -1;
	add.ftz.f32 	%r349, %r438, %r348;
	shfl.sync.bfly.b32 	%r350|%p128, %r349, 8, 31, -1;
	add.ftz.f32 	%r351, %r349, %r350;
	shfl.sync.bfly.b32 	%r352|%p129, %r351, 4, 31, -1;
	add.ftz.f32 	%r353, %r351, %r352;
	shfl.sync.bfly.b32 	%r354|%p130, %r353, 2, 31, -1;
	add.ftz.f32 	%r355, %r353, %r354;
	shfl.sync.bfly.b32 	%r356|%p131, %r355, 1, 31, -1;
	add.ftz.f32 	%r93, %r355, %r356;
	@%p126 bra 	$L__BB2_51;
	st.shared.b32 	[_ZZ25batch_fitness_combined_v2E17smem_final_escape+36], %r93;
$L__BB2_51:
	bar.sync 	0;
	setp.ne.s32 	%p132, %r2, 0;
	@%p132 bra 	$L__BB2_53;
	cvta.to.global.u64 	%rd37, %rd7;
	cvta.to.global.u64 	%rd38, %rd9;
	ld.shared.b32 	%r357, [_ZZ25batch_fitness_combined_v2E17smem_final_escape];
	ld.global.nc.b32 	%r358, [%rd37];
	fma.rn.ftz.f32 	%r359, %r357, %r358, 0f00000000;
	ld.shared.b32 	%r360, [_ZZ25batch_fitness_combined_v2E17smem_final_escape+4];
	ld.global.nc.b32 	%r361, [%rd37+4];
	fma.rn.ftz.f32 	%r362, %r360, %r361, %r359;
	ld.shared.b32 	%r363, [_ZZ25batch_fitness_combined_v2E17smem_final_escape+8];
	ld.global.nc.b32 	%r364, [%rd37+8];
	fma.rn.ftz.f32 	%r365, %r363, %r364, %r362;
	ld.shared.b32 	%r366, [_ZZ25batch_fitness_combined_v2E17smem_final_escape+12];
	ld.global.nc.b32 	%r367, [%rd37+12];
	fma.rn.ftz.f32 	%r368, %r366, %r367, %r365;
	ld.shared.b32 	%r369, [_ZZ25batch_fitness_combined_v2E17smem_final_escape+16];
	ld.global.nc.b32 	%r370, [%rd37+16];
	fma.rn.ftz.f32 	%r371, %r369, %r370, %r368;
	ld.shared.b32 	%r372, [_ZZ25batch_fitness_combined_v2E17smem_final_escape+20];
	ld.global.nc.b32 	%r373, [%rd37+20];
	fma.rn.ftz.f32 	%r374, %r372, %r373, %r371;
	ld.shared.b32 	%r375, [_ZZ25batch_fitness_combined_v2E17smem_final_escape+24];
	ld.global.nc.b32 	%r376, [%rd37+24];
	fma.rn.ftz.f32 	%r377, %r375, %r376, %r374;
	ld.shared.b32 	%r378, [_ZZ25batch_fitness_combined_v2E17smem_final_escape+28];
	ld.global.nc.b32 	%r379, [%rd37+28];
	fma.rn.ftz.f32 	%r380, %r378, %r379, %r377;
	ld.shared.b32 	%r381, [_ZZ25batch_fitness_combined_v2E17smem_final_escape+32];
	ld.global.nc.b32 	%r382, [%rd37+32];
	fma.rn.ftz.f32 	%r383, %r381, %r382, %r380;
	ld.shared.b32 	%r384, [_ZZ25batch_fitness_combined_v2E17smem_final_escape+36];
	ld.global.nc.b32 	%r385, [%rd37+36];
	fma.rn.ftz.f32 	%r386, %r384, %r385, %r383;
	ld.global.nc.b32 	%r387, [%rd38];
	mul.ftz.f32 	%r388, %r386, %r387;
	mul.ftz.f32 	%r389, %r388, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%r390, %r389;
	max.ftz.f32 	%r391, %r390, 0f358637BD;
	lg2.approx.ftz.f32 	%r392, %r391;
	mul.ftz.f32 	%r393, %r392, 0fBF317218;
	cvta.to.global.u64 	%rd39, %rd8;
	mul.wide.u32 	%rd40, %r1, 4;
	add.s64 	%rd41, %rd39, %rd40;
	ld.global.nc.b32 	%r394, [%rd41];
	ld.global.nc.b32 	%r395, [%rd38+92];
	ld.global.nc.b32 	%r396, [%rd38+96];
	ld.global.nc.b32 	%r397, [%rd38+56];
	div.approx.ftz.f32 	%r398, %r394, %r397;
	mul.ftz.f32 	%r399, %r396, %r398;
	mul.ftz.f32 	%r400, %r399, 0f3F4CCCCD;
	fma.rn.ftz.f32 	%r401, %r395, %r393, %r400;
	cvta.to.global.u64 	%rd42, %rd10;
	add.s64 	%rd43, %rd42, %rd40;
	st.global.b32 	[%rd43], %r401;
$L__BB2_53:
	setp.gt.u32 	%p133, %r2, 9;
	@%p133 bra 	$L__BB2_55;
	shl.b32 	%r402, %r2, 2;
	mov.b32 	%r403, _ZZ25batch_fitness_combined_v2E17smem_final_escape;
	add.s32 	%r404, %r403, %r402;
	ld.shared.b32 	%r405, [%r404];
	mad.lo.s32 	%r406, %r1, 10, %r2;
	cvta.to.global.u64 	%rd44, %rd11;
	mul.wide.u32 	%rd45, %r406, 4;
	add.s64 	%rd46, %rd44, %rd45;
	st.global.b32 	[%rd46], %r405;
$L__BB2_55:
	ret;

}
	// .globl	temporal_fitness_integration
.visible .entry temporal_fitness_integration(
	.param .u64 .ptr .align 1 temporal_fitness_integration_param_0,
	.param .u64 .ptr .align 1 temporal_fitness_integration_param_1,
	.param .u32 temporal_fitness_integration_param_2,
	.param .u32 temporal_fitness_integration_param_3,
	.param .f32 temporal_fitness_integration_param_4,
	.param .u64 .ptr .align 1 temporal_fitness_integration_param_5
)
.maxntid 256
.minnctapersm 4
{
	.reg .pred 	%p<12>;
	.reg .b32 	%r<133>;
	.reg .b64 	%rd<17>;

	ld.param.b64 	%rd6, [temporal_fitness_integration_param_0];
	ld.param.b64 	%rd7, [temporal_fitness_integration_param_1];
	ld.param.b32 	%r35, [temporal_fitness_integration_param_2];
	ld.param.b32 	%r33, [temporal_fitness_integration_param_3];
	ld.param.b32 	%r34, [temporal_fitness_integration_param_4];
	ld.param.b64 	%rd5, [temporal_fitness_integration_param_5];
	cvta.to.global.u64 	%rd1, %rd7;
	cvta.to.global.u64 	%rd2, %rd6;
	mov.u32 	%r36, %ctaid.x;
	mov.u32 	%r37, %ntid.x;
	mov.u32 	%r38, %tid.x;
	mad.lo.s32 	%r1, %r36, %r37, %r38;
	setp.ge.s32 	%p1, %r1, %r35;
	@%p1 bra 	$L__BB3_10;
	mul.lo.s32 	%r2, %r33, %r1;
	setp.lt.s32 	%p2, %r33, 1;
	mov.b32 	%r132, 0f00000000;
	@%p2 bra 	$L__BB3_9;
	and.b32 	%r3, %r33, 3;
	setp.lt.u32 	%p3, %r33, 4;
	mov.b32 	%r121, 0f00000000;
	mov.b32 	%r123, 0;
	mov.b32 	%r131, %r121;
	@%p3 bra 	$L__BB3_5;
	and.b32 	%r123, %r33, 2147483644;
	neg.s32 	%r118, %r123;
	add.s64 	%rd3, %rd2, 8;
	add.s64 	%rd4, %rd1, 8;
	mov.b32 	%r121, 0f00000000;
	mov.b32 	%r117, %r2;
$L__BB3_4:
	.pragma "nounroll";
	mul.wide.s32 	%rd8, %r117, 4;
	add.s64 	%rd9, %rd3, %rd8;
	add.s64 	%rd10, %rd4, %rd8;
	ld.global.nc.b32 	%r44, [%rd9+-8];
	ld.global.nc.b32 	%r45, [%rd10+-8];
	mul.ftz.f32 	%r46, %r44, %r45;
	mov.b32 	%r47, 0f3F800000;
	sub.ftz.f32 	%r48, %r47, %r45;
	mul.ftz.f32 	%r49, %r46, %r48;
	mul.ftz.f32 	%r50, %r34, %r49;
	add.ftz.f32 	%r51, %r121, %r50;
	abs.ftz.f32 	%r52, %r121;
	abs.ftz.f32 	%r53, %r50;
	setp.ltu.ftz.f32 	%p4, %r52, %r53;
	sub.ftz.f32 	%r54, %r50, %r51;
	add.ftz.f32 	%r55, %r121, %r54;
	sub.ftz.f32 	%r56, %r121, %r51;
	add.ftz.f32 	%r57, %r50, %r56;
	selp.f32 	%r58, %r55, %r57, %p4;
	add.ftz.f32 	%r59, %r131, %r58;
	ld.global.nc.b32 	%r60, [%rd9+-4];
	ld.global.nc.b32 	%r61, [%rd10+-4];
	mul.ftz.f32 	%r62, %r60, %r61;
	sub.ftz.f32 	%r63, %r47, %r61;
	mul.ftz.f32 	%r64, %r62, %r63;
	mul.ftz.f32 	%r65, %r34, %r64;
	add.ftz.f32 	%r66, %r51, %r65;
	abs.ftz.f32 	%r67, %r51;
	abs.ftz.f32 	%r68, %r65;
	setp.ltu.ftz.f32 	%p5, %r67, %r68;
	sub.ftz.f32 	%r69, %r65, %r66;
	add.ftz.f32 	%r70, %r51, %r69;
	sub.ftz.f32 	%r71, %r51, %r66;
	add.ftz.f32 	%r72, %r65, %r71;
	selp.f32 	%r73, %r70, %r72, %p5;
	add.ftz.f32 	%r74, %r59, %r73;
	ld.global.nc.b32 	%r75, [%rd9];
	ld.global.nc.b32 	%r76, [%rd10];
	mul.ftz.f32 	%r77, %r75, %r76;
	sub.ftz.f32 	%r78, %r47, %r76;
	mul.ftz.f32 	%r79, %r77, %r78;
	mul.ftz.f32 	%r80, %r34, %r79;
	add.ftz.f32 	%r81, %r66, %r80;
	abs.ftz.f32 	%r82, %r66;
	abs.ftz.f32 	%r83, %r80;
	setp.ltu.ftz.f32 	%p6, %r82, %r83;
	sub.ftz.f32 	%r84, %r80, %r81;
	add.ftz.f32 	%r85, %r66, %r84;
	sub.ftz.f32 	%r86, %r66, %r81;
	add.ftz.f32 	%r87, %r80, %r86;
	selp.f32 	%r88, %r85, %r87, %p6;
	add.ftz.f32 	%r89, %r74, %r88;
	ld.global.nc.b32 	%r90, [%rd9+4];
	ld.global.nc.b32 	%r91, [%rd10+4];
	mul.ftz.f32 	%r92, %r90, %r91;
	sub.ftz.f32 	%r93, %r47, %r91;
	mul.ftz.f32 	%r94, %r92, %r93;
	mul.ftz.f32 	%r95, %r34, %r94;
	add.ftz.f32 	%r121, %r81, %r95;
	abs.ftz.f32 	%r96, %r81;
	abs.ftz.f32 	%r97, %r95;
	setp.ltu.ftz.f32 	%p7, %r96, %r97;
	sub.ftz.f32 	%r98, %r95, %r121;
	add.ftz.f32 	%r99, %r81, %r98;
	sub.ftz.f32 	%r100, %r81, %r121;
	add.ftz.f32 	%r101, %r95, %r100;
	selp.f32 	%r102, %r99, %r101, %p7;
	add.ftz.f32 	%r131, %r89, %r102;
	add.s32 	%r118, %r118, 4;
	add.s32 	%r117, %r117, 4;
	setp.ne.s32 	%p8, %r118, 0;
	@%p8 bra 	$L__BB3_4;
$L__BB3_5:
	setp.eq.s32 	%p9, %r3, 0;
	@%p9 bra 	$L__BB3_8;
	add.s32 	%r127, %r123, %r2;
	neg.s32 	%r126, %r3;
	mov.b32 	%r128, %r121;
$L__BB3_7:
	.pragma "nounroll";
	mul.wide.s32 	%rd11, %r127, 4;
	add.s64 	%rd12, %rd1, %rd11;
	add.s64 	%rd13, %rd2, %rd11;
	ld.global.nc.b32 	%r103, [%rd13];
	ld.global.nc.b32 	%r104, [%rd12];
	mul.ftz.f32 	%r105, %r103, %r104;
	mov.b32 	%r106, 0f3F800000;
	sub.ftz.f32 	%r107, %r106, %r104;
	mul.ftz.f32 	%r108, %r105, %r107;
	mul.ftz.f32 	%r109, %r34, %r108;
	add.ftz.f32 	%r121, %r128, %r109;
	abs.ftz.f32 	%r110, %r128;
	abs.ftz.f32 	%r111, %r109;
	setp.ltu.ftz.f32 	%p10, %r110, %r111;
	sub.ftz.f32 	%r112, %r109, %r121;
	add.ftz.f32 	%r113, %r128, %r112;
	sub.ftz.f32 	%r114, %r128, %r121;
	add.ftz.f32 	%r115, %r109, %r114;
	selp.f32 	%r116, %r113, %r115, %p10;
	add.ftz.f32 	%r131, %r131, %r116;
	add.s32 	%r127, %r127, 1;
	add.s32 	%r126, %r126, 1;
	setp.ne.s32 	%p11, %r126, 0;
	mov.b32 	%r128, %r121;
	@%p11 bra 	$L__BB3_7;
$L__BB3_8:
	add.ftz.f32 	%r132, %r131, %r121;
$L__BB3_9:
	cvta.to.global.u64 	%rd14, %rd5;
	mul.wide.s32 	%rd15, %r1, 4;
	add.s64 	%rd16, %rd14, %rd15;
	st.global.b32 	[%rd16], %r132;
$L__BB3_10:
	ret;

}
	// .globl	compute_population_mean_S
.visible .entry compute_population_mean_S(
	.param .u64 .ptr .align 1 compute_population_mean_S_param_0,
	.param .u32 compute_population_mean_S_param_1,
	.param .u64 .ptr .align 1 compute_population_mean_S_param_2
)
.maxntid 256
.minnctapersm 4
{
	.reg .pred 	%p<18>;
	.reg .b32 	%r<68>;
	.reg .b64 	%rd<7>;
	// demoted variable
	.shared .align 4 .b8 _ZZ25compute_population_mean_SE9smem_warp[32];
	ld.param.b64 	%rd2, [compute_population_mean_S_param_0];
	ld.param.b32 	%r21, [compute_population_mean_S_param_1];
	ld.param.b64 	%rd3, [compute_population_mean_S_param_2];
	mov.u32 	%r1, %tid.x;
	mov.u32 	%r2, %ctaid.x;
	mov.u32 	%r3, %ntid.x;
	mad.lo.s32 	%r62, %r2, %r3, %r1;
	setp.ge.s32 	%p1, %r62, %r21;
	mov.b32 	%r65, 0f00000000;
	@%p1 bra 	$L__BB4_4;
	mov.u32 	%r24, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r24;
	cvta.to.global.u64 	%rd1, %rd2;
	mov.b32 	%r63, 0f00000000;
	mov.b32 	%r64, %r63;
$L__BB4_2:
	mul.wide.s32 	%rd4, %r62, 4;
	add.s64 	%rd5, %rd1, %rd4;
	ld.global.nc.b32 	%r25, [%rd5];
	add.ftz.f32 	%r9, %r63, %r25;
	abs.ftz.f32 	%r26, %r63;
	abs.ftz.f32 	%r27, %r25;
	setp.ltu.ftz.f32 	%p2, %r26, %r27;
	sub.ftz.f32 	%r28, %r25, %r9;
	add.ftz.f32 	%r29, %r63, %r28;
	sub.ftz.f32 	%r30, %r63, %r9;
	add.ftz.f32 	%r31, %r25, %r30;
	selp.f32 	%r32, %r29, %r31, %p2;
	add.ftz.f32 	%r64, %r64, %r32;
	add.s32 	%r62, %r62, %r5;
	setp.lt.s32 	%p3, %r62, %r21;
	mov.b32 	%r63, %r9;
	@%p3 bra 	$L__BB4_2;
	add.ftz.f32 	%r65, %r64, %r9;
$L__BB4_4:
	and.b32 	%r14, %r1, 31;
	add.s32 	%r15, %r3, 31;
	shfl.sync.bfly.b32 	%r33|%p4, %r65, 16, 31, -1;
	add.ftz.f32 	%r34, %r65, %r33;
	shfl.sync.bfly.b32 	%r35|%p5, %r34, 8, 31, -1;
	add.ftz.f32 	%r36, %r34, %r35;
	shfl.sync.bfly.b32 	%r37|%p6, %r36, 4, 31, -1;
	add.ftz.f32 	%r38, %r36, %r37;
	shfl.sync.bfly.b32 	%r39|%p7, %r38, 2, 31, -1;
	add.ftz.f32 	%r40, %r38, %r39;
	shfl.sync.bfly.b32 	%r41|%p8, %r40, 1, 31, -1;
	add.ftz.f32 	%r67, %r40, %r41;
	setp.ne.s32 	%p9, %r14, 0;
	@%p9 bra 	$L__BB4_6;
	shr.u32 	%r42, %r1, 3;
	mov.b32 	%r43, _ZZ25compute_population_mean_SE9smem_warp;
	add.s32 	%r44, %r43, %r42;
	st.shared.b32 	[%r44], %r67;
$L__BB4_6:
	bar.sync 	0;
	setp.gt.u32 	%p10, %r1, 31;
	@%p10 bra 	$L__BB4_10;
	shr.u32 	%r46, %r15, 5;
	setp.ge.u32 	%p11, %r14, %r46;
	mov.b32 	%r66, 0f00000000;
	@%p11 bra 	$L__BB4_9;
	shl.b32 	%r47, %r14, 2;
	mov.b32 	%r48, _ZZ25compute_population_mean_SE9smem_warp;
	add.s32 	%r49, %r48, %r47;
	ld.shared.b32 	%r66, [%r49];
$L__BB4_9:
	shfl.sync.bfly.b32 	%r50|%p12, %r66, 16, 31, -1;
	add.ftz.f32 	%r51, %r66, %r50;
	shfl.sync.bfly.b32 	%r52|%p13, %r51, 8, 31, -1;
	add.ftz.f32 	%r53, %r51, %r52;
	shfl.sync.bfly.b32 	%r54|%p14, %r53, 4, 31, -1;
	add.ftz.f32 	%r55, %r53, %r54;
	shfl.sync.bfly.b32 	%r56|%p15, %r55, 2, 31, -1;
	add.ftz.f32 	%r57, %r55, %r56;
	shfl.sync.bfly.b32 	%r58|%p16, %r57, 1, 31, -1;
	add.ftz.f32 	%r67, %r57, %r58;
$L__BB4_10:
	or.b32 	%r59, %r1, %r2;
	setp.ne.s32 	%p17, %r59, 0;
	@%p17 bra 	$L__BB4_12;
	cvt.rn.f32.s32 	%r60, %r21;
	div.approx.ftz.f32 	%r61, %r67, %r60;
	cvta.to.global.u64 	%rd6, %rd3;
	st.global.b32 	[%rd6], %r61;
$L__BB4_12:
	ret;

}
