//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-36836380
// Cuda compilation tools, release 13.1, V13.1.80
// Based on NVVM 7.0.1
//

.version 9.1
.target sm_86
.address_size 64

	// .globl	glycan_mask_kernel
// _ZZ18glycan_mask_kernelE13sequon_coords has been demoted
// _ZZ18glycan_mask_kernelE11num_sequons has been demoted
// _ZZ21count_masked_residuesE11local_count has been demoted

.visible .entry glycan_mask_kernel(
	.param .u64 glycan_mask_kernel_param_0,
	.param .u64 glycan_mask_kernel_param_1,
	.param .u32 glycan_mask_kernel_param_2,
	.param .u64 glycan_mask_kernel_param_3
)
.maxntid 256, 1, 1
.minnctapersm 4
{
	.reg .pred 	%p<44>;
	.reg .b16 	%rs<17>;
	.reg .f32 	%f<115>;
	.reg .b32 	%r<101>;
	.reg .b64 	%rd<13>;
	// demoted variable
	.shared .align 4 .b8 _ZZ18glycan_mask_kernelE13sequon_coords[768];
	// demoted variable
	.shared .align 4 .u32 _ZZ18glycan_mask_kernelE11num_sequons;

	ld.param.u64 	%rd2, [glycan_mask_kernel_param_0];
	ld.param.u64 	%rd3, [glycan_mask_kernel_param_1];
	ld.param.u32 	%r27, [glycan_mask_kernel_param_2];
	ld.param.u64 	%rd4, [glycan_mask_kernel_param_3];
	mov.u32 	%r28, %ntid.x;
	mov.u32 	%r29, %ctaid.x;
	mov.u32 	%r1, %tid.x;
	mad.lo.s32 	%r2, %r29, %r28, %r1;
	setp.ne.s32 	%p1, %r1, 0;
	@%p1 bra 	$L__BB0_2;

	mov.u32 	%r30, 0;
	st.shared.u32 	[_ZZ18glycan_mask_kernelE11num_sequons], %r30;

$L__BB0_2:
	bar.sync 	0;
	add.s32 	%r31, %r2, 2;
	setp.ge.s32 	%p2, %r31, %r27;
	setp.ge.s32 	%p3, %r2, %r27;
	cvta.to.global.u64 	%rd5, %rd3;
	mul.wide.s32 	%rd6, %r2, 12;
	add.s64 	%rd1, %rd5, %rd6;
	or.pred  	%p4, %p3, %p2;
	@%p4 bra 	$L__BB0_6;

	cvt.s64.s32 	%rd7, %r2;
	cvta.to.global.u64 	%rd8, %rd2;
	add.s64 	%rd9, %rd8, %rd7;
	ld.global.nc.u8 	%rs2, [%rd9];
	cvt.u16.u8 	%rs3, %rs2;
	setp.ne.s16 	%p5, %rs3, 78;
	ld.global.nc.u8 	%rs4, [%rd9+1];
	cvt.u16.u8 	%rs5, %rs4;
	setp.eq.s16 	%p6, %rs5, 80;
	or.pred  	%p7, %p5, %p6;
	ld.global.nc.u8 	%rs6, [%rd9+2];
	cvt.u16.u8 	%rs7, %rs6;
	add.s16 	%rs8, %rs7, -83;
	and.b16  	%rs9, %rs8, 255;
	setp.gt.u16 	%p8, %rs9, 1;
	or.pred  	%p9, %p7, %p8;
	@%p9 bra 	$L__BB0_6;

	mov.u32 	%r32, _ZZ18glycan_mask_kernelE11num_sequons;
	atom.shared.add.u32 	%r3, [%r32], 1;
	setp.gt.s32 	%p10, %r3, 63;
	@%p10 bra 	$L__BB0_6;

	ld.global.nc.f32 	%f4, [%rd1];
	ld.global.nc.f32 	%f5, [%rd1+4];
	ld.global.nc.f32 	%f6, [%rd1+8];
	mov.u32 	%r33, _ZZ18glycan_mask_kernelE13sequon_coords;
	mad.lo.s32 	%r34, %r3, 12, %r33;
	st.shared.f32 	[%r34], %f4;
	st.shared.f32 	[%r34+4], %f5;
	st.shared.f32 	[%r34+8], %f6;

$L__BB0_6:
	bar.sync 	0;
	@%p3 bra 	$L__BB0_24;

	ld.global.nc.f32 	%f1, [%rd1];
	ld.global.nc.f32 	%f2, [%rd1+4];
	ld.global.nc.f32 	%f3, [%rd1+8];
	ld.shared.u32 	%r100, [_ZZ18glycan_mask_kernelE11num_sequons];
	setp.lt.s32 	%p12, %r100, 1;
	mov.u16 	%rs10, 0;
	mov.u16 	%rs16, %rs10;
	@%p12 bra 	$L__BB0_23;

	shr.s32 	%r36, %r1, 31;
	shr.u32 	%r37, %r36, 27;
	add.s32 	%r38, %r1, %r37;
	and.b32  	%r39, %r38, -32;
	sub.s32 	%r5, %r1, %r39;
	mov.u32 	%r95, 0;

$L__BB0_9:
	add.s32 	%r8, %r95, %r5;
	setp.ge.s32 	%p13, %r8, %r100;
	mov.u32 	%r96, 1148846080;
	mov.u32 	%r97, %r96;
	mov.u32 	%r98, %r96;
	@%p13 bra 	$L__BB0_11;

	mov.u32 	%r43, _ZZ18glycan_mask_kernelE13sequon_coords;
	mad.lo.s32 	%r44, %r8, 12, %r43;
	ld.shared.u32 	%r98, [%r44];
	ld.shared.u32 	%r97, [%r44+4];
	ld.shared.u32 	%r96, [%r44+8];

$L__BB0_11:
	mov.u32 	%r99, 0;

$L__BB0_12:
	ld.shared.u32 	%r100, [_ZZ18glycan_mask_kernelE11num_sequons];
	add.s32 	%r46, %r99, %r95;
	setp.ge.s32 	%p14, %r46, %r100;
	@%p14 bra 	$L__BB0_22;

	mov.u32 	%r47, 31;
	mov.u32 	%r48, -1;
	shfl.sync.idx.b32 	%r49|%p15, %r98, %r99, %r47, %r48;
	mov.b32 	%f7, %r49;
	shfl.sync.idx.b32 	%r50|%p16, %r97, %r99, %r47, %r48;
	mov.b32 	%f8, %r50;
	shfl.sync.idx.b32 	%r51|%p17, %r96, %r99, %r47, %r48;
	mov.b32 	%f9, %r51;
	sub.f32 	%f10, %f1, %f7;
	sub.f32 	%f11, %f2, %f8;
	sub.f32 	%f12, %f3, %f9;
	abs.f32 	%f13, %f10;
	abs.f32 	%f14, %f11;
	abs.f32 	%f15, %f12;
	add.f32 	%f16, %f13, %f14;
	add.f32 	%f17, %f16, %f15;
	min.f32 	%f18, %f13, %f14;
	max.f32 	%f19, %f13, %f14;
	min.f32 	%f20, %f19, %f15;
	max.f32 	%f21, %f19, %f15;
	mov.b32 	%r52, %f21;
	and.b32  	%r53, %r52, -33554432;
	mov.u32 	%r54, 2122317824;
	sub.s32 	%r55, %r54, %r53;
	mov.b32 	%f22, %r55;
	mul.f32 	%f23, %f20, %f22;
	mul.f32 	%f24, %f18, %f22;
	mul.f32 	%f25, %f21, %f22;
	mul.f32 	%f26, %f23, %f23;
	fma.rn.f32 	%f27, %f24, %f24, %f26;
	fma.rn.f32 	%f28, %f25, %f25, %f27;
	sqrt.rn.f32 	%f29, %f28;
	or.b32  	%r56, %r53, 8388608;
	mov.b32 	%f30, %r56;
	mul.f32 	%f31, %f29, %f30;
	setp.gt.f32 	%p18, %f17, %f21;
	selp.f32 	%f32, %f31, %f17, %p18;
	setp.eq.f32 	%p19, %f21, 0f7F800000;
	selp.f32 	%f33, 0f7F800000, %f32, %p19;
	setp.lt.f32 	%p20, %f33, 0f41200000;
	add.s32 	%r17, %r99, 1;
	mov.u16 	%rs16, 1;
	@%p20 bra 	$L__BB0_23;

	add.s32 	%r57, %r17, %r95;
	ld.shared.u32 	%r100, [_ZZ18glycan_mask_kernelE11num_sequons];
	setp.ge.s32 	%p21, %r57, %r100;
	@%p21 bra 	$L__BB0_22;

	mov.u32 	%r58, 31;
	mov.u32 	%r59, -1;
	shfl.sync.idx.b32 	%r60|%p22, %r98, %r17, %r58, %r59;
	mov.b32 	%f34, %r60;
	shfl.sync.idx.b32 	%r61|%p23, %r97, %r17, %r58, %r59;
	mov.b32 	%f35, %r61;
	shfl.sync.idx.b32 	%r62|%p24, %r96, %r17, %r58, %r59;
	mov.b32 	%f36, %r62;
	sub.f32 	%f37, %f1, %f34;
	sub.f32 	%f38, %f2, %f35;
	sub.f32 	%f39, %f3, %f36;
	abs.f32 	%f40, %f37;
	abs.f32 	%f41, %f38;
	abs.f32 	%f42, %f39;
	add.f32 	%f43, %f40, %f41;
	add.f32 	%f44, %f43, %f42;
	min.f32 	%f45, %f40, %f41;
	max.f32 	%f46, %f40, %f41;
	min.f32 	%f47, %f46, %f42;
	max.f32 	%f48, %f46, %f42;
	mov.b32 	%r63, %f48;
	and.b32  	%r64, %r63, -33554432;
	mov.u32 	%r65, 2122317824;
	sub.s32 	%r66, %r65, %r64;
	mov.b32 	%f49, %r66;
	mul.f32 	%f50, %f47, %f49;
	mul.f32 	%f51, %f45, %f49;
	mul.f32 	%f52, %f48, %f49;
	mul.f32 	%f53, %f50, %f50;
	fma.rn.f32 	%f54, %f51, %f51, %f53;
	fma.rn.f32 	%f55, %f52, %f52, %f54;
	sqrt.rn.f32 	%f56, %f55;
	or.b32  	%r67, %r64, 8388608;
	mov.b32 	%f57, %r67;
	mul.f32 	%f58, %f56, %f57;
	setp.gt.f32 	%p25, %f44, %f48;
	selp.f32 	%f59, %f58, %f44, %p25;
	setp.eq.f32 	%p26, %f48, 0f7F800000;
	selp.f32 	%f60, 0f7F800000, %f59, %p26;
	setp.lt.f32 	%p27, %f60, 0f41200000;
	add.s32 	%r19, %r99, 2;
	@%p27 bra 	$L__BB0_23;

	add.s32 	%r68, %r19, %r95;
	ld.shared.u32 	%r100, [_ZZ18glycan_mask_kernelE11num_sequons];
	setp.ge.s32 	%p28, %r68, %r100;
	@%p28 bra 	$L__BB0_22;

	mov.u32 	%r69, 31;
	mov.u32 	%r70, -1;
	shfl.sync.idx.b32 	%r71|%p29, %r98, %r19, %r69, %r70;
	mov.b32 	%f61, %r71;
	shfl.sync.idx.b32 	%r72|%p30, %r97, %r19, %r69, %r70;
	mov.b32 	%f62, %r72;
	shfl.sync.idx.b32 	%r73|%p31, %r96, %r19, %r69, %r70;
	mov.b32 	%f63, %r73;
	sub.f32 	%f64, %f1, %f61;
	sub.f32 	%f65, %f2, %f62;
	sub.f32 	%f66, %f3, %f63;
	abs.f32 	%f67, %f64;
	abs.f32 	%f68, %f65;
	abs.f32 	%f69, %f66;
	add.f32 	%f70, %f67, %f68;
	add.f32 	%f71, %f70, %f69;
	min.f32 	%f72, %f67, %f68;
	max.f32 	%f73, %f67, %f68;
	min.f32 	%f74, %f73, %f69;
	max.f32 	%f75, %f73, %f69;
	mov.b32 	%r74, %f75;
	and.b32  	%r75, %r74, -33554432;
	mov.u32 	%r76, 2122317824;
	sub.s32 	%r77, %r76, %r75;
	mov.b32 	%f76, %r77;
	mul.f32 	%f77, %f74, %f76;
	mul.f32 	%f78, %f72, %f76;
	mul.f32 	%f79, %f75, %f76;
	mul.f32 	%f80, %f77, %f77;
	fma.rn.f32 	%f81, %f78, %f78, %f80;
	fma.rn.f32 	%f82, %f79, %f79, %f81;
	sqrt.rn.f32 	%f83, %f82;
	or.b32  	%r78, %r75, 8388608;
	mov.b32 	%f84, %r78;
	mul.f32 	%f85, %f83, %f84;
	setp.gt.f32 	%p32, %f71, %f75;
	selp.f32 	%f86, %f85, %f71, %p32;
	setp.eq.f32 	%p33, %f75, 0f7F800000;
	selp.f32 	%f87, 0f7F800000, %f86, %p33;
	setp.lt.f32 	%p34, %f87, 0f41200000;
	add.s32 	%r21, %r99, 3;
	@%p34 bra 	$L__BB0_23;

	add.s32 	%r79, %r21, %r95;
	ld.shared.u32 	%r100, [_ZZ18glycan_mask_kernelE11num_sequons];
	setp.ge.s32 	%p35, %r79, %r100;
	@%p35 bra 	$L__BB0_22;

	mov.u32 	%r80, 31;
	mov.u32 	%r81, -1;
	shfl.sync.idx.b32 	%r82|%p36, %r98, %r21, %r80, %r81;
	mov.b32 	%f88, %r82;
	shfl.sync.idx.b32 	%r83|%p37, %r97, %r21, %r80, %r81;
	mov.b32 	%f89, %r83;
	shfl.sync.idx.b32 	%r84|%p38, %r96, %r21, %r80, %r81;
	mov.b32 	%f90, %r84;
	sub.f32 	%f91, %f1, %f88;
	sub.f32 	%f92, %f2, %f89;
	sub.f32 	%f93, %f3, %f90;
	abs.f32 	%f94, %f91;
	abs.f32 	%f95, %f92;
	abs.f32 	%f96, %f93;
	add.f32 	%f97, %f94, %f95;
	add.f32 	%f98, %f97, %f96;
	min.f32 	%f99, %f94, %f95;
	max.f32 	%f100, %f94, %f95;
	min.f32 	%f101, %f100, %f96;
	max.f32 	%f102, %f100, %f96;
	mov.b32 	%r85, %f102;
	and.b32  	%r86, %r85, -33554432;
	mov.u32 	%r87, 2122317824;
	sub.s32 	%r88, %r87, %r86;
	mov.b32 	%f103, %r88;
	mul.f32 	%f104, %f101, %f103;
	mul.f32 	%f105, %f99, %f103;
	mul.f32 	%f106, %f102, %f103;
	mul.f32 	%f107, %f104, %f104;
	fma.rn.f32 	%f108, %f105, %f105, %f107;
	fma.rn.f32 	%f109, %f106, %f106, %f108;
	sqrt.rn.f32 	%f110, %f109;
	or.b32  	%r89, %r86, 8388608;
	mov.b32 	%f111, %r89;
	mul.f32 	%f112, %f110, %f111;
	setp.gt.f32 	%p39, %f98, %f102;
	selp.f32 	%f113, %f112, %f98, %p39;
	setp.eq.f32 	%p40, %f102, 0f7F800000;
	selp.f32 	%f114, 0f7F800000, %f113, %p40;
	setp.lt.f32 	%p41, %f114, 0f41200000;
	add.s32 	%r99, %r99, 4;
	@%p41 bra 	$L__BB0_23;

	setp.lt.u32 	%p42, %r99, 32;
	@%p42 bra 	$L__BB0_12;

	ld.shared.u32 	%r100, [_ZZ18glycan_mask_kernelE11num_sequons];

$L__BB0_22:
	add.s32 	%r95, %r95, 32;
	setp.lt.s32 	%p43, %r95, %r100;
	mov.u16 	%rs16, %rs10;
	@%p43 bra 	$L__BB0_9;

$L__BB0_23:
	cvt.s64.s32 	%rd10, %r2;
	cvta.to.global.u64 	%rd11, %rd4;
	add.s64 	%rd12, %rd11, %rd10;
	st.global.u8 	[%rd12], %rs16;

$L__BB0_24:
	ret;

}
	// .globl	count_masked_residues
.visible .entry count_masked_residues(
	.param .u64 count_masked_residues_param_0,
	.param .u64 count_masked_residues_param_1,
	.param .u32 count_masked_residues_param_2
)
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<12>;
	.reg .b64 	%rd<7>;
	// demoted variable
	.shared .align 4 .u32 _ZZ21count_masked_residuesE11local_count;

	ld.param.u64 	%rd2, [count_masked_residues_param_0];
	ld.param.u64 	%rd3, [count_masked_residues_param_1];
	ld.param.u32 	%r5, [count_masked_residues_param_2];
	mov.u32 	%r11, %tid.x;
	setp.ne.s32 	%p1, %r11, 0;
	@%p1 bra 	$L__BB1_2;

	mov.u32 	%r6, 0;
	st.shared.u32 	[_ZZ21count_masked_residuesE11local_count], %r6;

$L__BB1_2:
	bar.sync 	0;
	setp.ge.s32 	%p2, %r11, %r5;
	@%p2 bra 	$L__BB1_7;

	mov.u32 	%r2, %ntid.x;
	cvta.to.global.u64 	%rd1, %rd2;

$L__BB1_4:
	cvt.s64.s32 	%rd4, %r11;
	add.s64 	%rd5, %rd1, %rd4;
	ld.global.nc.u8 	%rs1, [%rd5];
	cvt.u16.u8 	%rs2, %rs1;
	setp.ne.s16 	%p3, %rs2, 1;
	@%p3 bra 	$L__BB1_6;

	mov.u32 	%r7, _ZZ21count_masked_residuesE11local_count;
	atom.shared.add.u32 	%r8, [%r7], 1;

$L__BB1_6:
	add.s32 	%r11, %r11, %r2;
	setp.lt.s32 	%p4, %r11, %r5;
	@%p4 bra 	$L__BB1_4;

$L__BB1_7:
	bar.sync 	0;
	@%p1 bra 	$L__BB1_9;

	ld.shared.u32 	%r9, [_ZZ21count_masked_residuesE11local_count];
	cvta.to.global.u64 	%rd6, %rd3;
	atom.global.add.u32 	%r10, [%rd6], %r9;

$L__BB1_9:
	ret;

}
	// .globl	extract_sequon_positions
.visible .entry extract_sequon_positions(
	.param .u64 extract_sequon_positions_param_0,
	.param .u64 extract_sequon_positions_param_1,
	.param .u64 extract_sequon_positions_param_2,
	.param .u32 extract_sequon_positions_param_3
)
{
	.reg .pred 	%p<10>;
	.reg .b16 	%rs<9>;
	.reg .b32 	%r<8>;
	.reg .b64 	%rd<11>;


	ld.param.u64 	%rd1, [extract_sequon_positions_param_0];
	ld.param.u64 	%rd2, [extract_sequon_positions_param_1];
	ld.param.u64 	%rd3, [extract_sequon_positions_param_2];
	ld.param.u32 	%r3, [extract_sequon_positions_param_3];
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r5, %ctaid.x;
	mov.u32 	%r6, %tid.x;
	mad.lo.s32 	%r1, %r5, %r4, %r6;
	setp.ge.s32 	%p1, %r1, %r3;
	add.s32 	%r7, %r1, 2;
	setp.ge.s32 	%p2, %r7, %r3;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	$L__BB2_4;

	cvt.s64.s32 	%rd4, %r1;
	cvta.to.global.u64 	%rd5, %rd1;
	add.s64 	%rd6, %rd5, %rd4;
	ld.global.nc.u8 	%rs1, [%rd6];
	cvt.u16.u8 	%rs2, %rs1;
	setp.ne.s16 	%p4, %rs2, 78;
	ld.global.nc.u8 	%rs3, [%rd6+1];
	cvt.u16.u8 	%rs4, %rs3;
	setp.eq.s16 	%p5, %rs4, 80;
	or.pred  	%p6, %p4, %p5;
	ld.global.nc.u8 	%rs5, [%rd6+2];
	cvt.u16.u8 	%rs6, %rs5;
	add.s16 	%rs7, %rs6, -83;
	and.b16  	%rs8, %rs7, 255;
	setp.gt.u16 	%p7, %rs8, 1;
	or.pred  	%p8, %p6, %p7;
	@%p8 bra 	$L__BB2_4;

	cvta.to.global.u64 	%rd7, %rd3;
	atom.global.add.u32 	%r2, [%rd7], 1;
	setp.gt.s32 	%p9, %r2, 63;
	@%p9 bra 	$L__BB2_4;

	cvta.to.global.u64 	%rd8, %rd2;
	mul.wide.s32 	%rd9, %r2, 4;
	add.s64 	%rd10, %rd8, %rd9;
	st.global.u32 	[%rd10], %r1;

$L__BB2_4:
	ret;

}

