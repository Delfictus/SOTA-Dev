//! Persistent NHS Engine for High-Throughput Batch Processing
//!
//! Keeps CUDA context, modules, and buffers alive across multiple structures.
//! Hot-swaps topologies without reinitializing GPU state.
//!
//! ## Performance Benefits
//! - Single CUDA context creation (~100ms saved per structure)
//! - Single PTX compilation (~200ms saved per structure)
//! - Buffer reuse for similar-sized structures
//! - Pipelined data transfer during compute
//!
//! ## Usage
//! ```no_run
//! let mut engine = PersistentNhsEngine::new(max_atoms)?;
//! for topology in topologies {
//!     engine.load_topology(&topology)?;
//!     let results = engine.run(steps, config)?;
//! }
//! ```

use anyhow::{bail, Context, Result};
use std::sync::Arc;
use std::path::Path;
use std::time::Instant;

#[cfg(feature = "gpu")]
use cudarc::driver::{
    CudaContext, CudaSlice, CudaStream, CudaFunction, CudaModule,
    LaunchConfig, PushKernelArg, DevicePtrMut,
};
#[cfg(feature = "gpu")]
use cudarc::nvrtc::Ptx;

use crate::input::PrismPrepTopology;

#[allow(deprecated)]
use crate::fused_engine::{
    NhsAmberFusedEngine, CryoUvProtocol,
    // Deprecated - kept for backward compatibility
    TemperatureProtocol,
    UvProbeConfig,
    StepResult, RunSummary, SpikeEvent, EnsembleSnapshot,
};

/// Configuration for persistent batch processing
#[derive(Debug, Clone)]
pub struct PersistentBatchConfig {
    /// Maximum atoms to pre-allocate for (prevents reallocation)
    pub max_atoms: usize,
    /// Grid dimension for exclusion field
    pub grid_dim: usize,
    /// Grid spacing in Angstroms
    pub grid_spacing: f32,
    /// Survey phase steps (cryo)
    pub survey_steps: i32,
    /// Convergence phase steps (warming)
    pub convergence_steps: i32,
    /// Precision phase steps (production)
    pub precision_steps: i32,
    /// Target temperature (K)
    pub temperature: f32,
    /// Cryo temperature (K)
    pub cryo_temp: f32,
    /// Cryo hold steps before warming
    pub cryo_hold: i32,
}

impl Default for PersistentBatchConfig {
    fn default() -> Self {
        Self {
            max_atoms: 20000,  // Handle large structures (1DLO ~16K atoms)
            grid_dim: 64,
            grid_spacing: 1.5,
            survey_steps: 500000,    // 1ns
            convergence_steps: 1000000, // 2ns
            precision_steps: 1000000,   // 2ns
            temperature: 300.0,
            cryo_temp: 100.0,
            cryo_hold: 100000,
        }
    }
}

/// Result from processing a single structure
#[derive(Debug, Clone)]
pub struct StructureResult {
    pub structure_id: String,
    pub total_steps: i32,
    pub wall_time_ms: u64,
    pub spike_events: Vec<SpikeEvent>,
    pub snapshots: Vec<EnsembleSnapshot>,
    pub final_temperature: f32,
    /// Clustered binding sites from RT-accelerated spatial analysis
    pub clustered_sites: Vec<ClusteredBindingSite>,
    /// RT clustering statistics
    pub clustering_stats: Option<ClusteringStats>,
}

/// A residue lining a binding site pocket
#[derive(Debug, Clone, serde::Serialize)]
pub struct LiningResidue {
    /// Chain identifier (e.g., "A", "B")
    pub chain: String,
    /// Residue sequence number
    pub resid: i32,
    /// Residue name (e.g., "ALA", "PHE")
    pub resname: String,
    /// Minimum distance from any atom to pocket centroid (Ã…)
    pub min_distance: f32,
    /// Number of atoms within cutoff
    pub n_atoms_in_pocket: usize,
}

/// A clustered binding site detected from spike spatial patterns
#[derive(Debug, Clone)]
pub struct ClusteredBindingSite {
    /// Cluster ID (unique per analysis run)
    pub cluster_id: i32,
    /// Centroid position [x, y, z] in Angstroms
    pub centroid: [f32; 3],
    /// Number of spikes in this cluster
    pub spike_count: usize,
    /// Spike indices belonging to this cluster
    pub spike_indices: Vec<usize>,
    /// Average spike intensity in cluster
    pub avg_intensity: f32,
    /// Estimated volume (convex hull approximation) in Ã…Â³
    pub estimated_volume: f32,
    /// Bounding box dimensions [dx, dy, dz] in Angstroms
    pub bounding_box: [f32; 3],
    /// Quality score for this binding site (0.0-1.0)
    pub quality_score: f32,
    /// Druggability assessment
    pub druggability: DruggabilityScore,
    /// Site classification
    pub classification: SiteClassification,
    /// Aromatic proximity analysis (if computed)
    pub aromatic_proximity: Option<AromaticProximityInfo>,
    /// Residues lining this binding pocket (within cutoff distance)
    pub lining_residues: Vec<LiningResidue>,
}

/// Aromatic residue proximity information for a binding site
#[derive(Debug, Clone, Default)]
pub struct AromaticProximityInfo {
    /// Distance to nearest TRP residue (Ã…), None if no TRP in structure
    pub nearest_trp_distance: Option<f32>,
    /// Distance to nearest TYR residue (Ã…)
    pub nearest_tyr_distance: Option<f32>,
    /// Distance to nearest PHE residue (Ã…)
    pub nearest_phe_distance: Option<f32>,
    /// Distance to nearest aromatic (any type)
    pub nearest_aromatic_distance: f32,
    /// Number of aromatics within 5Ã…
    pub aromatics_within_5a: usize,
    /// Number of aromatics within 8Ã…
    pub aromatics_within_8a: usize,
    /// Aromatic residue indices within 8Ã…
    pub nearby_aromatic_residues: Vec<u32>,
    /// Aromatic score (0.0-1.0) based on proximity
    pub aromatic_score: f32,
}

/// Druggability score for a binding site
#[derive(Debug, Clone, Default)]
pub struct DruggabilityScore {
    /// Overall druggability (0.0-1.0)
    pub overall: f32,
    /// Volume contribution (0.0-1.0) - sites need 200-800 Ã…Â³
    pub volume_score: f32,
    /// Enclosure score (0.0-1.0) - how enclosed the pocket is
    pub enclosure_score: f32,
    /// Hydrophobicity score (0.0-1.0) - dewetting signal strength
    pub hydrophobicity_score: f32,
    /// Aromatic score (0.0-1.0) - proximity to aromatics for pi-stacking
    pub aromatic_score: f32,
    /// Catalytic score (0.0-1.0) - enzyme active site potential
    pub catalytic_score: f32,
    /// Is this likely a druggable pocket?
    pub is_druggable: bool,
}

/// Catalytic residue types for enzyme active site detection
pub const CATALYTIC_RESIDUES: &[&str] = &["GLU", "ASP", "HIS", "HID", "HIE", "HIP", "SER", "CYS", "LYS"];

/// Compute catalytic score from lining residues
///
/// Enzyme active sites typically have:
/// - Multiple catalytic residues (GLU, ASP, HIS, SER, CYS, LYS)
/// - Catalytic residues clustered within 6Ã… of pocket center
/// - At least 2-3 catalytic residues for enzymatic activity
pub fn compute_catalytic_score(lining_residues: &[LiningResidue]) -> (f32, usize) {
    if lining_residues.is_empty() {
        return (0.0, 0);
    }

    // Count catalytic residues and their proximity
    let mut catalytic_count = 0;
    let mut close_catalytic = 0; // Within 5Ã…
    let mut total_catalytic_distance = 0.0f32;

    for res in lining_residues {
        if CATALYTIC_RESIDUES.contains(&res.resname.as_str()) {
            catalytic_count += 1;
            total_catalytic_distance += res.min_distance;
            if res.min_distance <= 5.0 {
                close_catalytic += 1;
            }
        }
    }

    if catalytic_count == 0 {
        return (0.0, 0);
    }

    // Score components:
    // 1. Count score: 2-3 catalytic residues is optimal for enzyme activity
    let count_score: f32 = match catalytic_count {
        0 => 0.0,
        1 => 0.3,
        2 => 0.7,
        3 => 1.0,
        4 => 0.95,
        5 => 0.9,
        _ => 0.85, // Many catalytic residues still good
    };

    // 2. Proximity score: closer catalytic residues = more likely active site
    let avg_distance = total_catalytic_distance / catalytic_count as f32;
    let proximity_score: f32 = if avg_distance <= 3.0 {
        1.0
    } else if avg_distance <= 5.0 {
        0.9
    } else if avg_distance <= 7.0 {
        0.7
    } else {
        0.5
    };

    // 3. Close clustering bonus: multiple catalytic residues within 5Ã…
    let clustering_bonus: f32 = match close_catalytic {
        0 => 0.0,
        1 => 0.1,
        2 => 0.2,
        _ => 0.3,
    };

    // Combined score
    let score: f32 = (0.5 * count_score + 0.3 * proximity_score + 0.2 * clustering_bonus).clamp(0.0, 1.0);

    (score, catalytic_count)
}

impl DruggabilityScore {
    /// Compute druggability from binding site properties (without aromatic info)
    pub fn from_site(volume: f32, avg_intensity: f32, bounding_box: &[f32; 3]) -> Self {
        Self::from_site_with_aromatics(volume, avg_intensity, bounding_box, None)
    }

    /// Compute druggability with aromatic proximity information
    pub fn from_site_with_aromatics(
        volume: f32,
        avg_intensity: f32,
        bounding_box: &[f32; 3],
        aromatic_info: Option<&AromaticProximityInfo>,
    ) -> Self {
        // Volume scoring: optimal range 200-800 Ã…Â³
        let volume_score = if volume < 100.0 {
            volume / 100.0 * 0.3  // Too small
        } else if volume < 200.0 {
            0.3 + (volume - 100.0) / 100.0 * 0.4  // Getting better
        } else if volume <= 800.0 {
            0.7 + (1.0 - (volume - 200.0) / 600.0 * 0.3).max(0.7)  // Optimal
        } else if volume <= 1500.0 {
            0.7 - (volume - 800.0) / 700.0 * 0.3  // Large but ok
        } else {
            0.4 - (volume - 1500.0) / 2000.0 * 0.2  // Too large (surface area)
        }.clamp(0.0, 1.0);

        // Enclosure: ratio of volume to bounding box volume
        let bb_volume = bounding_box[0] * bounding_box[1] * bounding_box[2];
        let enclosure_score = if bb_volume > 0.0 {
            (volume / bb_volume).clamp(0.0, 1.0) * 0.7 + 0.3  // Bias toward enclosed
        } else {
            0.0
        };

        // Hydrophobicity: spike intensity indicates dewetting strength
        let hydrophobicity_score = (avg_intensity / 10.0).clamp(0.0, 1.0);

        // Aromatic score: based on proximity to aromatic residues
        // Aromatics enable pi-stacking with drug molecules
        let aromatic_score = aromatic_info
            .map(|info| info.aromatic_score)
            .unwrap_or(0.5);  // Default to neutral if not computed

        // Overall: weighted combination (with aromatics)
        let overall = if aromatic_info.is_some() {
            // With aromatic info: 30% volume, 20% enclosure, 25% hydrophobicity, 25% aromatic
            0.30 * volume_score + 0.20 * enclosure_score + 0.25 * hydrophobicity_score + 0.25 * aromatic_score
        } else {
            // Without aromatic info: original weights
            0.40 * volume_score + 0.30 * enclosure_score + 0.30 * hydrophobicity_score
        };

        // Druggable threshold: overall >= threshold AND volume in reasonable range
        // Bonus: sites with aromatics nearby get lower threshold (pi-stacking potential)
        let aromatic_bonus = aromatic_info
            .map(|info| info.aromatics_within_5a > 0 || info.aromatic_score > 0.4)
            .unwrap_or(false);
        let threshold = if aromatic_bonus { 0.40 } else { 0.48 };
        let is_druggable = overall >= threshold && volume >= 50.0 && volume <= 3000.0;

        Self {
            overall,
            volume_score,
            enclosure_score,
            hydrophobicity_score,
            aromatic_score,
            catalytic_score: 0.0, // Computed separately with lining residues
            is_druggable,
        }
    }

    /// Compute druggability with full context: aromatics AND catalytic residues
    ///
    /// Enzyme active sites are druggable through:
    /// - Substrate mimics (competitive inhibitors)
    /// - Covalent inhibitors (targeting catalytic Ser/Cys)
    /// - Allosteric modulation
    ///
    /// This method properly scores polar enzyme sites that would fail
    /// traditional hydrophobic druggability metrics.
    pub fn from_site_with_catalytic(
        volume: f32,
        avg_intensity: f32,
        bounding_box: &[f32; 3],
        aromatic_info: Option<&AromaticProximityInfo>,
        lining_residues: &[LiningResidue],
    ) -> Self {
        // Start with base scoring
        let mut score = Self::from_site_with_aromatics(volume, avg_intensity, bounding_box, aromatic_info);

        // Compute catalytic score
        let (catalytic_score, catalytic_count) = compute_catalytic_score(lining_residues);
        score.catalytic_score = catalytic_score;

        // For enzyme active sites: adjust scoring to account for polar nature
        if catalytic_count >= 2 && catalytic_score >= 0.5 {
            // This is likely an enzyme active site
            // Recalculate overall with catalytic contribution
            // Enzyme sites: 25% volume, 15% enclosure, 15% hydrophobicity, 20% aromatic, 25% catalytic
            let aromatic = aromatic_info.map(|i| i.aromatic_score).unwrap_or(0.5);
            score.overall = 0.25 * score.volume_score
                + 0.15 * score.enclosure_score
                + 0.15 * score.hydrophobicity_score
                + 0.20 * aromatic
                + 0.25 * catalytic_score;

            // Enzyme active sites with good catalytic score are druggable
            // (substrate mimics, covalent inhibitors, etc.)
            // Note: Large enzyme sites have low volume_score, so use lower threshold
            let enzyme_threshold = 0.35; // Lower threshold for enzyme sites
            // Note: Large multi-subunit enzymes (aldolases, etc.) can have
            // binding sites up to ~8000 Ã…Â³. Use < comparison to avoid
            // floating-point boundary issues with clamped volumes.
            score.is_druggable = score.overall >= enzyme_threshold
                && volume >= 50.0
                && volume < 8001.0; // Enzyme sites can be quite large
        }

        score
    }
}

impl AromaticProximityInfo {
    /// Compute aromatic proximity for a site centroid given aromatic residue positions
    ///
    /// # Arguments
    /// * `site_centroid` - [x, y, z] position of binding site center
    /// * `aromatic_positions` - List of (residue_id, aromatic_type, [x, y, z]) for each aromatic
    ///
    /// # Aromatic Types
    /// * 0 = TRP (tryptophan)
    /// * 1 = TYR (tyrosine)
    /// * 2 = PHE (phenylalanine)
    pub fn compute(
        site_centroid: &[f32; 3],
        aromatic_positions: &[(u32, u8, [f32; 3])],
    ) -> Self {
        if aromatic_positions.is_empty() {
            return Self::default();
        }

        let mut nearest_trp: Option<f32> = None;
        let mut nearest_tyr: Option<f32> = None;
        let mut nearest_phe: Option<f32> = None;
        let mut nearest_any = f32::MAX;
        let mut within_5a = 0usize;
        let mut within_8a = 0usize;
        let mut nearby_residues = Vec::new();

        for &(residue_id, aromatic_type, pos) in aromatic_positions {
            let dx = pos[0] - site_centroid[0];
            let dy = pos[1] - site_centroid[1];
            let dz = pos[2] - site_centroid[2];
            let dist = (dx * dx + dy * dy + dz * dz).sqrt();

            // Track nearest by type
            match aromatic_type {
                0 => {  // TRP
                    if nearest_trp.map_or(true, |d| dist < d) {
                        nearest_trp = Some(dist);
                    }
                }
                1 => {  // TYR
                    if nearest_tyr.map_or(true, |d| dist < d) {
                        nearest_tyr = Some(dist);
                    }
                }
                2 => {  // PHE
                    if nearest_phe.map_or(true, |d| dist < d) {
                        nearest_phe = Some(dist);
                    }
                }
                _ => {}
            }

            // Track nearest any
            if dist < nearest_any {
                nearest_any = dist;
            }

            // Count within distance thresholds
            if dist <= 5.0 {
                within_5a += 1;
            }
            if dist <= 8.0 {
                within_8a += 1;
                nearby_residues.push(residue_id);
            }
        }

        // Compute aromatic score based on proximity
        // Higher score for closer aromatics, especially TRP (strongest UV absorber)
        let aromatic_score = Self::compute_aromatic_score(
            nearest_trp,
            nearest_tyr,
            nearest_phe,
            within_5a,
        );

        Self {
            nearest_trp_distance: nearest_trp,
            nearest_tyr_distance: nearest_tyr,
            nearest_phe_distance: nearest_phe,
            nearest_aromatic_distance: if nearest_any < f32::MAX { nearest_any } else { 0.0 },
            aromatics_within_5a: within_5a,
            aromatics_within_8a: within_8a,
            nearby_aromatic_residues: nearby_residues,
            aromatic_score,
        }
    }

    /// Compute aromatic score from distances
    fn compute_aromatic_score(
        nearest_trp: Option<f32>,
        nearest_tyr: Option<f32>,
        nearest_phe: Option<f32>,
        within_5a: usize,
    ) -> f32 {
        // TRP is most important (strongest UV absorber, best for pi-stacking)
        let trp_score = nearest_trp
            .map(|d| Self::distance_to_score(d, 1.5))  // TRP weight 1.5x
            .unwrap_or(0.0);

        // TYR is moderate
        let tyr_score = nearest_tyr
            .map(|d| Self::distance_to_score(d, 1.0))
            .unwrap_or(0.0);

        // PHE is weakest
        let phe_score = nearest_phe
            .map(|d| Self::distance_to_score(d, 0.7))
            .unwrap_or(0.0);

        // Combine scores (take best + bonus for multiple)
        let base_score = trp_score.max(tyr_score).max(phe_score);
        let multi_bonus = (within_5a as f32 * 0.05).min(0.2);  // Up to 0.2 bonus

        (base_score + multi_bonus).clamp(0.0, 1.0)
    }

    /// Convert distance to score (closer = higher)
    fn distance_to_score(distance: f32, weight: f32) -> f32 {
        if distance < 3.0 {
            // Direct contact: highest score
            weight * 1.0
        } else if distance < 5.0 {
            // Close proximity: good score
            weight * (1.0 - (distance - 3.0) / 2.0 * 0.3)
        } else if distance < 8.0 {
            // Medium range: moderate score
            weight * (0.7 - (distance - 5.0) / 3.0 * 0.3)
        } else {
            // Distal: low score
            weight * (0.4 - (distance - 8.0) / 10.0 * 0.4).max(0.0)
        }
    }
}

/// Classification of detected binding site
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum SiteClassification {
    /// Traditional active site (large, persistent)
    ActiveSite,
    /// Allosteric binding site (remote from active site)
    Allosteric,
    /// Cryptic site (only appears transiently)
    Cryptic,
    /// Protein-protein interaction surface
    PpiSurface,
    /// Membrane interface region
    MembraneInterface,
    /// Unclassified
    Unknown,
}

impl Default for SiteClassification {
    fn default() -> Self {
        Self::Unknown
    }
}

impl SiteClassification {
    /// Classify based on spike patterns and volume
    pub fn from_properties(spike_count: usize, volume: f32, _avg_intensity: f32) -> Self {
        if volume >= 400.0 && spike_count >= 50 {
            Self::ActiveSite
        } else if volume >= 200.0 && volume <= 600.0 && spike_count >= 20 {
            Self::Cryptic  // Moderate size, fewer spikes â†’ transient
        } else if volume >= 150.0 && spike_count >= 10 {
            Self::Allosteric
        } else if volume >= 800.0 {
            Self::PpiSurface  // Large surface areas
        } else {
            Self::Unknown
        }
    }
}

/// Statistics from RT clustering
#[derive(Debug, Clone)]
pub struct ClusteringStats {
    /// Number of clusters found
    pub num_clusters: usize,
    /// Total neighbor pairs examined
    pub total_neighbors: usize,
    /// GPU time in milliseconds
    pub gpu_time_ms: f64,
    /// Whether RT cores were used (vs fallback)
    pub used_rt_cores: bool,
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// MULTI-SCALE CLUSTERING
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/// Cluster found at a single scale (epsilon value)
#[derive(Debug, Clone)]
pub struct ScaleCluster {
    /// Cluster centroid [x, y, z]
    pub centroid: [f32; 3],
    /// Number of spikes in this cluster
    pub spike_count: usize,
    /// Spike indices belonging to this cluster
    pub spike_indices: Vec<usize>,
    /// Epsilon value (scale) at which this cluster was found
    pub epsilon: f32,
    /// Original cluster ID from DBSCAN at this scale
    pub original_cluster_id: i32,
    /// Persistence score (how many scales this cluster appears at)
    pub persistence: usize,
}

/// Merged cluster from multiple scales
#[derive(Debug, Clone)]
pub struct MergedCluster {
    /// Merged centroid (average across scales)
    pub centroid: [f32; 3],
    /// Total unique spikes across all scales
    pub spike_count: usize,
    /// Union of spike indices from all contributing scale clusters
    pub spike_indices: Vec<usize>,
    /// Persistence: number of scales this cluster appears at
    pub persistence: usize,
    /// List of epsilon values where this cluster was detected
    pub scales: Vec<f32>,
}

/// Result of multi-scale clustering
#[derive(Debug, Clone)]
pub struct MultiScaleClusteringResult {
    /// Merged clusters sorted by confidence (persistence Ã— spike_count)
    pub clusters: Vec<MergedCluster>,
    /// Number of epsilon scales used
    pub total_scales: usize,
    /// Epsilon values tested
    pub epsilon_values: Vec<f32>,
    /// Whether adaptive epsilon was used (vs fixed)
    pub adaptive_epsilon: bool,
    /// k value used for k-NN (if adaptive)
    pub knn_k: Option<usize>,
    /// Number of spikes sampled for k-NN (if adaptive)
    pub num_spikes_sampled: Option<usize>,
}

impl MultiScaleClusteringResult {
    /// Convert to cluster IDs array (for compatibility with single-scale API)
    ///
    /// Returns cluster ID for each spike position, using the merged cluster assignments.
    /// Spikes not in any persistent cluster get -1 (noise).
    pub fn to_cluster_ids(&self, num_spikes: usize) -> Vec<i32> {
        let mut cluster_ids = vec![-1i32; num_spikes];

        for (cluster_idx, cluster) in self.clusters.iter().enumerate() {
            for &spike_idx in &cluster.spike_indices {
                if spike_idx < num_spikes {
                    cluster_ids[spike_idx] = cluster_idx as i32;
                }
            }
        }

        cluster_ids
    }

    /// Get the number of persistent clusters
    pub fn num_clusters(&self) -> usize {
        self.clusters.len()
    }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// SITE PERSISTENCE TRACKING
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/// Tracks binding site persistence across trajectory frames
///
/// Sites that persist across multiple frames are more reliable drug targets.
/// Transient sites may be cryptic pockets that only appear during conformational changes.
#[derive(Debug, Clone)]
pub struct SitePersistenceTracker {
    /// Tracked sites by unique ID
    tracked_sites: Vec<TrackedSite>,
    /// Spatial matching threshold (Ã…)
    match_threshold: f32,
    /// Total frames processed
    total_frames: usize,
    /// Next unique site ID
    next_site_id: u64,
}

/// A binding site being tracked across frames
#[derive(Debug, Clone)]
pub struct TrackedSite {
    /// Unique ID for this site across all frames
    pub site_id: u64,
    /// Running average centroid position
    pub avg_centroid: [f32; 3],
    /// Running average volume
    pub avg_volume: f32,
    /// Number of frames this site was detected
    pub frame_count: usize,
    /// First frame this site appeared
    pub first_frame: usize,
    /// Most recent frame this site was seen
    pub last_frame: usize,
    /// Consecutive frames detected (current streak)
    pub consecutive_frames: usize,
    /// Maximum consecutive detection streak
    pub max_consecutive: usize,
    /// Running average spike count
    pub avg_spike_count: f32,
    /// Running average quality score
    pub avg_quality: f32,
    /// Is this site considered persistent? (detected in >50% of frames)
    pub is_persistent: bool,
    /// Site classification (most common across frames)
    pub classification: SiteClassification,
    /// Frame-by-frame spike counts for variability analysis
    spike_history: Vec<usize>,
}

/// Result of persistence analysis
#[derive(Debug, Clone)]
pub struct PersistenceAnalysis {
    /// Total frames analyzed
    pub total_frames: usize,
    /// All tracked sites with persistence info
    pub sites: Vec<TrackedSite>,
    /// Number of persistent sites (>50% frame presence)
    pub persistent_count: usize,
    /// Number of transient sites (<50% frame presence)
    pub transient_count: usize,
    /// Average site lifetime (frames)
    pub avg_lifetime: f32,
}

impl SitePersistenceTracker {
    /// Create a new persistence tracker
    ///
    /// # Arguments
    /// * `match_threshold` - Maximum distance (Ã…) for sites to be considered the same
    pub fn new(match_threshold: f32) -> Self {
        Self {
            tracked_sites: Vec::new(),
            match_threshold,
            total_frames: 0,
            next_site_id: 0,
        }
    }

    /// Process binding sites from a single frame
    ///
    /// Matches sites to existing tracked sites or creates new ones.
    pub fn process_frame(&mut self, frame_sites: &[ClusteredBindingSite]) {
        self.total_frames += 1;
        let current_frame = self.total_frames;

        // Mark all sites as not-seen-this-frame
        let mut matched = vec![false; self.tracked_sites.len()];

        for site in frame_sites {
            // Find best matching tracked site
            let mut best_match: Option<usize> = None;
            let mut best_dist = f32::MAX;

            for (idx, tracked) in self.tracked_sites.iter().enumerate() {
                if matched[idx] {
                    continue;
                }

                let dist = Self::distance(&site.centroid, &tracked.avg_centroid);
                if dist < self.match_threshold && dist < best_dist {
                    best_match = Some(idx);
                    best_dist = dist;
                }
            }

            if let Some(idx) = best_match {
                // Update existing site
                self.update_tracked_site(idx, site, current_frame);
                matched[idx] = true;
            } else {
                // Create new tracked site
                self.create_tracked_site(site, current_frame);
            }
        }

        // Update sites not seen this frame (break consecutive streak)
        for (idx, was_matched) in matched.iter().enumerate() {
            if !was_matched {
                self.tracked_sites[idx].consecutive_frames = 0;
            }
        }

        // Update persistence status for all sites
        self.update_persistence_status();
    }

    /// Update an existing tracked site with new detection
    fn update_tracked_site(&mut self, idx: usize, site: &ClusteredBindingSite, frame: usize) {
        let tracked = &mut self.tracked_sites[idx];

        // Update running averages
        let n = tracked.frame_count as f32;
        tracked.avg_centroid[0] = (tracked.avg_centroid[0] * n + site.centroid[0]) / (n + 1.0);
        tracked.avg_centroid[1] = (tracked.avg_centroid[1] * n + site.centroid[1]) / (n + 1.0);
        tracked.avg_centroid[2] = (tracked.avg_centroid[2] * n + site.centroid[2]) / (n + 1.0);
        tracked.avg_volume = (tracked.avg_volume * n + site.estimated_volume) / (n + 1.0);
        tracked.avg_spike_count = (tracked.avg_spike_count * n + site.spike_count as f32) / (n + 1.0);
        tracked.avg_quality = (tracked.avg_quality * n + site.quality_score) / (n + 1.0);

        tracked.frame_count += 1;
        tracked.last_frame = frame;
        tracked.consecutive_frames += 1;
        tracked.max_consecutive = tracked.max_consecutive.max(tracked.consecutive_frames);
        tracked.spike_history.push(site.spike_count);

        // Keep most common classification (or use most recent if better quality)
        if site.quality_score > tracked.avg_quality * 1.2 {
            tracked.classification = site.classification;
        }
    }

    /// Create a new tracked site
    fn create_tracked_site(&mut self, site: &ClusteredBindingSite, frame: usize) {
        let site_id = self.next_site_id;
        self.next_site_id += 1;

        self.tracked_sites.push(TrackedSite {
            site_id,
            avg_centroid: site.centroid,
            avg_volume: site.estimated_volume,
            frame_count: 1,
            first_frame: frame,
            last_frame: frame,
            consecutive_frames: 1,
            max_consecutive: 1,
            avg_spike_count: site.spike_count as f32,
            avg_quality: site.quality_score,
            is_persistent: false,
            classification: site.classification,
            spike_history: vec![site.spike_count],
        });
    }

    /// Update persistence status for all sites
    fn update_persistence_status(&mut self) {
        let threshold = self.total_frames as f32 * 0.5;  // 50% of frames

        for site in &mut self.tracked_sites {
            site.is_persistent = site.frame_count as f32 >= threshold;
        }
    }

    /// Get final persistence analysis
    pub fn analyze(&self) -> PersistenceAnalysis {
        let persistent_count = self.tracked_sites.iter().filter(|s| s.is_persistent).count();
        let transient_count = self.tracked_sites.len() - persistent_count;

        let avg_lifetime = if self.tracked_sites.is_empty() {
            0.0
        } else {
            self.tracked_sites.iter()
                .map(|s| s.frame_count as f32)
                .sum::<f32>() / self.tracked_sites.len() as f32
        };

        PersistenceAnalysis {
            total_frames: self.total_frames,
            sites: self.tracked_sites.clone(),
            persistent_count,
            transient_count,
            avg_lifetime,
        }
    }

    /// Get tracked sites sorted by persistence (most persistent first)
    pub fn get_persistent_sites(&self) -> Vec<&TrackedSite> {
        let mut sites: Vec<_> = self.tracked_sites.iter().collect();
        sites.sort_by(|a, b| {
            // Sort by frame_count descending, then by avg_quality descending
            b.frame_count.cmp(&a.frame_count)
                .then_with(|| b.avg_quality.partial_cmp(&a.avg_quality).unwrap_or(std::cmp::Ordering::Equal))
        });
        sites
    }

    /// Calculate Euclidean distance between two positions
    fn distance(a: &[f32; 3], b: &[f32; 3]) -> f32 {
        let dx = a[0] - b[0];
        let dy = a[1] - b[1];
        let dz = a[2] - b[2];
        (dx * dx + dy * dy + dz * dz).sqrt()
    }
}

impl TrackedSite {
    /// Calculate spike count variability (coefficient of variation)
    pub fn spike_variability(&self) -> f32 {
        if self.spike_history.len() < 2 {
            return 0.0;
        }

        let mean = self.avg_spike_count;
        if mean < 0.001 {
            return 0.0;
        }

        let variance: f32 = self.spike_history.iter()
            .map(|&x| (x as f32 - mean).powi(2))
            .sum::<f32>() / self.spike_history.len() as f32;

        variance.sqrt() / mean  // CV
    }

    /// Get frame presence ratio (0.0 to 1.0)
    pub fn presence_ratio(&self, total_frames: usize) -> f32 {
        if total_frames == 0 {
            return 0.0;
        }
        self.frame_count as f32 / total_frames as f32
    }
}

/// Persistent engine that keeps GPU state alive across structures
#[cfg(feature = "gpu")]
pub struct PersistentNhsEngine {
    /// Shared CUDA context (kept alive)
    context: Arc<CudaContext>,
    /// Compiled module (kept alive)
    module: Arc<CudaModule>,
    /// Stream for operations
    stream: Arc<CudaStream>,

    /// Currently loaded engine instance
    engine: Option<NhsAmberFusedEngine>,

    /// RT-accelerated clustering engine (lazy initialized)
    rt_engine: Option<crate::rt_clustering::RtClusteringEngine>,

    /// Pre-allocated buffer capacity
    max_atoms: usize,

    /// Grid configuration
    grid_dim: usize,
    grid_spacing: f32,

    /// Current topology ID
    current_topology_id: Option<String>,

    /// Initialization time tracking
    context_init_time_ms: u64,
    module_init_time_ms: u64,

    /// RT engine initialization time (if initialized)
    rt_init_time_ms: Option<u64>,

    /// Cumulative statistics
    structures_processed: usize,
    total_steps_run: i64,
    total_compute_time_ms: u64,
}

#[cfg(feature = "gpu")]
impl PersistentNhsEngine {
    /// Create persistent engine with pre-allocated capacity
    pub fn new(config: &PersistentBatchConfig) -> Result<Self> {
        log::info!("ğŸš€ Initializing Persistent NHS Engine (max_atoms: {})", config.max_atoms);

        // Time context creation
        let ctx_start = Instant::now();
        let context = CudaContext::new(0)
            .context("Failed to create CUDA context")?;
        let context_init_time_ms = ctx_start.elapsed().as_millis() as u64;
        log::info!("  CUDA context: {}ms", context_init_time_ms);

        // Time module loading
        let mod_start = Instant::now();

        // Try multiple PTX locations
        let ptx_candidates = [
            "../prism-gpu/src/kernels/nhs_amber_fused.ptx",  // From workspace
            "crates/prism-gpu/src/kernels/nhs_amber_fused.ptx",  // From root
            "target/ptx/nhs_amber_fused.ptx",  // Build output
        ];

        let ptx_path = ptx_candidates.iter()
            .find(|p| Path::new(p).exists())
            .ok_or_else(|| anyhow::anyhow!("nhs_amber_fused.ptx not found in any standard location"))?;

        let module = context
            .load_module(Ptx::from_file(ptx_path))
            .context("Failed to load NHS-AMBER fused PTX")?;
        let module_init_time_ms = mod_start.elapsed().as_millis() as u64;
        log::info!("  PTX module: {}ms", module_init_time_ms);

        let stream = context.default_stream();

        log::info!("âœ… Persistent engine ready (total init: {}ms)",
            context_init_time_ms + module_init_time_ms);

        Ok(Self {
            context,
            module,
            stream,
            engine: None,
            rt_engine: None,  // Lazy initialized on first use
            max_atoms: config.max_atoms,
            grid_dim: config.grid_dim,
            grid_spacing: config.grid_spacing,
            current_topology_id: None,
            context_init_time_ms,
            module_init_time_ms,
            rt_init_time_ms: None,
            structures_processed: 0,
            total_steps_run: 0,
            total_compute_time_ms: 0,
        })
    }

    /// Create persistent engine on an explicit CUDA stream (for multi-stream concurrency).
    /// Shares context + module with other engines â€” each gets its own stream for GPU overlap.
    pub fn new_on_stream(
        config: &PersistentBatchConfig,
        context: Arc<CudaContext>,
        module: Arc<CudaModule>,
        stream: Arc<CudaStream>,
    ) -> Result<Self> {
        log::info!("Persistent NHS Engine on dedicated stream (max_atoms: {})", config.max_atoms);
        Ok(Self {
            context,
            module,
            stream,
            engine: None,
            rt_engine: None,
            max_atoms: config.max_atoms,
            grid_dim: config.grid_dim,
            grid_spacing: config.grid_spacing,
            current_topology_id: None,
            context_init_time_ms: 0,
            module_init_time_ms: 0,
            rt_init_time_ms: None,
            structures_processed: 0,
            total_steps_run: 0,
            total_compute_time_ms: 0,
        })
    }

    /// Access the shared CUDA context (for creating additional streams)
    pub fn cuda_context(&self) -> &Arc<CudaContext> {
        &self.context
    }

    /// Access the compiled PTX module (for sharing across engines)
    pub fn cuda_module(&self) -> &Arc<CudaModule> {
        &self.module
    }

    /// Load a new topology (hot-swap)
    ///
    /// If the new topology fits in existing buffers, reuses them.
    /// Otherwise, reallocates with appropriate capacity.
    pub fn load_topology(&mut self, topology: &PrismPrepTopology) -> Result<()> {
        let topo_id = std::path::Path::new(&topology.source_pdb)
            .file_stem()
            .map(|s| s.to_string_lossy().to_string())
            .unwrap_or_else(|| "unknown".to_string());
        log::info!("ğŸ“¦ Loading topology: {} ({} atoms)", topo_id, topology.n_atoms);

        let load_start = Instant::now();

        // Check if we need to reallocate
        if topology.n_atoms > self.max_atoms {
            log::warn!("  Structure exceeds max_atoms ({}), reallocating to {}",
                self.max_atoms, topology.n_atoms + 1000);
            self.max_atoms = topology.n_atoms + 1000;
        }

        // Create new engine instance with shared context
        // Note: In a more optimized version, we would reuse GPU buffers
        // For now, we benefit from shared context + module
        let engine = NhsAmberFusedEngine::new_on_stream(
            self.context.clone(),
            self.stream.clone(),
            topology,
            self.grid_dim,
            self.grid_spacing,
        )?;

        self.engine = Some(engine);
        self.current_topology_id = Some(topo_id.clone());

        let load_time = load_start.elapsed().as_millis() as u64;
        log::info!("  Topology loaded: {}ms", load_time);

        Ok(())
    }

    /// **Configure unified cryo-UV protocol (RECOMMENDED)**
    ///
    /// Sets the integrated cryo-thermal + UV-LIF protocol for the current topology.
    /// This is the canonical PRISM4D cryptic site detection method.
    pub fn set_cryo_uv_protocol(&mut self, protocol: CryoUvProtocol) -> Result<()> {
        if let Some(ref mut engine) = self.engine {
            engine.set_cryo_uv_protocol(protocol)?;
            Ok(())
        } else {
            bail!("No topology loaded")
        }
    }

    /// **DEPRECATED**: Configure temperature protocol separately
    ///
    /// Use `set_cryo_uv_protocol()` instead to configure the unified cryo-UV protocol.
    #[deprecated(since = "1.2.0", note = "Use set_cryo_uv_protocol() instead")]
    pub fn set_temperature_protocol(&mut self, protocol: TemperatureProtocol) -> Result<()> {
        if let Some(ref mut engine) = self.engine {
            #[allow(deprecated)]
            engine.set_temperature_protocol(protocol)?;
            Ok(())
        } else {
            bail!("No topology loaded")
        }
    }

    /// **DEPRECATED**: Configure UV probe separately
    ///
    /// Use `set_cryo_uv_protocol()` instead to configure the unified cryo-UV protocol.
    #[deprecated(since = "1.2.0", note = "Use set_cryo_uv_protocol() instead")]
    pub fn set_uv_config(&mut self, config: UvProbeConfig) -> Result<()> {
        if let Some(ref mut engine) = self.engine {
            #[allow(deprecated)]
            engine.set_uv_config(config);
            Ok(())
        } else {
            bail!("No topology loaded")
        }
    }

    /// Run simulation on current topology
    pub fn run(&mut self, n_steps: i32) -> Result<RunSummary> {
        if let Some(ref mut engine) = self.engine {
            let run_start = Instant::now();
            let summary = engine.run(n_steps)?;
            let run_time = run_start.elapsed().as_millis() as u64;

            self.structures_processed += 1;
            self.total_steps_run += n_steps as i64;
            self.total_compute_time_ms += run_time;

            Ok(summary)
        } else {
            bail!("No topology loaded")
        }
    }

    /// Run simulation and automatically cluster spike events
    ///
    /// Convenience method that:
    /// 1. Runs the simulation for n_steps
    /// 2. Collects spike events
    /// 3. Clusters them using RT cores (or fallback)
    /// 4. Returns structured binding site information
    ///
    /// # Example
    /// ```ignore
    /// let (summary, sites, stats) = engine.run_and_cluster(1_000_000)?;
    /// for site in &sites {
    ///     println!("Binding site at {:?} with {} spikes", site.centroid, site.spike_count);
    /// }
    /// ```
    pub fn run_and_cluster(&mut self, n_steps: i32) -> Result<(RunSummary, Vec<ClusteredBindingSite>, Option<ClusteringStats>)> {
        let summary = self.run(n_steps)?;
        let spike_events = self.get_spike_events();

        if spike_events.is_empty() {
            return Ok((summary, Vec::new(), None));
        }

        // Extract positions
        let positions: Vec<f32> = spike_events.iter()
            .flat_map(|s| s.position.iter().copied())
            .collect();

        // Cluster using RT cores or fallback
        let used_rt = self.has_rt_clustering();
        let result = self.cluster_spikes(&positions)?;
        let sites = build_clustered_sites(&spike_events, &result);
        let stats = ClusteringStats {
            num_clusters: result.num_clusters,
            total_neighbors: result.total_neighbors,
            gpu_time_ms: result.gpu_time_ms,
            used_rt_cores: used_rt,
        };

        Ok((summary, sites, Some(stats)))
    }

    /// Get spike events from current run
    pub fn get_spike_events(&self) -> Vec<SpikeEvent> {
        if let Some(ref engine) = self.engine {
            engine.get_spike_events().to_vec()
        } else {
            Vec::new()
        }
    }

    /// Enable spike accumulation for analysis
    ///
    /// When enabled, spikes are downloaded from the GPU and accumulated
    /// across sync intervals. Use `get_accumulated_spikes()` to retrieve.
    pub fn set_spike_accumulation(&mut self, enabled: bool) {
        if let Some(ref mut engine) = self.engine {
            engine.set_spike_accumulation(enabled);
        }
    }

    /// Get accumulated spike events (GPU format with timestamps)
    ///
    /// Returns all spike events accumulated since spike accumulation was enabled.
    /// Only populated when spike accumulation is enabled via `set_spike_accumulation(true)`.
    pub fn get_accumulated_spikes(&self) -> Vec<crate::fused_engine::GpuSpikeEvent> {
        if let Some(ref engine) = self.engine {
            engine.get_accumulated_spikes().to_vec()
        } else {
            Vec::new()
        }
    }

    /// Get snapshots from current run
    pub fn get_snapshots(&self) -> Vec<EnsembleSnapshot> {
        if let Some(ref engine) = self.engine {
            engine.get_ensemble_snapshots().to_vec()
        } else {
            Vec::new()
        }
    }

    /// Reset engine state for a new replica
    ///
    /// Clears accumulated spikes, re-initializes velocities with a new seed,
    /// and resets simulation counters. Topology and forces are preserved.
    ///
    /// # Arguments
    /// * `seed` - Random seed for velocity initialization (Maxwell-Boltzmann)
    pub fn reset_for_replica(&mut self, seed: u64) -> Result<()> {
        if let Some(ref mut engine) = self.engine {
            engine.reset_for_replica(seed)
        } else {
            bail!("No topology loaded")
        }
    }

    /// Get current positions
    pub fn get_positions(&self) -> Result<Vec<f32>> {
        if let Some(ref engine) = self.engine {
            engine.get_positions()
        } else {
            bail!("No topology loaded")
        }
    }

    /// Enable UltimateEngine for 2-4x faster MD simulation
    ///
    /// Requires SM86+ GPU (Ampere/Ada/Blackwell) and topology to be loaded.
    /// Uses mixed-precision, SoA layout, and other hyperoptimizations.
    ///
    /// Note: Must be called after load_topology() with the same topology.
    pub fn enable_ultimate_mode(&mut self, topology: &PrismPrepTopology) -> Result<()> {
        if let Some(ref mut engine) = self.engine {
            engine.enable_ultimate_mode(topology)?;
            log::info!("âœ“ UltimateEngine enabled (2-4x faster MD)");
            Ok(())
        } else {
            bail!("Engine not initialized - call load_topology() first")
        }
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // RT-ACCELERATED CLUSTERING
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    /// Check if RT cores are available for accelerated clustering
    pub fn has_rt_clustering(&self) -> bool {
        crate::rt_utils::has_rt_cores() && crate::rt_utils::is_optix_available()
    }

    /// Ensure the RT clustering pipeline is initialized (lazy init)
    ///
    /// Call this explicitly to pre-warm the pipeline, or let it initialize
    /// lazily on first `cluster_spikes()` call.
    pub fn ensure_rt_pipeline(&mut self) -> Result<bool> {
        if self.rt_engine.is_some() {
            return Ok(true);  // Already initialized
        }

        if !self.has_rt_clustering() {
            log::debug!("RT clustering not available (no RT cores or OptiX)");
            return Ok(false);
        }

        log::info!("ğŸ”· Initializing OptiX RT pipeline for clustering...");
        let start = Instant::now();

        // Find the OptiX IR file
        let optixir_path = crate::rt_clustering::find_optixir_path()
            .context("Could not find rt_clustering.optixir")?;

        // Adaptive epsilon: scale inversely with cube root of atom count.
        // Larger proteins need tighter clustering to resolve distinct pockets.
        //   â‰¤500 atoms  â†’ 3.0 Ã…  (small, e.g. crambin)
        //   ~2000 atoms â†’ 2.0 Ã…  (medium)
        //   ~4000 atoms â†’ 1.5 Ã…  (large, e.g. TEM-1)
        //   ~8000 atoms â†’ 1.2 Ã…  (very large)
        // Formula: epsilon = 3.0 * (500 / n_atoms)^(1/3), clamped to [1.2, 3.0]
        let n_atoms = self.engine.as_ref().map(|e| e.n_atoms()).unwrap_or(500);
        let adaptive_epsilon = (3.0_f32 * (500.0_f32 / n_atoms as f32).cbrt())
            .clamp(1.2, 3.0);
        log::info!("  Adaptive epsilon: {:.2}Ã… (n_atoms={})", adaptive_epsilon, n_atoms);

        // Create RT clustering config with adaptive epsilon
        let rt_config = crate::rt_clustering::RtClusteringConfig {
            epsilon: adaptive_epsilon,
            min_points: 4,         // Minimum 4 neighbors for core point
            min_cluster_size: 20,  // Minimum 20 points per cluster (catch smaller pockets)
            rays_per_event: 32,    // 32 rays for neighbor finding
        };

        // Create and initialize the RT engine
        let mut rt_engine = crate::rt_clustering::RtClusteringEngine::new(
            self.context.clone(),
            rt_config,
        ).context("Failed to create RT clustering engine")?;

        rt_engine.load_pipeline(&optixir_path)
            .context("Failed to load RT clustering pipeline")?;

        let init_time = start.elapsed().as_millis() as u64;
        self.rt_init_time_ms = Some(init_time);
        self.rt_engine = Some(rt_engine);

        log::info!("  RT pipeline initialized: {}ms", init_time);
        log::info!("  GPU Architecture: {}", crate::rt_utils::get_architecture_name());

        Ok(true)
    }

    /// Cluster spike positions using RT-accelerated spatial queries
    ///
    /// Falls back to grid-based clustering if RT cores are unavailable.
    ///
    /// # Arguments
    /// * `spike_positions` - Flat array of [x, y, z, x, y, z, ...] coordinates
    ///
    /// # Returns
    /// Clustering result with cluster assignments and statistics
    pub fn cluster_spikes(&mut self, spike_positions: &[f32]) -> Result<crate::rt_clustering::RtClusteringResult> {
        let num_spikes = spike_positions.len() / 3;

        // Try RT-accelerated path
        if self.ensure_rt_pipeline()? {
            if let Some(ref mut rt_engine) = self.rt_engine {
                log::debug!("Using RT-accelerated clustering for {} spikes", num_spikes);
                return rt_engine.cluster(spike_positions);
            }
        }

        // Fallback: simple grid-based clustering
        log::debug!("Using fallback grid clustering for {} spikes", num_spikes);
        self.fallback_grid_cluster(spike_positions)
    }

    /// Re-cluster spikes at a specific epsilon (for mega-cluster subdivision).
    /// Temporarily overrides the RT engine's epsilon, clusters, then restores it.
    pub fn cluster_spikes_at_epsilon(&mut self, spike_positions: &[f32], epsilon: f32) -> Result<crate::rt_clustering::RtClusteringResult> {
        if let Some(ref mut rt_engine) = self.rt_engine {
            let saved = rt_engine.config.epsilon;
            rt_engine.config.epsilon = epsilon;
            let result = rt_engine.cluster(spike_positions);
            rt_engine.config.epsilon = saved;
            result
        } else {
            anyhow::bail!("RT clustering engine not initialized")
        }
    }

    /// Get the current adaptive epsilon value
    pub fn current_epsilon(&self) -> Option<f32> {
        self.rt_engine.as_ref().map(|e| e.config.epsilon)
    }

    /// Multi-scale clustering for robust, structure-agnostic binding site detection
    ///
    /// Runs DBSCAN clustering at multiple epsilon values and tracks cluster persistence
    /// across scales. Clusters that appear at multiple scales are more likely to be
    /// real binding sites rather than noise.
    ///
    /// # Algorithm
    /// Compute adaptive epsilon values from k-NN distance distribution
    ///
    /// Samples spike positions and computes the k-th nearest neighbor distance
    /// for each sample. Returns epsilon values at key percentiles that capture
    /// the natural clustering scales in the data.
    ///
    /// # Arguments
    /// * `positions` - Flat array of [x, y, z, x, y, z, ...] coordinates
    /// * `k` - Number of nearest neighbors to consider (default: 4 for DBSCAN min_points)
    /// * `sample_size` - Number of points to sample (default: 1000)
    ///
    /// # Returns
    /// Vector of epsilon values at 25th, 50th, 75th, and 90th percentiles
    pub fn compute_adaptive_epsilon(
        positions: &[f32],
        k: usize,
        sample_size: usize,
    ) -> Vec<f32> {
        let n_points = positions.len() / 3;
        if n_points < k + 1 {
            // Not enough points, return default
            return vec![5.0, 7.0, 10.0, 14.0];
        }

        // Sample points (evenly spaced or random)
        let sample_indices: Vec<usize> = if n_points <= sample_size {
            (0..n_points).collect()
        } else {
            let step = n_points / sample_size;
            (0..sample_size).map(|i| i * step).collect()
        };

        // Compute k-NN distance for each sampled point
        let mut knn_distances: Vec<f32> = Vec::with_capacity(sample_indices.len());

        for &i in &sample_indices {
            let xi = positions[i * 3];
            let yi = positions[i * 3 + 1];
            let zi = positions[i * 3 + 2];

            // Compute distances to all other points (brute force for simplicity)
            let mut distances: Vec<f32> = Vec::with_capacity(n_points.min(1000));
            for j in 0..n_points.min(5000) { // Limit comparison for performance
                if i == j { continue; }
                let xj = positions[j * 3];
                let yj = positions[j * 3 + 1];
                let zj = positions[j * 3 + 2];
                let d = ((xi - xj).powi(2) + (yi - yj).powi(2) + (zi - zj).powi(2)).sqrt();
                distances.push(d);
            }

            // Get k-th smallest distance
            if distances.len() >= k {
                distances.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
                knn_distances.push(distances[k - 1]);
            }
        }

        if knn_distances.is_empty() {
            return vec![5.0, 7.0, 10.0, 14.0];
        }

        // Sort k-NN distances
        knn_distances.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));

        // Extract percentiles: 25th, 50th, 75th, 90th
        let n = knn_distances.len();
        let p25 = knn_distances[n / 4].clamp(3.0, 8.0);
        let p50 = knn_distances[n / 2].clamp(5.0, 12.0);
        let p75 = knn_distances[3 * n / 4].clamp(7.0, 18.0);
        let p90 = knn_distances[9 * n / 10].clamp(10.0, 25.0);

        // Ensure monotonically increasing and minimum spacing
        let mut epsilons = vec![p25];
        for &e in &[p50, p75, p90] {
            if e > epsilons.last().unwrap() + 1.5 {
                epsilons.push(e);
            }
        }

        // Ensure we have at least 3 scales
        while epsilons.len() < 3 {
            let last = *epsilons.last().unwrap();
            epsilons.push((last * 1.4).min(25.0));
        }

        log::info!("Adaptive epsilon: {:?} (from k-NN analysis, k={})", epsilons, k);
        epsilons
    }

    /// Multi-scale clustering with automatic or fixed epsilon selection
    ///
    /// 1. Run clustering at epsilon values: [5.0, 7.0, 10.0, 14.0] Angstroms
    /// 2. For each scale, compute cluster centroids
    /// 3. Find clusters that "persist" (have similar centroids) across â‰¥2 scales
    /// 4. Merge overlapping clusters and assign persistence scores
    /// 5. Return clusters sorted by persistence Ã— spike_count
    ///
    /// # Arguments
    /// * `spike_positions` - Flat array of [x, y, z, x, y, z, ...] coordinates
    ///
    /// # Returns
    /// MultiScaleClusteringResult with persistence-scored clusters
    pub fn multi_scale_cluster_spikes(
        &mut self,
        spike_positions: &[f32],
    ) -> Result<MultiScaleClusteringResult> {
        self.multi_scale_cluster_spikes_with_epsilon(spike_positions, None)
    }

    /// Multi-scale clustering with optional custom epsilon values
    ///
    /// # Arguments
    /// * `spike_positions` - Flat array of [x, y, z, x, y, z, ...] coordinates
    /// * `custom_epsilon` - If Some, use these values; if None, use adaptive selection
    pub fn multi_scale_cluster_spikes_with_epsilon(
        &mut self,
        spike_positions: &[f32],
        custom_epsilon: Option<Vec<f32>>,
    ) -> Result<MultiScaleClusteringResult> {
        use std::collections::HashMap;

        let num_spikes = spike_positions.len() / 3;

        // Determine epsilon values: custom, adaptive, or default
        // Track whether adaptive was used for output
        let knn_k = 4usize;
        let sample_size = 1000usize;
        let (epsilon_scales, is_adaptive, actual_sample_size): (Vec<f32>, bool, Option<usize>) =
            if let Some(eps) = custom_epsilon {
                log::info!("Using fixed epsilon values: {:?}", eps);
                (eps, false, None)
            } else if num_spikes > 1000 {
                // Use adaptive selection for large datasets
                let actual_samples = num_spikes.min(sample_size);
                let eps = Self::compute_adaptive_epsilon(spike_positions, knn_k, sample_size);
                (eps, true, Some(actual_samples))
            } else {
                // Default values for small datasets
                log::info!("Using default epsilon values (small dataset): [5.0, 7.0, 10.0, 14.0]");
                (vec![5.0, 7.0, 10.0, 14.0], false, None)
            };
        let merge_distance = 8.0f32; // Clusters within 8Ã… are considered the same site

        log::info!("Running multi-scale clustering on {} spikes at {} scales",
            num_spikes, epsilon_scales.len());

        // Track clusters across scales: (centroid, spike_count, epsilon, cluster_id)
        let mut all_clusters: Vec<ScaleCluster> = Vec::new();

        // Run clustering at each scale
        for &epsilon in &epsilon_scales {
            // Create RT engine with this epsilon
            let rt_config = crate::rt_clustering::RtClusteringConfig {
                epsilon,
                min_points: 4,
                min_cluster_size: 15, // Lower threshold for multi-scale
                rays_per_event: 32,
            };

            // We need to create a new RT engine for each epsilon
            // (The BVH sphere radii depend on epsilon)
            let optixir_path = crate::rt_clustering::find_optixir_path()
                .context("Could not find rt_clustering.optixir")?;

            let mut rt_engine = crate::rt_clustering::RtClusteringEngine::new(
                self.context.clone(),
                rt_config,
            ).context("Failed to create RT clustering engine")?;

            rt_engine.load_pipeline(&optixir_path)
                .context("Failed to load RT clustering pipeline")?;

            let result = rt_engine.cluster(spike_positions)?;

            log::info!("  Scale Îµ={:.1}Ã…: {} clusters, {} neighbors",
                epsilon, result.num_clusters, result.total_neighbors);

            // Compute centroids for each cluster at this scale
            let mut cluster_points: HashMap<i32, Vec<usize>> = HashMap::new();
            for (idx, &cluster_id) in result.cluster_ids.iter().enumerate() {
                if cluster_id >= 0 {
                    cluster_points.entry(cluster_id).or_default().push(idx);
                }
            }

            for (cluster_id, point_indices) in cluster_points {
                if point_indices.len() < 15 {
                    continue; // Skip tiny clusters
                }

                // Compute centroid
                let mut cx = 0.0f32;
                let mut cy = 0.0f32;
                let mut cz = 0.0f32;
                for &idx in &point_indices {
                    cx += spike_positions[idx * 3];
                    cy += spike_positions[idx * 3 + 1];
                    cz += spike_positions[idx * 3 + 2];
                }
                let n = point_indices.len() as f32;
                cx /= n;
                cy /= n;
                cz /= n;

                all_clusters.push(ScaleCluster {
                    centroid: [cx, cy, cz],
                    spike_count: point_indices.len(),
                    spike_indices: point_indices,
                    epsilon,
                    original_cluster_id: cluster_id,
                    persistence: 1, // Will be updated during merge
                });
            }
        }

        log::info!("  Total clusters across all scales: {}", all_clusters.len());

        // Merge clusters that overlap across scales
        let mut merged_clusters: Vec<MergedCluster> = Vec::new();
        let mut used = vec![false; all_clusters.len()];

        for i in 0..all_clusters.len() {
            if used[i] {
                continue;
            }

            // Start a new merged cluster
            let mut merge_group: Vec<usize> = vec![i];
            used[i] = true;

            // Find all clusters within merge_distance of this centroid
            let ci = &all_clusters[i];
            for j in (i + 1)..all_clusters.len() {
                if used[j] {
                    continue;
                }

                let cj = &all_clusters[j];
                let dist = ((ci.centroid[0] - cj.centroid[0]).powi(2)
                    + (ci.centroid[1] - cj.centroid[1]).powi(2)
                    + (ci.centroid[2] - cj.centroid[2]).powi(2))
                    .sqrt();

                if dist <= merge_distance {
                    merge_group.push(j);
                    used[j] = true;
                }
            }

            // Compute merged cluster properties
            let scales_present: std::collections::HashSet<u32> = merge_group
                .iter()
                .map(|&idx| (all_clusters[idx].epsilon * 10.0) as u32)
                .collect();
            let persistence = scales_present.len();

            // Merge spike indices (union across scales)
            let mut all_spike_indices: std::collections::HashSet<usize> = std::collections::HashSet::new();
            let mut sum_cx = 0.0f32;
            let mut sum_cy = 0.0f32;
            let mut sum_cz = 0.0f32;

            for &idx in &merge_group {
                let c = &all_clusters[idx];
                sum_cx += c.centroid[0];
                sum_cy += c.centroid[1];
                sum_cz += c.centroid[2];
                for &spike_idx in &c.spike_indices {
                    all_spike_indices.insert(spike_idx);
                }
            }

            let n = merge_group.len() as f32;
            let merged_centroid = [sum_cx / n, sum_cy / n, sum_cz / n];
            let merged_spike_count = all_spike_indices.len();

            merged_clusters.push(MergedCluster {
                centroid: merged_centroid,
                spike_count: merged_spike_count,
                spike_indices: all_spike_indices.into_iter().collect(),
                persistence,
                scales: scales_present.into_iter().map(|s| s as f32 / 10.0).collect(),
            });
        }

        // Sort by persistence * spike_count (higher = more confident)
        merged_clusters.sort_by(|a, b| {
            let score_a = a.persistence * a.spike_count;
            let score_b = b.persistence * b.spike_count;
            score_b.cmp(&score_a)
        });

        // Filter to clusters with persistence >= 2 (appear at multiple scales)
        let persistent_clusters: Vec<MergedCluster> = merged_clusters
            .into_iter()
            .filter(|c| c.persistence >= 2)
            .collect();

        log::info!("  Multi-scale result: {} persistent clusters (appear at â‰¥2 scales)",
            persistent_clusters.len());

        for (i, c) in persistent_clusters.iter().take(5).enumerate() {
            log::info!("    #{}: {} spikes, persistence={}, scales={:?}",
                i + 1, c.spike_count, c.persistence, c.scales);
        }

        Ok(MultiScaleClusteringResult {
            clusters: persistent_clusters,
            total_scales: epsilon_scales.len(),
            epsilon_values: epsilon_scales,
            adaptive_epsilon: is_adaptive,
            knn_k: if is_adaptive { Some(knn_k) } else { None },
            num_spikes_sampled: actual_sample_size,
        })
    }

    /// Fallback grid-based clustering when RT cores unavailable
    fn fallback_grid_cluster(&self, positions: &[f32]) -> Result<crate::rt_clustering::RtClusteringResult> {
        let num_points = positions.len() / 3;
        let start = Instant::now();

        // Simple single-linkage clustering using spatial hashing
        // This is O(N) for sparse data but degrades to O(NÂ²) for dense clusters
        let epsilon = 5.0f32;
        let cell_size = epsilon;

        use std::collections::HashMap;

        // Hash points into cells
        let mut cells: HashMap<(i32, i32, i32), Vec<usize>> = HashMap::new();
        for i in 0..num_points {
            let x = positions[i * 3];
            let y = positions[i * 3 + 1];
            let z = positions[i * 3 + 2];
            let cell = (
                (x / cell_size).floor() as i32,
                (y / cell_size).floor() as i32,
                (z / cell_size).floor() as i32,
            );
            cells.entry(cell).or_default().push(i);
        }

        // Union-find for clustering
        let mut parent: Vec<i32> = (0..num_points as i32).collect();

        fn find(parent: &mut [i32], i: usize) -> i32 {
            if parent[i] != i as i32 {
                parent[i] = find(parent, parent[i] as usize);
            }
            parent[i]
        }

        fn union(parent: &mut [i32], a: usize, b: usize) {
            let ra = find(parent, a);
            let rb = find(parent, b);
            if ra != rb {
                parent[ra as usize] = rb;
            }
        }

        // Find neighbors and union
        let mut total_neighbors = 0usize;
        for (&cell, points) in &cells {
            // Check this cell and 26 neighbors
            for dx in -1..=1 {
                for dy in -1..=1 {
                    for dz in -1..=1 {
                        let neighbor_cell = (cell.0 + dx, cell.1 + dy, cell.2 + dz);
                        if let Some(neighbors) = cells.get(&neighbor_cell) {
                            for &i in points {
                                let xi = positions[i * 3];
                                let yi = positions[i * 3 + 1];
                                let zi = positions[i * 3 + 2];

                                for &j in neighbors {
                                    if i >= j { continue; }
                                    let xj = positions[j * 3];
                                    let yj = positions[j * 3 + 1];
                                    let zj = positions[j * 3 + 2];

                                    let dist_sq = (xi - xj).powi(2) + (yi - yj).powi(2) + (zi - zj).powi(2);
                                    if dist_sq <= epsilon * epsilon {
                                        union(&mut parent, i, j);
                                        total_neighbors += 1;
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }

        // Flatten and count clusters
        let mut cluster_ids: Vec<i32> = Vec::with_capacity(num_points);
        let mut cluster_counts: HashMap<i32, usize> = HashMap::new();

        for i in 0..num_points {
            let root = find(&mut parent, i);
            cluster_ids.push(root);
            *cluster_counts.entry(root).or_default() += 1;
        }

        let num_clusters = cluster_counts.len();
        let gpu_time_ms = start.elapsed().as_secs_f64() * 1000.0;

        Ok(crate::rt_clustering::RtClusteringResult {
            cluster_ids,
            num_clusters,
            total_neighbors,
            gpu_time_ms,
        })
    }

    /// Report cumulative statistics
    pub fn stats(&self) -> PersistentEngineStats {
        PersistentEngineStats {
            structures_processed: self.structures_processed,
            total_steps_run: self.total_steps_run,
            total_compute_time_ms: self.total_compute_time_ms,
            context_init_time_ms: self.context_init_time_ms,
            module_init_time_ms: self.module_init_time_ms,
            overhead_saved_ms: self.structures_processed.saturating_sub(1) as u64
                * (self.context_init_time_ms + self.module_init_time_ms),
        }
    }
}

/// Statistics from persistent engine
#[derive(Debug, Clone)]
pub struct PersistentEngineStats {
    pub structures_processed: usize,
    pub total_steps_run: i64,
    pub total_compute_time_ms: u64,
    pub context_init_time_ms: u64,
    pub module_init_time_ms: u64,
    /// Estimated overhead saved by reusing context/module
    pub overhead_saved_ms: u64,
}

/// Convert RT clustering results into binding site structures
#[cfg(feature = "gpu")]
fn build_clustered_sites(
    spike_events: &[SpikeEvent],
    clustering_result: &crate::rt_clustering::RtClusteringResult,
) -> Vec<ClusteredBindingSite> {
    use std::collections::HashMap;

    if spike_events.is_empty() {
        return Vec::new();
    }

    // Group spikes by cluster
    let mut cluster_spikes: HashMap<i32, Vec<(usize, &SpikeEvent)>> = HashMap::new();
    for (idx, (spike, &cluster_id)) in spike_events.iter()
        .zip(clustering_result.cluster_ids.iter())
        .enumerate()
    {
        if cluster_id >= 0 {  // Skip noise points (-1)
            cluster_spikes.entry(cluster_id)
                .or_default()
                .push((idx, spike));
        }
    }

    // Build site structures for each cluster
    let mut sites = Vec::with_capacity(cluster_spikes.len());
    for (cluster_id, spikes) in cluster_spikes {
        if spikes.is_empty() {
            continue;
        }

        // Compute centroid
        let mut centroid = [0.0f32; 3];
        let mut sum_intensity = 0.0f32;
        let mut min_pos = [f32::MAX; 3];
        let mut max_pos = [f32::MIN; 3];

        for (_, spike) in &spikes {
            centroid[0] += spike.position[0];
            centroid[1] += spike.position[1];
            centroid[2] += spike.position[2];
            sum_intensity += spike.intensity;

            // Update bounding box
            for i in 0..3 {
                min_pos[i] = min_pos[i].min(spike.position[i]);
                max_pos[i] = max_pos[i].max(spike.position[i]);
            }
        }

        let n = spikes.len() as f32;
        centroid[0] /= n;
        centroid[1] /= n;
        centroid[2] /= n;

        let bounding_box = [
            max_pos[0] - min_pos[0],
            max_pos[1] - min_pos[1],
            max_pos[2] - min_pos[2],
        ];

        // Estimate pocket volume using voxel density method
        // Grid the space at 2Ã… resolution and count occupied voxels
        let voxel_size = 2.0f32;
        let estimated_volume = if bounding_box[0] > 0.0 && bounding_box[1] > 0.0 && bounding_box[2] > 0.0 {
            let nx = ((bounding_box[0] / voxel_size).ceil() as usize).max(1);
            let ny = ((bounding_box[1] / voxel_size).ceil() as usize).max(1);
            let nz = ((bounding_box[2] / voxel_size).ceil() as usize).max(1);

            // Use HashSet to count unique voxels occupied by spikes
            let mut occupied_voxels = std::collections::HashSet::new();
            for (_, spike) in &spikes {
                let vx = ((spike.position[0] - min_pos[0]) / voxel_size) as i32;
                let vy = ((spike.position[1] - min_pos[1]) / voxel_size) as i32;
                let vz = ((spike.position[2] - min_pos[2]) / voxel_size) as i32;

                // Mark this voxel and its immediate neighbors (small neighborhood)
                for dx in -1..=1 {
                    for dy in -1..=1 {
                        for dz in -1..=1 {
                            let key = (vx + dx, vy + dy, vz + dz);
                            occupied_voxels.insert(key);
                        }
                    }
                }
            }

            // Volume = occupied voxels * voxel volume
            let voxel_volume = voxel_size.powi(3);
            let raw_volume = occupied_voxels.len() as f32 * voxel_volume;

            // Apply packing efficiency correction (sphere packing ~74% efficiency)
            let pocket_volume = raw_volume * 0.74;

            // Sanity bounds: typical pockets 100-2000 Ã…Â³, large enzyme sites up to 8000 Ã…Â³
            pocket_volume.clamp(50.0, 8000.0)
        } else {
            // Degenerate case: estimate from spike count
            (spikes.len() as f32 * 15.0).clamp(50.0, 2000.0)
        };

        let avg_intensity = sum_intensity / n;
        let spike_count = spikes.len();

        // Compute druggability score
        let druggability = DruggabilityScore::from_site(estimated_volume, avg_intensity, &bounding_box);

        // Classify site
        let classification = SiteClassification::from_properties(spike_count, estimated_volume, avg_intensity);

        // Overall quality score: combines spike count, intensity, and druggability
        let spike_quality = (spike_count as f32 / 100.0).clamp(0.0, 1.0);
        let intensity_quality = (avg_intensity / 10.0).clamp(0.0, 1.0);
        let quality_score = 0.3 * spike_quality + 0.3 * intensity_quality + 0.4 * druggability.overall;

        sites.push(ClusteredBindingSite {
            cluster_id,
            centroid,
            spike_count,
            spike_indices: spikes.iter().map(|(idx, _)| *idx).collect(),
            avg_intensity,
            estimated_volume,
            bounding_box,
            quality_score,
            druggability,
            classification,
            aromatic_proximity: None,  // Computed separately when aromatic positions available
            lining_residues: Vec::new(),  // Computed separately when topology available
        });
    }

    // Sort by spike count (most significant first)
    sites.sort_by(|a, b| b.spike_count.cmp(&a.spike_count));
    sites
}

impl ClusteredBindingSite {
    /// Enhance this binding site with aromatic proximity analysis
    ///
    /// Updates the aromatic_proximity field and recalculates druggability score.
    ///
    /// # Arguments
    /// * `aromatic_positions` - List of (residue_id, aromatic_type, [x, y, z])
    ///   - aromatic_type: 0=TRP, 1=TYR, 2=PHE
    pub fn compute_aromatic_proximity(&mut self, aromatic_positions: &[(u32, u8, [f32; 3])]) {
        let info = AromaticProximityInfo::compute(&self.centroid, aromatic_positions);

        // Recalculate druggability with aromatic info
        self.druggability = DruggabilityScore::from_site_with_aromatics(
            self.estimated_volume,
            self.avg_intensity,
            &self.bounding_box,
            Some(&info),
        );

        // Update quality score
        let spike_quality = (self.spike_count as f32 / 100.0).clamp(0.0, 1.0);
        let intensity_quality = (self.avg_intensity / 10.0).clamp(0.0, 1.0);
        self.quality_score = 0.25 * spike_quality
            + 0.25 * intensity_quality
            + 0.3 * self.druggability.overall
            + 0.2 * info.aromatic_score;

        self.aromatic_proximity = Some(info);
    }

    /// Check if this site has been analyzed for aromatic proximity
    pub fn has_aromatic_analysis(&self) -> bool {
        self.aromatic_proximity.is_some()
    }

    /// Get the aromatic score (0.0 if not analyzed)
    pub fn aromatic_score(&self) -> f32 {
        self.aromatic_proximity
            .as_ref()
            .map(|p| p.aromatic_score)
            .unwrap_or(0.0)
    }

    /// Compute residues lining this binding pocket
    ///
    /// Finds all residues with at least one atom within `cutoff` distance
    /// of the pocket centroid.
    ///
    /// # Arguments
    /// * `positions` - Atom positions as flat [x0,y0,z0,x1,y1,z1,...] array
    /// * `residue_ids` - Residue ID for each atom
    /// * `residue_names` - Name of each residue (indexed by residue_id)
    /// * `chain_ids` - Chain ID for each atom
    /// * `cutoff` - Distance cutoff in Angstroms (default: 5.0)
    pub fn compute_lining_residues(
        &mut self,
        positions: &[f32],
        residue_ids: &[usize],
        residue_names: &[String],
        chain_ids: &[String],
        residue_pdb_ids: &[i32],
        cutoff: f32,
    ) {
        use std::collections::HashMap;

        let n_atoms = positions.len() / 3;
        let cx = self.centroid[0];
        let cy = self.centroid[1];
        let cz = self.centroid[2];
        let cutoff_sq = cutoff * cutoff;

        // Track per-residue: (chain, resname, min_distance, atom_count)
        let mut residue_info: HashMap<(String, i32), (String, f32, usize)> = HashMap::new();

        // Accumulate pocket atom positions for centroid refinement
        let mut pocket_sum = [0.0f64; 3];
        let mut pocket_count = 0u32;

        for i in 0..n_atoms {
            let x = positions[i * 3];
            let y = positions[i * 3 + 1];
            let z = positions[i * 3 + 2];

            let dx = x - cx;
            let dy = y - cy;
            let dz = z - cz;
            let dist_sq = dx * dx + dy * dy + dz * dz;

            if dist_sq <= cutoff_sq {
                // Accumulate for pocket centroid
                pocket_sum[0] += x as f64;
                pocket_sum[1] += y as f64;
                pocket_sum[2] += z as f64;
                pocket_count += 1;

                let internal_id = residue_ids[i];
                let res_id = if internal_id < residue_pdb_ids.len() { residue_pdb_ids[internal_id] + 1 } else { (internal_id + 1) as i32 };
                let chain = chain_ids[i].clone();
                let resname = if i < residue_names.len() {
                    residue_names[i].clone()
                } else {
                    "UNK".to_string()
                };
                let dist = dist_sq.sqrt();

                let key = (chain.clone(), res_id as i32);
                residue_info
                    .entry(key)
                    .and_modify(|(_, min_d, count)| {
                        if dist < *min_d {
                            *min_d = dist;
                        }
                        *count += 1;
                    })
                    .or_insert((resname, dist, 1));
            }
        }

        // Refine centroid: shift from aromatic probe position toward pocket interior.
        // The spike centroid sits at the aromatic ring (pocket wall). The actual pocket
        // center is shifted toward the protein interior. We detect the interior direction
        // using a large (15Ã…) hemisphere count: more atoms on the protein-interior side
        // than the solvent-exposed side gives the correction vector and magnitude.
        if pocket_count >= 10 {
            // Protein center of mass
            let mut com = [0.0f64; 3];
            for j in 0..n_atoms {
                com[0] += positions[j * 3] as f64;
                com[1] += positions[j * 3 + 1] as f64;
                com[2] += positions[j * 3 + 2] as f64;
            }
            let na = n_atoms as f64;
            com[0] /= na;
            com[1] /= na;
            com[2] /= na;

            // Direction from spike centroid toward protein COM
            let dir = [com[0] - cx as f64, com[1] - cy as f64, com[2] - cz as f64];
            let dir_mag = (dir[0] * dir[0] + dir[1] * dir[1] + dir[2] * dir[2]).sqrt();

            if dir_mag > 0.5 {
                let ux = dir[0] / dir_mag;
                let uy = dir[1] / dir_mag;
                let uz = dir[2] / dir_mag;

                // Use 15Ã… sphere for asymmetry detection (much larger than lining cutoff)
                // to capture the surface-vs-interior signal that's invisible at 8Ã….
                let asym_radius_sq = 15.0f64 * 15.0;
                let mut toward = 0u32;
                let mut away = 0u32;
                for j in 0..n_atoms {
                    let ax = positions[j * 3] as f64 - cx as f64;
                    let ay = positions[j * 3 + 1] as f64 - cy as f64;
                    let az = positions[j * 3 + 2] as f64 - cz as f64;
                    let d2 = ax * ax + ay * ay + az * az;
                    if d2 <= asym_radius_sq {
                        let dot = ax * ux + ay * uy + az * uz;
                        if dot > 0.0 { toward += 1; } else { away += 1; }
                    }
                }

                let total = (toward + away) as f64;
                if total > 0.0 {
                    let asymmetry = (toward as f64 - away as f64) / total;
                    // Shift proportional to asymmetry; max 4Ã….
                    let shift = (asymmetry * 10.0).clamp(0.0, 4.0);
                    if shift > 0.1 {
                        self.centroid[0] += (ux * shift) as f32;
                        self.centroid[1] += (uy * shift) as f32;
                        self.centroid[2] += (uz * shift) as f32;
                    }
                }
            }
        }

        // Convert to LiningResidue list, sorted by distance from refined centroid
        self.lining_residues = residue_info
            .into_iter()
            .map(|((chain, resid), (resname, min_distance, n_atoms))| LiningResidue {
                chain,
                resid,
                resname,
                min_distance,
                n_atoms_in_pocket: n_atoms,
            })
            .collect();

        self.lining_residues.sort_by(|a, b| {
            a.min_distance.partial_cmp(&b.min_distance).unwrap_or(std::cmp::Ordering::Equal)
        });

        // Recompute druggability with catalytic scoring
        self.recompute_druggability_with_catalytic();
    }

    /// Recompute druggability score including catalytic residue analysis
    ///
    /// Called after lining residues are computed to update druggability
    /// for enzyme active sites that would otherwise fail hydrophobic scoring.
    pub fn recompute_druggability_with_catalytic(&mut self) {
        self.druggability = DruggabilityScore::from_site_with_catalytic(
            self.estimated_volume,
            self.avg_intensity,
            &self.bounding_box,
            self.aromatic_proximity.as_ref(),
            &self.lining_residues,
        );
    }

    /// Get lining residue IDs as a simple list (for validation comparisons)
    pub fn lining_residue_ids(&self) -> Vec<i32> {
        self.lining_residues.iter().map(|r| r.resid).collect()
    }

    /// Get formatted residue list string (e.g., "A:PHE347, A:TRP348, A:GLU349")
    pub fn lining_residues_str(&self) -> String {
        self.lining_residues
            .iter()
            .map(|r| format!("{}:{}{}", r.chain, r.resname, r.resid))
            .collect::<Vec<_>>()
            .join(", ")
    }
}

/// Enhance a list of binding sites with aromatic proximity analysis
#[cfg(feature = "gpu")]
pub fn enhance_sites_with_aromatics(
    sites: &mut [ClusteredBindingSite],
    aromatic_positions: &[(u32, u8, [f32; 3])],
) {
    for site in sites.iter_mut() {
        site.compute_aromatic_proximity(aromatic_positions);
    }

    // Re-sort by quality score after enhancement
    sites.sort_by(|a, b| {
        b.quality_score.partial_cmp(&a.quality_score).unwrap_or(std::cmp::Ordering::Equal)
    });
}

/// Batch processor using persistent engine
#[cfg(feature = "gpu")]
pub struct BatchProcessor {
    engine: PersistentNhsEngine,
    config: PersistentBatchConfig,
}

#[cfg(feature = "gpu")]
impl BatchProcessor {
    /// Create batch processor
    pub fn new(config: PersistentBatchConfig) -> Result<Self> {
        let engine = PersistentNhsEngine::new(&config)?;
        Ok(Self { engine, config })
    }

    /// Process multiple topology files
    pub fn process_batch<P: AsRef<Path>>(&mut self, topology_paths: &[P]) -> Result<Vec<StructureResult>> {
        log::info!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        log::info!("  PERSISTENT BATCH PROCESSING: {} structures", topology_paths.len());
        log::info!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

        let batch_start = Instant::now();
        let mut results = Vec::with_capacity(topology_paths.len());

        for (idx, path) in topology_paths.iter().enumerate() {
            let path = path.as_ref();
            log::info!("\n[{}/{}] Processing: {}",
                idx + 1, topology_paths.len(), path.display());

            // Load topology
            let topology = PrismPrepTopology::load(path)
                .with_context(|| format!("Failed to load topology: {}", path.display()))?;

            let structure_id = path.file_stem()
                .map(|s| s.to_string_lossy().to_string())
                .unwrap_or_else(|| "unknown".to_string());

            let struct_start = Instant::now();

            // Load into engine
            self.engine.load_topology(&topology)?;

            // Configure unified cryo-UV protocol
            let cryo_uv_protocol = CryoUvProtocol {
                start_temp: self.config.cryo_temp,
                end_temp: self.config.temperature,
                cold_hold_steps: self.config.cryo_hold,
                ramp_steps: self.config.convergence_steps / 2,
                warm_hold_steps: self.config.convergence_steps / 2,
                current_step: 0,
                // UV-LIF coupling (validated parameters)
                uv_burst_energy: 30.0,
                uv_burst_interval: 500,
                uv_burst_duration: 50,
                scan_wavelengths: vec![280.0, 274.0, 258.0],  // TRP, TYR, PHE
                wavelength_dwell_steps: 500,
                ramp_down_steps: 0,
                cold_return_steps: 0,
            };
            self.engine.set_cryo_uv_protocol(cryo_uv_protocol)?;

            // Run all phases
            let total_steps = self.config.survey_steps
                + self.config.convergence_steps
                + self.config.precision_steps;

            let summary = self.engine.run(total_steps)?;

            let wall_time_ms = struct_start.elapsed().as_millis() as u64;

            // Collect spike events
            let spike_events = self.engine.get_spike_events();

            // RT-accelerated clustering of spike positions
            let (clustered_sites, clustering_stats) = if !spike_events.is_empty() {
                // Extract positions for clustering
                let spike_positions: Vec<f32> = spike_events.iter()
                    .flat_map(|s| s.position.iter().copied())
                    .collect();

                // Cluster using RT cores (or fallback)
                let used_rt = self.engine.has_rt_clustering();
                match self.engine.cluster_spikes(&spike_positions) {
                    Ok(result) => {
                        let sites = build_clustered_sites(&spike_events, &result);
                        let stats = ClusteringStats {
                            num_clusters: result.num_clusters,
                            total_neighbors: result.total_neighbors,
                            gpu_time_ms: result.gpu_time_ms,
                            used_rt_cores: used_rt,
                        };
                        log::info!("  ğŸ“Š Clustered {} spikes â†’ {} binding sites ({:.1}ms, {})",
                            spike_events.len(),
                            sites.len(),
                            result.gpu_time_ms,
                            if used_rt { "RT cores" } else { "fallback" });
                        (sites, Some(stats))
                    }
                    Err(e) => {
                        log::warn!("  âš ï¸ Clustering failed: {}", e);
                        (Vec::new(), None)
                    }
                }
            } else {
                (Vec::new(), None)
            };

            results.push(StructureResult {
                structure_id,
                total_steps,
                wall_time_ms,
                spike_events,
                snapshots: self.engine.get_snapshots(),
                final_temperature: summary.end_temperature,
                clustered_sites,
                clustering_stats,
            });

            log::info!("  âœ“ Completed in {}ms ({:.1} steps/sec)",
                wall_time_ms,
                total_steps as f64 / (wall_time_ms as f64 / 1000.0));
        }

        let total_time = batch_start.elapsed();
        let stats = self.engine.stats();

        log::info!("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        log::info!("  BATCH COMPLETE");
        log::info!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        log::info!("  Structures processed: {}", stats.structures_processed);
        log::info!("  Total steps: {}", stats.total_steps_run);
        log::info!("  Total wall time: {:.1}s", total_time.as_secs_f64());
        log::info!("  Overhead saved (persistent): {}ms", stats.overhead_saved_ms);
        log::info!("  Avg throughput: {:.0} steps/sec",
            stats.total_steps_run as f64 / total_time.as_secs_f64());

        Ok(results)
    }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// VISUALIZATION OUTPUT FORMATTERS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/// Output formatter for binding site visualization
pub struct BindingSiteFormatter;

impl BindingSiteFormatter {
    /// Generate PDB file with pseudo-atoms at binding site centroids
    ///
    /// Creates HETATM records with:
    /// - Atom name "BS" (Binding Site)
    /// - Residue name based on classification (DRG=druggable, CRY=cryptic, etc.)
    /// - B-factor = quality score * 100
    /// - Occupancy = druggability score
    pub fn to_pdb(sites: &[ClusteredBindingSite]) -> String {
        let mut pdb = String::new();
        pdb.push_str("REMARK   PRISM4D Binding Site Detection Results\n");
        pdb.push_str("REMARK   Pseudo-atoms at binding site centroids\n");
        pdb.push_str("REMARK   B-factor = quality score * 100\n");
        pdb.push_str("REMARK   Occupancy = druggability score\n");
        pdb.push_str("REMARK\n");

        for (idx, site) in sites.iter().enumerate() {
            let atom_num = idx + 1;
            let res_name = match site.classification {
                SiteClassification::ActiveSite => "ACT",
                SiteClassification::Allosteric => "ALO",
                SiteClassification::Cryptic => "CRY",
                SiteClassification::PpiSurface => "PPI",
                SiteClassification::MembraneInterface => "MEM",
                SiteClassification::Unknown => "UNK",
            };

            // PDB HETATM format
            // HETATM    1  BS  DRG A   1      10.000  20.000  30.000  0.80 50.00
            pdb.push_str(&format!(
                "HETATM{:5}  BS  {} A{:4}    {:8.3}{:8.3}{:8.3}{:6.2}{:6.2}\n",
                atom_num,
                res_name,
                atom_num,
                site.centroid[0],
                site.centroid[1],
                site.centroid[2],
                site.druggability.overall,
                site.quality_score * 100.0,
            ));
        }

        pdb.push_str("END\n");
        pdb
    }

    /// Generate PyMOL script for visualization
    ///
    /// Creates industry-standard pocket visualization with:
    /// - Lining residues shown as sticks
    /// - Pocket surface (transparent)
    /// - Residue type coloring (catalytic=magenta, aromatic=green, hydrophobic=yellow)
    /// - Centroid marker (small sphere)
    pub fn to_pymol(sites: &[ClusteredBindingSite], structure_name: &str) -> String {
        let mut script = String::new();

        script.push_str("# PRISM4D Binding Site Visualization\n");
        script.push_str("# Generated by prism-nhs\n");
        script.push_str("# Industry-standard pocket visualization\n\n");

        // Setup commands
        script.push_str("# Setup\n");
        script.push_str("bg_color white\n");
        script.push_str("set cartoon_fancy_helices, 1\n");
        script.push_str("set cartoon_side_chain_helper, 1\n");
        script.push_str("set surface_quality, 1\n\n");

        // Load structure placeholder
        if !structure_name.is_empty() {
            script.push_str(&format!("# Load your structure (adjust path as needed)\n"));
            script.push_str(&format!("# load {}.pdb, protein\n", structure_name));
            script.push_str("# show cartoon, protein\n");
            script.push_str("# color gray80, protein\n\n");
        }

        // Process each binding site
        for (idx, site) in sites.iter().enumerate() {
            let site_num = idx + 1;
            let [x, y, z] = site.centroid;
            let druggable_tag = if site.druggability.is_druggable { " [DRUGGABLE]" } else { "" };

            script.push_str(&format!("# ========== Site {} ({:?}){} ==========\n",
                site_num, site.classification, druggable_tag));

            // Skip if no lining residues
            if site.lining_residues.is_empty() {
                script.push_str(&format!("# No lining residues for site {}\n", site_num));
                script.push_str(&format!("pseudoatom site_{}_center, pos=[{:.3}, {:.3}, {:.3}]\n",
                    site_num, x, y, z));
                script.push_str(&format!("show spheres, site_{}_center\n", site_num));
                script.push_str(&format!("set sphere_scale, 1.0, site_{}_center\n", site_num));
                script.push_str(&format!("color red, site_{}_center\n\n", site_num));
                continue;
            }

            // Build residue selection string
            let residue_sel: Vec<String> = site.lining_residues.iter()
                .map(|r| format!("(chain {} and resi {})", r.chain, r.resid))
                .collect();
            let sel_str = residue_sel.join(" or ");

            // Create selection for pocket lining residues
            script.push_str(&format!("select pocket_{}_lining, {}\n", site_num, sel_str));

            // Show lining residues as sticks
            script.push_str(&format!("show sticks, pocket_{}_lining\n", site_num));
            script.push_str(&format!("set stick_radius, 0.15, pocket_{}_lining\n", site_num));

            // Color by residue type
            let catalytic = ["GLU", "ASP", "HIS", "SER", "CYS", "LYS"];
            let aromatic = ["PHE", "TYR", "TRP"];
            let hydrophobic = ["ALA", "VAL", "LEU", "ILE", "MET", "PRO"];

            // Categorize residues
            let cat_residues: Vec<_> = site.lining_residues.iter()
                .filter(|r| catalytic.contains(&r.resname.as_str()))
                .collect();
            let aro_residues: Vec<_> = site.lining_residues.iter()
                .filter(|r| aromatic.contains(&r.resname.as_str()))
                .collect();
            let hydro_residues: Vec<_> = site.lining_residues.iter()
                .filter(|r| hydrophobic.contains(&r.resname.as_str()))
                .collect();

            // Color catalytic residues (magenta/hotpink)
            if !cat_residues.is_empty() {
                let cat_sel: Vec<String> = cat_residues.iter()
                    .map(|r| format!("(chain {} and resi {})", r.chain, r.resid))
                    .collect();
                script.push_str(&format!("select pocket_{}_catalytic, {}\n", site_num, cat_sel.join(" or ")));
                script.push_str(&format!("color magenta, pocket_{}_catalytic\n", site_num));
            }

            // Color aromatic residues (green)
            if !aro_residues.is_empty() {
                let aro_sel: Vec<String> = aro_residues.iter()
                    .map(|r| format!("(chain {} and resi {})", r.chain, r.resid))
                    .collect();
                script.push_str(&format!("select pocket_{}_aromatic, {}\n", site_num, aro_sel.join(" or ")));
                script.push_str(&format!("color forest, pocket_{}_aromatic\n", site_num));
            }

            // Color hydrophobic residues (yellow)
            if !hydro_residues.is_empty() {
                let hydro_sel: Vec<String> = hydro_residues.iter()
                    .map(|r| format!("(chain {} and resi {})", r.chain, r.resid))
                    .collect();
                script.push_str(&format!("select pocket_{}_hydrophobic, {}\n", site_num, hydro_sel.join(" or ")));
                script.push_str(&format!("color tv_yellow, pocket_{}_hydrophobic\n", site_num));
            }

            // Create pocket surface (transparent)
            script.push_str(&format!("create pocket_{}_surface, pocket_{}_lining\n", site_num, site_num));
            script.push_str(&format!("show surface, pocket_{}_surface\n", site_num));
            script.push_str(&format!("set surface_color, slate, pocket_{}_surface\n", site_num));
            script.push_str(&format!("set transparency, 0.7, pocket_{}_surface\n", site_num));

            // Small centroid marker
            script.push_str(&format!("pseudoatom pocket_{}_center, pos=[{:.3}, {:.3}, {:.3}]\n",
                site_num, x, y, z));
            script.push_str(&format!("show spheres, pocket_{}_center\n", site_num));
            script.push_str(&format!("set sphere_scale, 0.5, pocket_{}_center\n", site_num));
            let center_color = if site.druggability.is_druggable { "red" } else { "gray50" };
            script.push_str(&format!("color {}, pocket_{}_center\n", center_color, site_num));

            // Group all pocket objects
            script.push_str(&format!(
                "group pocket_{}, pocket_{}_lining pocket_{}_surface pocket_{}_center",
                site_num, site_num, site_num, site_num
            ));
            if !cat_residues.is_empty() {
                script.push_str(&format!(" pocket_{}_catalytic", site_num));
            }
            if !aro_residues.is_empty() {
                script.push_str(&format!(" pocket_{}_aromatic", site_num));
            }
            if !hydro_residues.is_empty() {
                script.push_str(&format!(" pocket_{}_hydrophobic", site_num));
            }
            script.push_str("\n\n");
        }

        // Group all pockets
        if !sites.is_empty() {
            let pocket_groups: Vec<String> = (1..=sites.len()).map(|i| format!("pocket_{}", i)).collect();
            script.push_str(&format!("group all_pockets, {}\n\n", pocket_groups.join(" ")));
        }

        // Add legend and usage tips
        script.push_str("# ========== Color Legend ==========\n");
        script.push_str("# Magenta = Catalytic residues (GLU, ASP, HIS, SER, CYS, LYS)\n");
        script.push_str("# Green = Aromatic residues (PHE, TYR, TRP) - pi-stacking\n");
        script.push_str("# Yellow = Hydrophobic residues (ALA, VAL, LEU, ILE, MET, PRO)\n");
        script.push_str("# Slate surface = Pocket cavity\n");
        script.push_str("# Red sphere = Druggable site centroid\n");
        script.push_str("# Gray sphere = Non-druggable site centroid\n\n");

        script.push_str("# ========== Usage Tips ==========\n");
        script.push_str("# To view specific pocket: disable all_pockets, enable pocket_N\n");
        script.push_str("# To zoom on pocket: zoom pocket_N_lining\n");
        script.push_str("# To show H-bonds: select donors, pocket_N_lining; distance hbonds, donors, acceptors, 3.5\n");
        script.push_str("# To label residues: label pocket_N_lining and name CA, \"%s%s\" % (resn, resi)\n");

        script
    }

    /// Generate ChimeraX script for visualization
    ///
    /// Creates industry-standard pocket visualization with:
    /// - Lining residues shown as sticks
    /// - Pocket surface (transparent)
    /// - Residue type coloring
    pub fn to_chimerax(sites: &[ClusteredBindingSite], structure_name: &str) -> String {
        let mut script = String::new();

        script.push_str("# PRISM4D Binding Site Visualization\n");
        script.push_str("# Generated by prism-nhs\n");
        script.push_str("# Industry-standard pocket visualization\n\n");

        // Setup
        script.push_str("# Setup\n");
        script.push_str("set bgColor white\n");
        script.push_str("lighting soft\n\n");

        // Load structure placeholder
        if !structure_name.is_empty() {
            script.push_str("# Load your structure (adjust path as needed)\n");
            script.push_str(&format!("# open {}.pdb\n", structure_name));
            script.push_str("# cartoon\n");
            script.push_str("# color #1 gray80\n\n");
        }

        // Process each binding site
        for (idx, site) in sites.iter().enumerate() {
            let site_num = idx + 1;
            let [x, y, z] = site.centroid;
            let druggable_tag = if site.druggability.is_druggable { " [DRUGGABLE]" } else { "" };

            script.push_str(&format!("# ========== Site {} ({:?}){} ==========\n",
                site_num, site.classification, druggable_tag));

            // Skip if no lining residues
            if site.lining_residues.is_empty() {
                script.push_str(&format!("# No lining residues for site {}\n", site_num));
                script.push_str(&format!("marker #10{} position {:.3},{:.3},{:.3} color red radius 2.0\n\n",
                    site_num, x, y, z));
                continue;
            }

            // Build residue selection string for ChimeraX
            let residue_sel: Vec<String> = site.lining_residues.iter()
                .map(|r| format!("/{}:{}", r.chain, r.resid))
                .collect();
            let sel_str = residue_sel.join(",");

            // Select and show lining residues
            script.push_str(&format!("# Pocket {} lining residues\n", site_num));
            script.push_str(&format!("name pocket{}_lining #1{}\n", site_num, sel_str));
            script.push_str(&format!("show pocket{}_lining atoms\n", site_num));
            script.push_str(&format!("style pocket{}_lining stick\n", site_num));

            // Categorize and color residues
            let catalytic = ["GLU", "ASP", "HIS", "SER", "CYS", "LYS"];
            let aromatic = ["PHE", "TYR", "TRP"];
            let hydrophobic = ["ALA", "VAL", "LEU", "ILE", "MET", "PRO"];

            // Color catalytic residues (magenta)
            let cat_residues: Vec<_> = site.lining_residues.iter()
                .filter(|r| catalytic.contains(&r.resname.as_str()))
                .collect();
            if !cat_residues.is_empty() {
                let cat_sel: Vec<String> = cat_residues.iter()
                    .map(|r| format!("/{}:{}", r.chain, r.resid))
                    .collect();
                script.push_str(&format!("color #1{} magenta\n", cat_sel.join(",")));
            }

            // Color aromatic residues (forest green)
            let aro_residues: Vec<_> = site.lining_residues.iter()
                .filter(|r| aromatic.contains(&r.resname.as_str()))
                .collect();
            if !aro_residues.is_empty() {
                let aro_sel: Vec<String> = aro_residues.iter()
                    .map(|r| format!("/{}:{}", r.chain, r.resid))
                    .collect();
                script.push_str(&format!("color #1{} forest green\n", aro_sel.join(",")));
            }

            // Color hydrophobic residues (gold)
            let hydro_residues: Vec<_> = site.lining_residues.iter()
                .filter(|r| hydrophobic.contains(&r.resname.as_str()))
                .collect();
            if !hydro_residues.is_empty() {
                let hydro_sel: Vec<String> = hydro_residues.iter()
                    .map(|r| format!("/{}:{}", r.chain, r.resid))
                    .collect();
                script.push_str(&format!("color #1{} gold\n", hydro_sel.join(",")));
            }

            // Create pocket surface
            script.push_str(&format!("surface pocket{}_lining\n", site_num));
            script.push_str(&format!("transparency pocket{}_lining 70\n", site_num));
            script.push_str(&format!("color pocket{}_lining slate gray\n", site_num));

            // Centroid marker
            let marker_color = if site.druggability.is_druggable { "red" } else { "gray" };
            script.push_str(&format!("marker #10{} position {:.3},{:.3},{:.3} color {} radius 1.0\n",
                site_num, x, y, z, marker_color));

            // Label
            script.push_str(&format!("2dlabels text \"Pocket {} ({:.0}% druggable){}\" xpos 0.02 ypos {:.2} color black size 14\n",
                site_num,
                site.druggability.overall * 100.0,
                if site.druggability.is_druggable { " *" } else { "" },
                0.95 - idx as f32 * 0.04
            ));

            script.push_str("\n");
        }

        // Legend
        script.push_str("# ========== Color Legend ==========\n");
        script.push_str("# Magenta = Catalytic residues (GLU, ASP, HIS, SER, CYS, LYS)\n");
        script.push_str("# Forest Green = Aromatic residues (PHE, TYR, TRP)\n");
        script.push_str("# Gold = Hydrophobic residues (ALA, VAL, LEU, ILE, MET, PRO)\n");
        script.push_str("# Slate surface = Pocket cavity\n");
        script.push_str("# Red marker = Druggable site centroid\n");
        script.push_str("# Gray marker = Non-druggable site centroid\n\n");

        script.push_str("# ========== Usage ==========\n");
        script.push_str("# To view pocket: view pocket1_lining\n");
        script.push_str("# To hide surface: hide pocket1_lining surface\n");
        script.push_str("# To show H-bonds: hbonds pocket1_lining\n");

        script
    }

    /// Generate summary report in Markdown format
    pub fn to_markdown_report(
        sites: &[ClusteredBindingSite],
        structure_name: &str,
        persistence: Option<&PersistenceAnalysis>,
    ) -> String {
        let mut report = String::new();

        report.push_str(&format!("# PRISM4D Binding Site Analysis: {}\n\n", structure_name));

        // Summary statistics
        report.push_str("## Summary\n\n");
        report.push_str(&format!("- **Total Sites Detected:** {}\n", sites.len()));

        let druggable_count = sites.iter().filter(|s| s.druggability.is_druggable).count();
        report.push_str(&format!("- **Druggable Sites:** {}\n", druggable_count));

        // Classification breakdown
        let mut class_counts = std::collections::HashMap::new();
        for site in sites {
            *class_counts.entry(format!("{:?}", site.classification)).or_insert(0) += 1;
        }
        report.push_str("\n### Classification Breakdown\n\n");
        for (class, count) in class_counts {
            report.push_str(&format!("- {}: {}\n", class, count));
        }

        // Persistence info if available
        if let Some(pers) = persistence {
            report.push_str("\n## Persistence Analysis\n\n");
            report.push_str(&format!("- **Total Frames Analyzed:** {}\n", pers.total_frames));
            report.push_str(&format!("- **Persistent Sites (>50% frames):** {}\n", pers.persistent_count));
            report.push_str(&format!("- **Transient Sites (<50% frames):** {}\n", pers.transient_count));
            report.push_str(&format!("- **Average Site Lifetime:** {:.1} frames\n", pers.avg_lifetime));
        }

        // Top sites table
        report.push_str("\n## Top Binding Sites\n\n");
        report.push_str("| Rank | Position (Ã…) | Volume (Ã…Â³) | Spikes | Quality | Druggable | Class |\n");
        report.push_str("|------|--------------|-------------|--------|---------|-----------|-------|\n");

        for (idx, site) in sites.iter().take(10).enumerate() {
            report.push_str(&format!(
                "| {} | ({:.1}, {:.1}, {:.1}) | {:.0} | {} | {:.2} | {} | {:?} |\n",
                idx + 1,
                site.centroid[0], site.centroid[1], site.centroid[2],
                site.estimated_volume,
                site.spike_count,
                site.quality_score,
                if site.druggability.is_druggable { "âœ“" } else { "âœ—" },
                site.classification,
            ));
        }

        // Lining residues for top sites
        report.push_str("\n## Binding Site Residues (5Ã… cutoff)\n\n");
        for (idx, site) in sites.iter().take(10).enumerate() {
            if !site.lining_residues.is_empty() {
                report.push_str(&format!("### Site {} ({:?})\n\n", idx + 1, site.classification));
                report.push_str("| Chain | ResID | ResName | Distance (Ã…) | Atoms |\n");
                report.push_str("|-------|-------|---------|--------------|-------|\n");
                for res in site.lining_residues.iter().take(20) {
                    report.push_str(&format!(
                        "| {} | {} | {} | {:.2} | {} |\n",
                        res.chain, res.resid, res.resname, res.min_distance, res.n_atoms_in_pocket
                    ));
                }
                if site.lining_residues.len() > 20 {
                    report.push_str(&format!("| ... | {} more residues | | | |\n",
                        site.lining_residues.len() - 20));
                }
                report.push_str("\n");
            }
        }

        report
    }
}

/// Write binding sites to multiple visualization formats
pub fn write_binding_site_visualizations(
    sites: &[ClusteredBindingSite],
    base_path: &std::path::Path,
    structure_name: &str,
) -> Result<()> {
    use std::fs;
    use std::io::Write;

    // Write PDB
    let pdb_path = base_path.with_extension("binding_sites.pdb");
    let mut pdb_file = fs::File::create(&pdb_path)?;
    pdb_file.write_all(BindingSiteFormatter::to_pdb(sites).as_bytes())?;
    log::info!("Wrote binding sites PDB: {}", pdb_path.display());

    // Write PyMOL script
    let pml_path = base_path.with_extension("binding_sites.pml");
    let mut pml_file = fs::File::create(&pml_path)?;
    pml_file.write_all(BindingSiteFormatter::to_pymol(sites, structure_name).as_bytes())?;
    log::info!("Wrote PyMOL script: {}", pml_path.display());

    // Write ChimeraX script
    let cxc_path = base_path.with_extension("binding_sites.cxc");
    let mut cxc_file = fs::File::create(&cxc_path)?;
    cxc_file.write_all(BindingSiteFormatter::to_chimerax(sites, structure_name).as_bytes())?;
    log::info!("Wrote ChimeraX script: {}", cxc_path.display());

    // Write Markdown report
    let md_path = base_path.with_extension("binding_sites.md");
    let mut md_file = fs::File::create(&md_path)?;
    md_file.write_all(BindingSiteFormatter::to_markdown_report(sites, structure_name, None).as_bytes())?;
    log::info!("Wrote Markdown report: {}", md_path.display());

    Ok(())
}

// Stub for non-GPU builds
#[cfg(not(feature = "gpu"))]
pub struct PersistentNhsEngine;

#[cfg(not(feature = "gpu"))]
impl PersistentNhsEngine {
    pub fn new(_config: &PersistentBatchConfig) -> Result<Self> {
        bail!("GPU feature required for PersistentNhsEngine")
    }
}

#[cfg(not(feature = "gpu"))]
pub struct BatchProcessor;

#[cfg(not(feature = "gpu"))]
impl BatchProcessor {
    pub fn new(_config: PersistentBatchConfig) -> Result<Self> {
        bail!("GPU feature required for BatchProcessor")
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_default_config() {
        let config = PersistentBatchConfig::default();
        assert_eq!(config.max_atoms, 15000);
        assert_eq!(config.temperature, 300.0);
    }
}
