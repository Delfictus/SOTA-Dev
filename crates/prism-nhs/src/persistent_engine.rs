//! Persistent NHS Engine for High-Throughput Batch Processing
//!
//! Keeps CUDA context, modules, and buffers alive across multiple structures.
//! Hot-swaps topologies without reinitializing GPU state.
//!
//! ## Performance Benefits
//! - Single CUDA context creation (~100ms saved per structure)
//! - Single PTX compilation (~200ms saved per structure)
//! - Buffer reuse for similar-sized structures
//! - Pipelined data transfer during compute
//!
//! ## Usage
//! ```no_run
//! let mut engine = PersistentNhsEngine::new(max_atoms)?;
//! for topology in topologies {
//!     engine.load_topology(&topology)?;
//!     let results = engine.run(steps, config)?;
//! }
//! ```

use anyhow::{bail, Context, Result};
use std::sync::Arc;
use std::path::Path;
use std::time::Instant;

#[cfg(feature = "gpu")]
use cudarc::driver::{
    CudaContext, CudaSlice, CudaStream, CudaFunction, CudaModule,
    LaunchConfig, PushKernelArg, DevicePtrMut,
};
#[cfg(feature = "gpu")]
use cudarc::nvrtc::Ptx;

use crate::input::PrismPrepTopology;

#[allow(deprecated)]
use crate::fused_engine::{
    NhsAmberFusedEngine, CryoUvProtocol,
    // Deprecated - kept for backward compatibility
    TemperatureProtocol,
    UvProbeConfig,
    StepResult, RunSummary, SpikeEvent, EnsembleSnapshot,
};

/// Configuration for persistent batch processing
#[derive(Debug, Clone)]
pub struct PersistentBatchConfig {
    /// Maximum atoms to pre-allocate for (prevents reallocation)
    pub max_atoms: usize,
    /// Grid dimension for exclusion field
    pub grid_dim: usize,
    /// Grid spacing in Angstroms
    pub grid_spacing: f32,
    /// Survey phase steps (cryo)
    pub survey_steps: i32,
    /// Convergence phase steps (warming)
    pub convergence_steps: i32,
    /// Precision phase steps (production)
    pub precision_steps: i32,
    /// Target temperature (K)
    pub temperature: f32,
    /// Cryo temperature (K)
    pub cryo_temp: f32,
    /// Cryo hold steps before warming
    pub cryo_hold: i32,
}

impl Default for PersistentBatchConfig {
    fn default() -> Self {
        Self {
            max_atoms: 15000,  // Handle 4B7Q (~12K atoms) with margin
            grid_dim: 64,
            grid_spacing: 1.5,
            survey_steps: 500000,    // 1ns
            convergence_steps: 1000000, // 2ns
            precision_steps: 1000000,   // 2ns
            temperature: 300.0,
            cryo_temp: 100.0,
            cryo_hold: 100000,
        }
    }
}

/// Result from processing a single structure
#[derive(Debug, Clone)]
pub struct StructureResult {
    pub structure_id: String,
    pub total_steps: i32,
    pub wall_time_ms: u64,
    pub spike_events: Vec<SpikeEvent>,
    pub snapshots: Vec<EnsembleSnapshot>,
    pub final_temperature: f32,
    /// Clustered binding sites from RT-accelerated spatial analysis
    pub clustered_sites: Vec<ClusteredBindingSite>,
    /// RT clustering statistics
    pub clustering_stats: Option<ClusteringStats>,
}

/// A clustered binding site detected from spike spatial patterns
#[derive(Debug, Clone)]
pub struct ClusteredBindingSite {
    /// Cluster ID (unique per analysis run)
    pub cluster_id: i32,
    /// Centroid position [x, y, z] in Angstroms
    pub centroid: [f32; 3],
    /// Number of spikes in this cluster
    pub spike_count: usize,
    /// Spike indices belonging to this cluster
    pub spike_indices: Vec<usize>,
    /// Average spike intensity in cluster
    pub avg_intensity: f32,
    /// Estimated volume (convex hull approximation) in Ã…Â³
    pub estimated_volume: f32,
    /// Bounding box dimensions [dx, dy, dz] in Angstroms
    pub bounding_box: [f32; 3],
    /// Quality score for this binding site (0.0-1.0)
    pub quality_score: f32,
    /// Druggability assessment
    pub druggability: DruggabilityScore,
    /// Site classification
    pub classification: SiteClassification,
}

/// Druggability score for a binding site
#[derive(Debug, Clone, Default)]
pub struct DruggabilityScore {
    /// Overall druggability (0.0-1.0)
    pub overall: f32,
    /// Volume contribution (0.0-1.0) - sites need 200-800 Ã…Â³
    pub volume_score: f32,
    /// Enclosure score (0.0-1.0) - how enclosed the pocket is
    pub enclosure_score: f32,
    /// Hydrophobicity score (0.0-1.0) - dewetting signal strength
    pub hydrophobicity_score: f32,
    /// Is this likely a druggable pocket?
    pub is_druggable: bool,
}

impl DruggabilityScore {
    /// Compute druggability from binding site properties
    pub fn from_site(volume: f32, avg_intensity: f32, bounding_box: &[f32; 3]) -> Self {
        // Volume scoring: optimal range 200-800 Ã…Â³
        let volume_score = if volume < 100.0 {
            volume / 100.0 * 0.3  // Too small
        } else if volume < 200.0 {
            0.3 + (volume - 100.0) / 100.0 * 0.4  // Getting better
        } else if volume <= 800.0 {
            0.7 + (1.0 - (volume - 200.0) / 600.0 * 0.3).max(0.7)  // Optimal
        } else if volume <= 1500.0 {
            0.7 - (volume - 800.0) / 700.0 * 0.3  // Large but ok
        } else {
            0.4 - (volume - 1500.0) / 2000.0 * 0.2  // Too large (surface area)
        }.clamp(0.0, 1.0);

        // Enclosure: ratio of volume to bounding box volume
        let bb_volume = bounding_box[0] * bounding_box[1] * bounding_box[2];
        let enclosure_score = if bb_volume > 0.0 {
            (volume / bb_volume).clamp(0.0, 1.0) * 0.7 + 0.3  // Bias toward enclosed
        } else {
            0.0
        };

        // Hydrophobicity: spike intensity indicates dewetting strength
        let hydrophobicity_score = (avg_intensity / 10.0).clamp(0.0, 1.0);

        // Overall: weighted combination
        let overall = 0.4 * volume_score + 0.3 * enclosure_score + 0.3 * hydrophobicity_score;

        // Druggable threshold: overall >= 0.5 AND volume in reasonable range
        let is_druggable = overall >= 0.5 && volume >= 100.0 && volume <= 2000.0;

        Self {
            overall,
            volume_score,
            enclosure_score,
            hydrophobicity_score,
            is_druggable,
        }
    }
}

/// Classification of detected binding site
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum SiteClassification {
    /// Traditional active site (large, persistent)
    ActiveSite,
    /// Allosteric binding site (remote from active site)
    Allosteric,
    /// Cryptic site (only appears transiently)
    Cryptic,
    /// Protein-protein interaction surface
    PpiSurface,
    /// Membrane interface region
    MembraneInterface,
    /// Unclassified
    Unknown,
}

impl Default for SiteClassification {
    fn default() -> Self {
        Self::Unknown
    }
}

impl SiteClassification {
    /// Classify based on spike patterns and volume
    pub fn from_properties(spike_count: usize, volume: f32, _avg_intensity: f32) -> Self {
        if volume >= 400.0 && spike_count >= 50 {
            Self::ActiveSite
        } else if volume >= 200.0 && volume <= 600.0 && spike_count >= 20 {
            Self::Cryptic  // Moderate size, fewer spikes â†’ transient
        } else if volume >= 150.0 && spike_count >= 10 {
            Self::Allosteric
        } else if volume >= 800.0 {
            Self::PpiSurface  // Large surface areas
        } else {
            Self::Unknown
        }
    }
}

/// Statistics from RT clustering
#[derive(Debug, Clone)]
pub struct ClusteringStats {
    /// Number of clusters found
    pub num_clusters: usize,
    /// Total neighbor pairs examined
    pub total_neighbors: usize,
    /// GPU time in milliseconds
    pub gpu_time_ms: f64,
    /// Whether RT cores were used (vs fallback)
    pub used_rt_cores: bool,
}

/// Persistent engine that keeps GPU state alive across structures
#[cfg(feature = "gpu")]
pub struct PersistentNhsEngine {
    /// Shared CUDA context (kept alive)
    context: Arc<CudaContext>,
    /// Compiled module (kept alive)
    module: Arc<CudaModule>,
    /// Stream for operations
    stream: Arc<CudaStream>,

    /// Currently loaded engine instance
    engine: Option<NhsAmberFusedEngine>,

    /// RT-accelerated clustering engine (lazy initialized)
    rt_engine: Option<crate::rt_clustering::RtClusteringEngine>,

    /// Pre-allocated buffer capacity
    max_atoms: usize,

    /// Grid configuration
    grid_dim: usize,
    grid_spacing: f32,

    /// Current topology ID
    current_topology_id: Option<String>,

    /// Initialization time tracking
    context_init_time_ms: u64,
    module_init_time_ms: u64,

    /// RT engine initialization time (if initialized)
    rt_init_time_ms: Option<u64>,

    /// Cumulative statistics
    structures_processed: usize,
    total_steps_run: i64,
    total_compute_time_ms: u64,
}

#[cfg(feature = "gpu")]
impl PersistentNhsEngine {
    /// Create persistent engine with pre-allocated capacity
    pub fn new(config: &PersistentBatchConfig) -> Result<Self> {
        log::info!("ğŸš€ Initializing Persistent NHS Engine (max_atoms: {})", config.max_atoms);

        // Time context creation
        let ctx_start = Instant::now();
        let context = CudaContext::new(0)
            .context("Failed to create CUDA context")?;
        let context_init_time_ms = ctx_start.elapsed().as_millis() as u64;
        log::info!("  CUDA context: {}ms", context_init_time_ms);

        // Time module loading
        let mod_start = Instant::now();

        // Try multiple PTX locations
        let ptx_candidates = [
            "../prism-gpu/src/kernels/nhs_amber_fused.ptx",  // From workspace
            "crates/prism-gpu/src/kernels/nhs_amber_fused.ptx",  // From root
            "target/ptx/nhs_amber_fused.ptx",  // Build output
        ];

        let ptx_path = ptx_candidates.iter()
            .find(|p| Path::new(p).exists())
            .ok_or_else(|| anyhow::anyhow!("nhs_amber_fused.ptx not found in any standard location"))?;

        let module = context
            .load_module(Ptx::from_file(ptx_path))
            .context("Failed to load NHS-AMBER fused PTX")?;
        let module_init_time_ms = mod_start.elapsed().as_millis() as u64;
        log::info!("  PTX module: {}ms", module_init_time_ms);

        let stream = context.default_stream();

        log::info!("âœ… Persistent engine ready (total init: {}ms)",
            context_init_time_ms + module_init_time_ms);

        Ok(Self {
            context,
            module,
            stream,
            engine: None,
            rt_engine: None,  // Lazy initialized on first use
            max_atoms: config.max_atoms,
            grid_dim: config.grid_dim,
            grid_spacing: config.grid_spacing,
            current_topology_id: None,
            context_init_time_ms,
            module_init_time_ms,
            rt_init_time_ms: None,
            structures_processed: 0,
            total_steps_run: 0,
            total_compute_time_ms: 0,
        })
    }

    /// Load a new topology (hot-swap)
    ///
    /// If the new topology fits in existing buffers, reuses them.
    /// Otherwise, reallocates with appropriate capacity.
    pub fn load_topology(&mut self, topology: &PrismPrepTopology) -> Result<()> {
        let topo_id = std::path::Path::new(&topology.source_pdb)
            .file_stem()
            .map(|s| s.to_string_lossy().to_string())
            .unwrap_or_else(|| "unknown".to_string());
        log::info!("ğŸ“¦ Loading topology: {} ({} atoms)", topo_id, topology.n_atoms);

        let load_start = Instant::now();

        // Check if we need to reallocate
        if topology.n_atoms > self.max_atoms {
            log::warn!("  Structure exceeds max_atoms ({}), reallocating to {}",
                self.max_atoms, topology.n_atoms + 1000);
            self.max_atoms = topology.n_atoms + 1000;
        }

        // Create new engine instance with shared context
        // Note: In a more optimized version, we would reuse GPU buffers
        // For now, we benefit from shared context + module
        let engine = NhsAmberFusedEngine::new(
            self.context.clone(),
            topology,
            self.grid_dim,
            self.grid_spacing,
        )?;

        self.engine = Some(engine);
        self.current_topology_id = Some(topo_id.clone());

        let load_time = load_start.elapsed().as_millis() as u64;
        log::info!("  Topology loaded: {}ms", load_time);

        Ok(())
    }

    /// **Configure unified cryo-UV protocol (RECOMMENDED)**
    ///
    /// Sets the integrated cryo-thermal + UV-LIF protocol for the current topology.
    /// This is the canonical PRISM4D cryptic site detection method.
    pub fn set_cryo_uv_protocol(&mut self, protocol: CryoUvProtocol) -> Result<()> {
        if let Some(ref mut engine) = self.engine {
            engine.set_cryo_uv_protocol(protocol)?;
            Ok(())
        } else {
            bail!("No topology loaded")
        }
    }

    /// **DEPRECATED**: Configure temperature protocol separately
    ///
    /// Use `set_cryo_uv_protocol()` instead to configure the unified cryo-UV protocol.
    #[deprecated(since = "1.2.0", note = "Use set_cryo_uv_protocol() instead")]
    pub fn set_temperature_protocol(&mut self, protocol: TemperatureProtocol) -> Result<()> {
        if let Some(ref mut engine) = self.engine {
            #[allow(deprecated)]
            engine.set_temperature_protocol(protocol)?;
            Ok(())
        } else {
            bail!("No topology loaded")
        }
    }

    /// **DEPRECATED**: Configure UV probe separately
    ///
    /// Use `set_cryo_uv_protocol()` instead to configure the unified cryo-UV protocol.
    #[deprecated(since = "1.2.0", note = "Use set_cryo_uv_protocol() instead")]
    pub fn set_uv_config(&mut self, config: UvProbeConfig) -> Result<()> {
        if let Some(ref mut engine) = self.engine {
            #[allow(deprecated)]
            engine.set_uv_config(config);
            Ok(())
        } else {
            bail!("No topology loaded")
        }
    }

    /// Run simulation on current topology
    pub fn run(&mut self, n_steps: i32) -> Result<RunSummary> {
        if let Some(ref mut engine) = self.engine {
            let run_start = Instant::now();
            let summary = engine.run(n_steps)?;
            let run_time = run_start.elapsed().as_millis() as u64;

            self.structures_processed += 1;
            self.total_steps_run += n_steps as i64;
            self.total_compute_time_ms += run_time;

            Ok(summary)
        } else {
            bail!("No topology loaded")
        }
    }

    /// Run simulation and automatically cluster spike events
    ///
    /// Convenience method that:
    /// 1. Runs the simulation for n_steps
    /// 2. Collects spike events
    /// 3. Clusters them using RT cores (or fallback)
    /// 4. Returns structured binding site information
    ///
    /// # Example
    /// ```ignore
    /// let (summary, sites, stats) = engine.run_and_cluster(1_000_000)?;
    /// for site in &sites {
    ///     println!("Binding site at {:?} with {} spikes", site.centroid, site.spike_count);
    /// }
    /// ```
    pub fn run_and_cluster(&mut self, n_steps: i32) -> Result<(RunSummary, Vec<ClusteredBindingSite>, Option<ClusteringStats>)> {
        let summary = self.run(n_steps)?;
        let spike_events = self.get_spike_events();

        if spike_events.is_empty() {
            return Ok((summary, Vec::new(), None));
        }

        // Extract positions
        let positions: Vec<f32> = spike_events.iter()
            .flat_map(|s| s.position.iter().copied())
            .collect();

        // Cluster using RT cores or fallback
        let used_rt = self.has_rt_clustering();
        let result = self.cluster_spikes(&positions)?;
        let sites = build_clustered_sites(&spike_events, &result);
        let stats = ClusteringStats {
            num_clusters: result.num_clusters,
            total_neighbors: result.total_neighbors,
            gpu_time_ms: result.gpu_time_ms,
            used_rt_cores: used_rt,
        };

        Ok((summary, sites, Some(stats)))
    }

    /// Get spike events from current run
    pub fn get_spike_events(&self) -> Vec<SpikeEvent> {
        if let Some(ref engine) = self.engine {
            engine.get_spike_events().to_vec()
        } else {
            Vec::new()
        }
    }

    /// Get snapshots from current run
    pub fn get_snapshots(&self) -> Vec<EnsembleSnapshot> {
        if let Some(ref engine) = self.engine {
            engine.get_ensemble_snapshots().to_vec()
        } else {
            Vec::new()
        }
    }

    /// Get current positions
    pub fn get_positions(&self) -> Result<Vec<f32>> {
        if let Some(ref engine) = self.engine {
            engine.get_positions()
        } else {
            bail!("No topology loaded")
        }
    }

    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    // RT-ACCELERATED CLUSTERING
    // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    /// Check if RT cores are available for accelerated clustering
    pub fn has_rt_clustering(&self) -> bool {
        crate::rt_utils::has_rt_cores() && crate::rt_utils::is_optix_available()
    }

    /// Ensure the RT clustering pipeline is initialized (lazy init)
    ///
    /// Call this explicitly to pre-warm the pipeline, or let it initialize
    /// lazily on first `cluster_spikes()` call.
    pub fn ensure_rt_pipeline(&mut self) -> Result<bool> {
        if self.rt_engine.is_some() {
            return Ok(true);  // Already initialized
        }

        if !self.has_rt_clustering() {
            log::debug!("RT clustering not available (no RT cores or OptiX)");
            return Ok(false);
        }

        log::info!("ğŸ”· Initializing OptiX RT pipeline for clustering...");
        let start = Instant::now();

        // Find the OptiX IR file
        let optixir_path = crate::rt_clustering::find_optixir_path()
            .context("Could not find rt_clustering.optixir")?;

        // Create RT clustering config
        let rt_config = crate::rt_clustering::RtClusteringConfig {
            epsilon: 5.0,         // 5 Angstrom neighborhood
            min_points: 3,        // Minimum 3 neighbors for core point
            min_cluster_size: 50, // Minimum 50 points per cluster
            rays_per_event: 32,   // 32 rays for neighbor finding
        };

        // Create and initialize the RT engine
        let mut rt_engine = crate::rt_clustering::RtClusteringEngine::new(
            self.context.clone(),
            rt_config,
        ).context("Failed to create RT clustering engine")?;

        rt_engine.load_pipeline(&optixir_path)
            .context("Failed to load RT clustering pipeline")?;

        let init_time = start.elapsed().as_millis() as u64;
        self.rt_init_time_ms = Some(init_time);
        self.rt_engine = Some(rt_engine);

        log::info!("  RT pipeline initialized: {}ms", init_time);
        log::info!("  GPU Architecture: {}", crate::rt_utils::get_architecture_name());

        Ok(true)
    }

    /// Cluster spike positions using RT-accelerated spatial queries
    ///
    /// Falls back to grid-based clustering if RT cores are unavailable.
    ///
    /// # Arguments
    /// * `spike_positions` - Flat array of [x, y, z, x, y, z, ...] coordinates
    ///
    /// # Returns
    /// Clustering result with cluster assignments and statistics
    pub fn cluster_spikes(&mut self, spike_positions: &[f32]) -> Result<crate::rt_clustering::RtClusteringResult> {
        let num_spikes = spike_positions.len() / 3;

        // Try RT-accelerated path
        if self.ensure_rt_pipeline()? {
            if let Some(ref mut rt_engine) = self.rt_engine {
                log::debug!("Using RT-accelerated clustering for {} spikes", num_spikes);
                return rt_engine.cluster(spike_positions);
            }
        }

        // Fallback: simple grid-based clustering
        log::debug!("Using fallback grid clustering for {} spikes", num_spikes);
        self.fallback_grid_cluster(spike_positions)
    }

    /// Fallback grid-based clustering when RT cores unavailable
    fn fallback_grid_cluster(&self, positions: &[f32]) -> Result<crate::rt_clustering::RtClusteringResult> {
        let num_points = positions.len() / 3;
        let start = Instant::now();

        // Simple single-linkage clustering using spatial hashing
        // This is O(N) for sparse data but degrades to O(NÂ²) for dense clusters
        let epsilon = 5.0f32;
        let cell_size = epsilon;

        use std::collections::HashMap;

        // Hash points into cells
        let mut cells: HashMap<(i32, i32, i32), Vec<usize>> = HashMap::new();
        for i in 0..num_points {
            let x = positions[i * 3];
            let y = positions[i * 3 + 1];
            let z = positions[i * 3 + 2];
            let cell = (
                (x / cell_size).floor() as i32,
                (y / cell_size).floor() as i32,
                (z / cell_size).floor() as i32,
            );
            cells.entry(cell).or_default().push(i);
        }

        // Union-find for clustering
        let mut parent: Vec<i32> = (0..num_points as i32).collect();

        fn find(parent: &mut [i32], i: usize) -> i32 {
            if parent[i] != i as i32 {
                parent[i] = find(parent, parent[i] as usize);
            }
            parent[i]
        }

        fn union(parent: &mut [i32], a: usize, b: usize) {
            let ra = find(parent, a);
            let rb = find(parent, b);
            if ra != rb {
                parent[ra as usize] = rb;
            }
        }

        // Find neighbors and union
        let mut total_neighbors = 0usize;
        for (&cell, points) in &cells {
            // Check this cell and 26 neighbors
            for dx in -1..=1 {
                for dy in -1..=1 {
                    for dz in -1..=1 {
                        let neighbor_cell = (cell.0 + dx, cell.1 + dy, cell.2 + dz);
                        if let Some(neighbors) = cells.get(&neighbor_cell) {
                            for &i in points {
                                let xi = positions[i * 3];
                                let yi = positions[i * 3 + 1];
                                let zi = positions[i * 3 + 2];

                                for &j in neighbors {
                                    if i >= j { continue; }
                                    let xj = positions[j * 3];
                                    let yj = positions[j * 3 + 1];
                                    let zj = positions[j * 3 + 2];

                                    let dist_sq = (xi - xj).powi(2) + (yi - yj).powi(2) + (zi - zj).powi(2);
                                    if dist_sq <= epsilon * epsilon {
                                        union(&mut parent, i, j);
                                        total_neighbors += 1;
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }

        // Flatten and count clusters
        let mut cluster_ids: Vec<i32> = Vec::with_capacity(num_points);
        let mut cluster_counts: HashMap<i32, usize> = HashMap::new();

        for i in 0..num_points {
            let root = find(&mut parent, i);
            cluster_ids.push(root);
            *cluster_counts.entry(root).or_default() += 1;
        }

        let num_clusters = cluster_counts.len();
        let gpu_time_ms = start.elapsed().as_secs_f64() * 1000.0;

        Ok(crate::rt_clustering::RtClusteringResult {
            cluster_ids,
            num_clusters,
            total_neighbors,
            gpu_time_ms,
        })
    }

    /// Report cumulative statistics
    pub fn stats(&self) -> PersistentEngineStats {
        PersistentEngineStats {
            structures_processed: self.structures_processed,
            total_steps_run: self.total_steps_run,
            total_compute_time_ms: self.total_compute_time_ms,
            context_init_time_ms: self.context_init_time_ms,
            module_init_time_ms: self.module_init_time_ms,
            overhead_saved_ms: self.structures_processed.saturating_sub(1) as u64
                * (self.context_init_time_ms + self.module_init_time_ms),
        }
    }
}

/// Statistics from persistent engine
#[derive(Debug, Clone)]
pub struct PersistentEngineStats {
    pub structures_processed: usize,
    pub total_steps_run: i64,
    pub total_compute_time_ms: u64,
    pub context_init_time_ms: u64,
    pub module_init_time_ms: u64,
    /// Estimated overhead saved by reusing context/module
    pub overhead_saved_ms: u64,
}

/// Convert RT clustering results into binding site structures
#[cfg(feature = "gpu")]
fn build_clustered_sites(
    spike_events: &[SpikeEvent],
    clustering_result: &crate::rt_clustering::RtClusteringResult,
) -> Vec<ClusteredBindingSite> {
    use std::collections::HashMap;

    if spike_events.is_empty() {
        return Vec::new();
    }

    // Group spikes by cluster
    let mut cluster_spikes: HashMap<i32, Vec<(usize, &SpikeEvent)>> = HashMap::new();
    for (idx, (spike, &cluster_id)) in spike_events.iter()
        .zip(clustering_result.cluster_ids.iter())
        .enumerate()
    {
        if cluster_id >= 0 {  // Skip noise points (-1)
            cluster_spikes.entry(cluster_id)
                .or_default()
                .push((idx, spike));
        }
    }

    // Build site structures for each cluster
    let mut sites = Vec::with_capacity(cluster_spikes.len());
    for (cluster_id, spikes) in cluster_spikes {
        if spikes.is_empty() {
            continue;
        }

        // Compute centroid
        let mut centroid = [0.0f32; 3];
        let mut sum_intensity = 0.0f32;
        let mut min_pos = [f32::MAX; 3];
        let mut max_pos = [f32::MIN; 3];

        for (_, spike) in &spikes {
            centroid[0] += spike.position[0];
            centroid[1] += spike.position[1];
            centroid[2] += spike.position[2];
            sum_intensity += spike.intensity;

            // Update bounding box
            for i in 0..3 {
                min_pos[i] = min_pos[i].min(spike.position[i]);
                max_pos[i] = max_pos[i].max(spike.position[i]);
            }
        }

        let n = spikes.len() as f32;
        centroid[0] /= n;
        centroid[1] /= n;
        centroid[2] /= n;

        let bounding_box = [
            max_pos[0] - min_pos[0],
            max_pos[1] - min_pos[1],
            max_pos[2] - min_pos[2],
        ];

        // Estimate volume as bounding box volume (rough approximation)
        let estimated_volume = bounding_box[0] * bounding_box[1] * bounding_box[2];
        let avg_intensity = sum_intensity / n;
        let spike_count = spikes.len();

        // Compute druggability score
        let druggability = DruggabilityScore::from_site(estimated_volume, avg_intensity, &bounding_box);

        // Classify site
        let classification = SiteClassification::from_properties(spike_count, estimated_volume, avg_intensity);

        // Overall quality score: combines spike count, intensity, and druggability
        let spike_quality = (spike_count as f32 / 100.0).clamp(0.0, 1.0);
        let intensity_quality = (avg_intensity / 10.0).clamp(0.0, 1.0);
        let quality_score = 0.3 * spike_quality + 0.3 * intensity_quality + 0.4 * druggability.overall;

        sites.push(ClusteredBindingSite {
            cluster_id,
            centroid,
            spike_count,
            spike_indices: spikes.iter().map(|(idx, _)| *idx).collect(),
            avg_intensity,
            estimated_volume,
            bounding_box,
            quality_score,
            druggability,
            classification,
        });
    }

    // Sort by spike count (most significant first)
    sites.sort_by(|a, b| b.spike_count.cmp(&a.spike_count));
    sites
}

/// Batch processor using persistent engine
#[cfg(feature = "gpu")]
pub struct BatchProcessor {
    engine: PersistentNhsEngine,
    config: PersistentBatchConfig,
}

#[cfg(feature = "gpu")]
impl BatchProcessor {
    /// Create batch processor
    pub fn new(config: PersistentBatchConfig) -> Result<Self> {
        let engine = PersistentNhsEngine::new(&config)?;
        Ok(Self { engine, config })
    }

    /// Process multiple topology files
    pub fn process_batch<P: AsRef<Path>>(&mut self, topology_paths: &[P]) -> Result<Vec<StructureResult>> {
        log::info!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        log::info!("  PERSISTENT BATCH PROCESSING: {} structures", topology_paths.len());
        log::info!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

        let batch_start = Instant::now();
        let mut results = Vec::with_capacity(topology_paths.len());

        for (idx, path) in topology_paths.iter().enumerate() {
            let path = path.as_ref();
            log::info!("\n[{}/{}] Processing: {}",
                idx + 1, topology_paths.len(), path.display());

            // Load topology
            let topology = PrismPrepTopology::load(path)
                .with_context(|| format!("Failed to load topology: {}", path.display()))?;

            let structure_id = path.file_stem()
                .map(|s| s.to_string_lossy().to_string())
                .unwrap_or_else(|| "unknown".to_string());

            let struct_start = Instant::now();

            // Load into engine
            self.engine.load_topology(&topology)?;

            // Configure unified cryo-UV protocol
            let cryo_uv_protocol = CryoUvProtocol {
                start_temp: self.config.cryo_temp,
                end_temp: self.config.temperature,
                cold_hold_steps: self.config.cryo_hold,
                ramp_steps: self.config.convergence_steps / 2,
                warm_hold_steps: self.config.convergence_steps / 2,
                current_step: 0,
                // UV-LIF coupling (validated parameters)
                uv_burst_energy: 30.0,
                uv_burst_interval: 500,
                uv_burst_duration: 50,
                scan_wavelengths: vec![280.0, 274.0, 258.0],  // TRP, TYR, PHE
                wavelength_dwell_steps: 500,
            };
            self.engine.set_cryo_uv_protocol(cryo_uv_protocol)?;

            // Run all phases
            let total_steps = self.config.survey_steps
                + self.config.convergence_steps
                + self.config.precision_steps;

            let summary = self.engine.run(total_steps)?;

            let wall_time_ms = struct_start.elapsed().as_millis() as u64;

            // Collect spike events
            let spike_events = self.engine.get_spike_events();

            // RT-accelerated clustering of spike positions
            let (clustered_sites, clustering_stats) = if !spike_events.is_empty() {
                // Extract positions for clustering
                let spike_positions: Vec<f32> = spike_events.iter()
                    .flat_map(|s| s.position.iter().copied())
                    .collect();

                // Cluster using RT cores (or fallback)
                let used_rt = self.engine.has_rt_clustering();
                match self.engine.cluster_spikes(&spike_positions) {
                    Ok(result) => {
                        let sites = build_clustered_sites(&spike_events, &result);
                        let stats = ClusteringStats {
                            num_clusters: result.num_clusters,
                            total_neighbors: result.total_neighbors,
                            gpu_time_ms: result.gpu_time_ms,
                            used_rt_cores: used_rt,
                        };
                        log::info!("  ğŸ“Š Clustered {} spikes â†’ {} binding sites ({:.1}ms, {})",
                            spike_events.len(),
                            sites.len(),
                            result.gpu_time_ms,
                            if used_rt { "RT cores" } else { "fallback" });
                        (sites, Some(stats))
                    }
                    Err(e) => {
                        log::warn!("  âš ï¸ Clustering failed: {}", e);
                        (Vec::new(), None)
                    }
                }
            } else {
                (Vec::new(), None)
            };

            results.push(StructureResult {
                structure_id,
                total_steps,
                wall_time_ms,
                spike_events,
                snapshots: self.engine.get_snapshots(),
                final_temperature: summary.end_temperature,
                clustered_sites,
                clustering_stats,
            });

            log::info!("  âœ“ Completed in {}ms ({:.1} steps/sec)",
                wall_time_ms,
                total_steps as f64 / (wall_time_ms as f64 / 1000.0));
        }

        let total_time = batch_start.elapsed();
        let stats = self.engine.stats();

        log::info!("\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        log::info!("  BATCH COMPLETE");
        log::info!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        log::info!("  Structures processed: {}", stats.structures_processed);
        log::info!("  Total steps: {}", stats.total_steps_run);
        log::info!("  Total wall time: {:.1}s", total_time.as_secs_f64());
        log::info!("  Overhead saved (persistent): {}ms", stats.overhead_saved_ms);
        log::info!("  Avg throughput: {:.0} steps/sec",
            stats.total_steps_run as f64 / total_time.as_secs_f64());

        Ok(results)
    }
}

// Stub for non-GPU builds
#[cfg(not(feature = "gpu"))]
pub struct PersistentNhsEngine;

#[cfg(not(feature = "gpu"))]
impl PersistentNhsEngine {
    pub fn new(_config: &PersistentBatchConfig) -> Result<Self> {
        bail!("GPU feature required for PersistentNhsEngine")
    }
}

#[cfg(not(feature = "gpu"))]
pub struct BatchProcessor;

#[cfg(not(feature = "gpu"))]
impl BatchProcessor {
    pub fn new(_config: PersistentBatchConfig) -> Result<Self> {
        bail!("GPU feature required for BatchProcessor")
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_default_config() {
        let config = PersistentBatchConfig::default();
        assert_eq!(config.max_atoms, 15000);
        assert_eq!(config.temperature, 300.0);
    }
}
