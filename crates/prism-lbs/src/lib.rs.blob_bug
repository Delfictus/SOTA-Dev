//! PRISM-LBS: Ligand Binding Site Prediction System
//!
//! Reframes binding site prediction as a graph coloring optimization problem
//! leveraging PRISM's quantum-neuromorphic-GPU architecture.
//!
//! ## Features
//! - GPU-accelerated pocket detection (4 CUDA kernels)
//! - FluxNet RL for druggability weight optimization
//! - GNN embeddings for enhanced pocket features
//! - Ensemble prediction with multi-method voting
//! - PDBBind training integration
//! - World-class allosteric site detection (4-stage pipeline)

pub mod allosteric;
pub mod config;
pub mod features;
pub mod graph;
// pub mod output;  // TEMPORARILY DISABLED - missing file
pub mod phases;
pub mod pipeline_integration;
pub mod pocket;
pub mod scoring;
pub mod softspot;
pub mod structure;
pub mod training;
pub mod unified;
pub mod validation;

// Re-exports
// pub use output::{
//     GpuTelemetryData, write_publication_json, write_publication_json_with_telemetry,
// };
pub use allosteric::{
    AllostericDetectionConfig, AllostericDetectionOutput, AllostericDetector, AllostericPocket,
    AllostericDetectionType, ConfidenceAssessment, CoverageGap, Domain, DomainInterface,
    HingeRegion, MultiModuleEvidence,
};
pub use config::{
    DetectionMode, DruggabilityWeights, ProvenanceLevel, QualityPreset, UnifiedHybridConfig,
};
pub use graph::{GraphConfig, ProteinGraph, ProteinGraphBuilder};
pub use pocket::{Pocket, PocketDetector, PocketProperties, PrecisionMode};
pub use scoring::{DrugabilityClass, DruggabilityScore, DruggabilityScorer};
pub use softspot::{CrypticCandidate, CrypticConfidence, SoftSpotDetector};
pub use structure::{Atom, PdbParseOptions, ProteinStructure, Residue};
pub use unified::{
    Confidence, DetectionType, Evidence, UnifiedDetector, UnifiedOutput, UnifiedPocket,
};

use anyhow::Result;
#[cfg(feature = "cuda")]
use prism_gpu::context::GpuContext;
#[cfg(feature = "cuda")]
use prism_gpu::global_context::GlobalGpuContext;
use serde::{Deserialize, Serialize};
use std::path::Path;
#[cfg(feature = "cuda")]
use std::sync::Arc;

/// Main configuration for PRISM-LBS
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LbsConfig {
    /// Graph construction parameters
    pub graph: GraphConfig,
    /// GPU acceleration toggle for LBS-specific kernels
    pub use_gpu: bool,
    /// Pocket geometry parameters
    pub geometry: pocket::GeometryConfig,

    /// Phase-specific configurations
    pub phase0: phases::SurfaceReservoirConfig,
    pub phase1: phases::PocketBeliefConfig,
    pub phase2: phases::PocketSamplingConfig,
    pub phase4: phases::CavityAnalysisConfig,
    pub phase6: phases::TopologicalPocketConfig,

    /// Scoring weights
    pub scoring: scoring::ScoringWeights,

    /// Output options
    pub output: OutputConfig,

    /// Maximum number of pockets to return
    pub top_n: usize,

    /// Pure GPU screening mode: bypass all CPU geometry (Voronoi, Delaunay, fpocket)
    /// Uses only mega-fused GPU kernel for ultra-fast batch processing
    #[cfg(feature = "cuda")]
    #[serde(default)]
    pub pure_gpu_mode: bool,
}

impl Default for LbsConfig {
    fn default() -> Self {
        Self {
            graph: GraphConfig::default(),
            use_gpu: true,
            geometry: pocket::GeometryConfig::default(),
            phase0: phases::SurfaceReservoirConfig::default(),
            phase1: phases::PocketBeliefConfig::default(),
            phase2: phases::PocketSamplingConfig::default(),
            phase4: phases::CavityAnalysisConfig::default(),
            phase6: phases::TopologicalPocketConfig::default(),
            scoring: scoring::ScoringWeights::default(),
            output: OutputConfig::default(),
            top_n: 20,  // Increased from 10 to catch more binding sites
            #[cfg(feature = "cuda")]
            pure_gpu_mode: false,
        }
    }
}

impl LbsConfig {
    /// Load configuration from TOML file
    pub fn from_file(path: &Path) -> anyhow::Result<Self> {
        let config_str = std::fs::read_to_string(path)?;
        let config: LbsConfig = toml::from_str(&config_str)?;
        Ok(config)
    }
}

/// Output configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OutputConfig {
    pub formats: Vec<OutputFormat>,
    pub include_pymol_script: bool,
    pub include_json: bool,
}

impl Default for OutputConfig {
    fn default() -> Self {
        Self {
            formats: vec![OutputFormat::Pdb, OutputFormat::Json],
            include_pymol_script: true,
            include_json: true,
        }
    }
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum OutputFormat {
    Pdb,
    Json,
    Csv,
}

/// Main PRISM-LBS predictor
pub struct PrismLbs {
    config: LbsConfig,
    detector: PocketDetector,
    scorer: DruggabilityScorer,
    #[cfg(feature = "cuda")]
    gpu_ctx: Option<Arc<GpuContext>>,
}

impl PrismLbs {
    /// Create new predictor with given configuration
    pub fn new(config: LbsConfig) -> Result<Self> {
        #[cfg(feature = "cuda")]
        {
            return Self::new_with_gpu(config, None);
        }

        #[cfg(not(feature = "cuda"))]
        {
            let detector = PocketDetector::new(config.clone())?;
            let scorer = DruggabilityScorer::new(config.scoring.clone());

            Ok(Self {
                config,
                detector,
                scorer,
            })
        }
    }

    /// Create predictor while reusing an existing GPU context (when CUDA is available).
    #[cfg(feature = "cuda")]
    pub fn new_with_gpu(config: LbsConfig, gpu_ctx: Option<Arc<GpuContext>>) -> Result<Self> {
        let detector = PocketDetector::new(config.clone())?;
        let scorer = DruggabilityScorer::new(config.scoring.clone());

        let gpu_ctx = if config.use_gpu {
            gpu_ctx.or_else(|| Self::init_gpu_context_from_env().ok())
        } else {
            None
        };

        Ok(Self {
            config,
            detector,
            scorer,
            gpu_ctx,
        })
    }

    #[cfg(feature = "cuda")]
    fn init_gpu_context_from_env() -> Result<Arc<GpuContext>, LbsError> {
        // Trigger GlobalGpuContext initialization ONCE - this loads all PTX files
        // and pre-initializes mega-fused and LBS kernels. The detector will use
        // GlobalGpuContext directly for pocket detection (the main compute path).
        // We return None here to avoid creating a duplicate context.
        match GlobalGpuContext::try_get() {
            Ok(_global_gpu) => {
                log::info!("GlobalGpuContext initialized - detector will use pre-loaded kernels");
                // GlobalGpuContext is initialized; detector will use it directly.
                // Don't create a separate context to avoid duplicate PTX loading.
                // Surface/graph ops will use CPU fallback (minimal perf impact).
                Err(LbsError::Gpu("Using GlobalGpuContext directly (no separate Arc<GpuContext>)".to_string()))
            }
            Err(e) => {
                log::warn!("GlobalGpuContext initialization failed: {}. GPU disabled.", e);
                Err(LbsError::Gpu(format!("GlobalGpuContext init failed: {}", e)))
            }
        }
    }

    /// Load configuration from TOML file
    pub fn from_config_file(path: &Path) -> Result<Self> {
        let config_str = std::fs::read_to_string(path)?;
        let config: LbsConfig = toml::from_str(&config_str)?;
        Self::new(config)
    }

    /// Predict binding sites for a protein structure
    pub fn predict(&self, structure: &ProteinStructure) -> Result<Vec<Pocket>> {
        log::info!("Starting PRISM-LBS prediction for {}", structure.title);

        // 1. Compute surface accessibility (GPU when available/configured)
        let mut structure = structure.clone();
        #[cfg(feature = "cuda")]
        {
            if self.config.use_gpu {
                // Try gpu_ctx first, then fall back to GlobalGpuContext
                let gpu_ctx_ref = self.gpu_ctx.as_ref().map(|arc| arc.as_ref());
                let global_ctx_ref = GlobalGpuContext::try_get().ok().map(|g| g.context());

                if let Some(ctx) = gpu_ctx_ref.or(global_ctx_ref) {
                    let computer = structure::SurfaceComputer::default();
                    computer.compute_gpu(&mut structure, ctx)?;
                } else {
                    log::warn!(
                        "GPU requested for surface computation but no GPU context available; falling back to CPU"
                    );
                    structure.compute_surface_accessibility()?;
                }
            } else {
                structure.compute_surface_accessibility()?;
            }
        }
        #[cfg(not(feature = "cuda"))]
        {
            structure.compute_surface_accessibility()?;
        }

        // 2. Build protein graph
        let graph_builder = ProteinGraphBuilder::new(self.config.graph.clone());
        #[cfg(feature = "cuda")]
        let graph = if self.config.graph.use_gpu {
            // Try gpu_ctx first, then fall back to GlobalGpuContext
            let gpu_ctx_ref = self.gpu_ctx.as_ref().map(|arc| arc.as_ref());
            let global_ctx_ref = GlobalGpuContext::try_get().ok().map(|g| g.context());
            graph_builder.build_with_gpu(&structure, gpu_ctx_ref.or(global_ctx_ref))?
        } else {
            graph_builder.build(&structure)?
        };
        #[cfg(not(feature = "cuda"))]
        let graph = graph_builder.build(&structure)?;

        // 3. Run pocket detection through phases (with GPU when available)
        #[cfg(feature = "cuda")]
        let mut pockets = self.detector.detect_with_gpu(&graph, self.gpu_ctx.as_ref())?;
        #[cfg(not(feature = "cuda"))]
        let mut pockets = self.detector.detect(&graph)?;

        // 3.5 Progressive pocket merging for fragmented binding sites
        // Reduced merge distances to prevent mega-pockets (was 15/20/25, now 12/16/20)
        // Phase 1: Standard merge (kinases, proteases)
        pockets = merge_adjacent_pockets_with_seq(pockets, 12.0, 1, 10);
        // Phase 2: Channel merge (substrate channels like aldose reductase)
        pockets = merge_adjacent_pockets_with_seq(pockets, 16.0, 1, 50);
        // Phase 3: GPCR/membrane protein merge (multi-helix sites)
        pockets = merge_adjacent_pockets_with_seq(pockets, 20.0, 1, 100);

        // 3.6 Expand pocket residues to capture nearby interaction-capable residues
        // This catches residues not directly pocket-lining but within binding distance
        // Use 6Å radius with 80-residue cap (balanced: capture more cryptic site residues)
        // With max_pockets=4 in precision filter, larger pockets improve per-pocket recall
        for pocket in &mut pockets {
            expand_pocket_residues(pocket, &structure.atoms, 6.0, 80);
        }

        // 4. Score pockets (GPU when available)
        #[cfg(feature = "cuda")]
        {
            // Try gpu_ctx first, then fall back to GlobalGpuContext
            let gpu_ctx_ref = self.gpu_ctx.as_ref().map(|arc| arc.as_ref());
            let global_ctx_ref = GlobalGpuContext::try_get().ok().map(|g| g.context());

            if let Some(ctx) = gpu_ctx_ref.or(global_ctx_ref) {
                match self.scorer.score_batch_gpu(&pockets, ctx) {
                    Ok(scores) => {
                        for (pocket, score) in pockets.iter_mut().zip(scores) {
                            pocket.druggability_score = score;
                        }
                    }
                    Err(e) => {
                        log::warn!("GPU batch scoring failed, falling back to CPU: {}", e);
                        for pocket in &mut pockets {
                            pocket.druggability_score = self.scorer.score(pocket);
                        }
                    }
                }
            } else {
                for pocket in &mut pockets {
                    pocket.druggability_score = self.scorer.score(pocket);
                }
            }
        }
        #[cfg(not(feature = "cuda"))]
        {
            for pocket in &mut pockets {
                pocket.druggability_score = self.scorer.score(pocket);
            }
        }

        // 5. Sort by druggability score
        pockets.sort_by(|a, b| {
            b.druggability_score
                .total
                .partial_cmp(&a.druggability_score.total)
                .unwrap()
        });

        // 6. Return top N
        pockets.truncate(self.config.top_n);

        log::info!("Found {} pockets", pockets.len());
        Ok(pockets)
    }

    /// Batch prediction for multiple structures
    pub async fn predict_batch(
        &self,
        structures: Vec<ProteinStructure>,
    ) -> Result<Vec<Vec<Pocket>>> {
        use rayon::prelude::*;

        structures.par_iter().map(|s| self.predict(s)).collect()
    }

    /// ULTRA-FAST PURE GPU DIRECT PATH: No graph construction, no CPU geometry
    ///
    /// This method bypasses ALL CPU-heavy operations:
    /// - NO ProteinGraphBuilder (saves 10.8s per large structure)
    /// - NO surface accessibility computation
    /// - NO Voronoi/Delaunay triangulation
    /// - NO fpocket
    /// - NO belief propagation
    ///
    /// Uses ONLY the mega-fused GPU kernel with 5 flat arrays:
    /// - atom coordinates
    /// - CA indices
    /// - conservation scores
    /// - B-factors
    /// - burial estimates
    ///
    /// Target: 219 structures in under 3 seconds
    #[cfg(feature = "cuda")]
    pub fn predict_pure_gpu(&self, structure: &ProteinStructure) -> Result<Vec<Pocket>> {
        log::info!("PURE GPU DIRECT: Bypassing graph construction for {}", structure.title);

        // Call detector's pure GPU direct method - NO graph construction
        let pockets = self.detector.detect_pure_gpu_direct(structure)?;

        Ok(pockets)
    }

    /// Extract 92-dim features using pure GPU (for ML/viral escape)
    #[cfg(feature = "cuda")]
    pub fn extract_features_pure_gpu(&self, structure: &ProteinStructure) -> Result<Vec<f32>> {
        self.detector.extract_features_pure_gpu(structure)
            .map_err(|e| anyhow::anyhow!("Feature extraction failed: {}", e))
    }

    /// MEGA-BATCH GPU: Process ALL structures in a SINGLE kernel launch
    ///
    /// This is the ULTIMATE batch processing mode:
    /// - ALL structures packed into contiguous GPU arrays
    /// - SINGLE kernel launch for the entire batch
    /// - L1 cache optimization with __ldg() intrinsics
    /// - Register optimization with __launch_bounds__(256, 2)
    ///
    /// Target: 221 structures in <100ms (20-50x faster than sequential)
    #[cfg(feature = "cuda")]
    pub fn predict_batch_true_gpu(
        structures: &[ProteinStructure],
    ) -> Result<Vec<(String, Vec<Pocket>)>> {
        use prism_gpu::mega_fused_batch::{
            MegaFusedBatchGpu, StructureInput, PackedBatch, MegaFusedConfig,
        };
        use prism_gpu::global_context::GlobalGpuContext;
        use std::collections::HashMap;
        use std::time::Instant;

        let total_start = Instant::now();
        let n_structures = structures.len();

        if n_structures == 0 {
            return Ok(Vec::new());
        }

        // CHUNKING: Process in batches of MAX_CHUNK_SIZE to avoid GPU memory overflow
        // 220 structures with 1.4M atoms is too large for a single kernel launch
        const MAX_CHUNK_SIZE: usize = 32;
        let n_chunks = (n_structures + MAX_CHUNK_SIZE - 1) / MAX_CHUNK_SIZE;
        log::info!("MEGA-BATCH GPU: Processing {} structures in {} chunks of {} max",
                   n_structures, n_chunks, MAX_CHUNK_SIZE);

        // 1. Convert all structures to StructureInput format
        let convert_start = Instant::now();
        let mut inputs: Vec<StructureInput> = Vec::with_capacity(n_structures);

        for structure in structures {
            let id = structure.title.clone();
            let n_residues = structure.residues.len();

            // Flatten atoms to [x0, y0, z0, x1, y1, z1, ...]
            let atoms: Vec<f32> = structure.atoms.iter()
                .flat_map(|a| [a.coord[0] as f32, a.coord[1] as f32, a.coord[2] as f32])
                .collect();

            // Build residue→atom map for O(1) lookups
            let mut residue_atom_map: HashMap<(i32, char), Vec<usize>> = HashMap::new();
            for (atom_idx, atom) in structure.atoms.iter().enumerate() {
                residue_atom_map
                    .entry((atom.residue_seq, atom.chain_id))
                    .or_insert_with(Vec::new)
                    .push(atom_idx);
            }

            // CA atom indices for each residue
            let ca_indices: Vec<i32> = structure.residues.iter()
                .map(|res| {
                    structure.atoms.iter().position(|a| {
                        a.residue_seq == res.seq_number
                            && a.chain_id == res.chain_id
                            && a.name == "CA"
                    })
                    .map(|i| i as i32)
                    .unwrap_or(-1)
                })
                .collect();

            // Per-residue features
            let conservation: Vec<f32> = structure.residues.iter()
                .map(|r| r.conservation_score as f32)
                .collect();

            let mut bfactor: Vec<f32> = Vec::with_capacity(n_residues);
            let mut burial: Vec<f32> = Vec::with_capacity(n_residues);

            for res in &structure.residues {
                if let Some(res_atom_indices) = residue_atom_map.get(&(res.seq_number, res.chain_id)) {
                    if res_atom_indices.is_empty() {
                        bfactor.push(0.5);
                        burial.push(0.5);
                    } else {
                        let avg_bfactor: f64 = res_atom_indices.iter()
                            .map(|&i| structure.atoms[i].b_factor)
                            .sum::<f64>() / res_atom_indices.len() as f64;
                        bfactor.push((avg_bfactor / 100.0).clamp(0.0, 1.0) as f32);

                        let avg_sasa: f64 = res_atom_indices.iter()
                            .map(|&i| structure.atoms[i].sasa)
                            .sum::<f64>() / res_atom_indices.len() as f64;
                        burial.push((1.0 - (avg_sasa / 150.0).clamp(0.0, 1.0)) as f32);
                    }
                } else {
                    bfactor.push(0.5);
                    burial.push(0.5);
                }
            }

            inputs.push(StructureInput {
                id,
                atoms,
                ca_indices,
                conservation,
                bfactor,
                burial,
            });
        }
        log::debug!("Structure conversion: {:?}", convert_start.elapsed());

        // 2. Get batch kernel from GlobalGpuContext (once)
        let global_gpu = GlobalGpuContext::try_get()
            .map_err(|e| anyhow::anyhow!("Batch GPU requires GlobalGpuContext: {}", e))?;

        let ptx_dir = std::env::var("PRISM_PTX_DIR").unwrap_or_else(|_| "target/ptx".to_string());
        let mut batch_gpu = MegaFusedBatchGpu::new(global_gpu.context().device().clone(), std::path::Path::new(&ptx_dir))
            .map_err(|e| anyhow::anyhow!("Failed to load batch kernel: {}", e))?;

        let config = MegaFusedConfig::screening();

        // 3. Process structures in chunks to avoid GPU memory overflow
        use prism_gpu::mega_fused_batch::BatchStructureOutput;
        let mut all_chunk_outputs: Vec<BatchStructureOutput> = Vec::with_capacity(n_structures);
        let mut total_kernel_time_us = 0u64;

        for (chunk_idx, chunk_inputs) in inputs.chunks(MAX_CHUNK_SIZE).enumerate() {
            let chunk_start = Instant::now();

            // Pack this chunk
            let packed = PackedBatch::from_structures(chunk_inputs)
                .map_err(|e| anyhow::anyhow!("Failed to pack chunk {}: {}", chunk_idx, e))?;

            // Run kernel on this chunk
            let batch_output = batch_gpu.detect_pockets_batch(&packed, &config)
                .map_err(|e| anyhow::anyhow!("Chunk {} kernel failed: {}", chunk_idx, e))?;

            total_kernel_time_us += batch_output.kernel_time_us;

            // Collect outputs
            all_chunk_outputs.extend(batch_output.structures);

            log::info!("Chunk {}/{}: {} structures in {:?} ({}µs kernel)",
                chunk_idx + 1, n_chunks, chunk_inputs.len(),
                chunk_start.elapsed(), batch_output.kernel_time_us);

            // WSL2 dxg driver stability: small delay between chunks to prevent driver overload
            // This adds ~15 seconds total for 155 chunks but prevents hangs
            std::thread::sleep(std::time::Duration::from_millis(100));
        }

        log::info!("All chunks complete: {} structures, total kernel time {}µs",
            n_structures, total_kernel_time_us);

        // 4. Convert batch output to per-structure Pockets
        let convert_back_start = Instant::now();
        let mut results: Vec<(String, Vec<Pocket>)> = Vec::with_capacity(n_structures);

        for (struct_idx, struct_output) in all_chunk_outputs.iter().enumerate() {
            let structure = &structures[struct_idx];
            let n_residues = structure.residues.len();

            // Build residue→atom map for this structure
            let mut residue_atom_map: HashMap<(i32, char), Vec<usize>> = HashMap::new();
            for (atom_idx, atom) in structure.atoms.iter().enumerate() {
                residue_atom_map
                    .entry((atom.residue_seq, atom.chain_id))
                    .or_insert_with(Vec::new)
                    .push(atom_idx);
            }

            // KERNEL OUTPUTS CLUSTER IDs DIRECTLY via Union-Find Stage 7
            // Group residues by their pocket_assignment value (1, 2, 3, etc.)
            // Note: Mega-pocket prevention is handled in post-processing (MAX_BATCH_POCKET_RESIDUES=60)
            let mut pocket_id_to_residues: HashMap<i32, Vec<usize>> = HashMap::new();
            for (res_idx, &pocket_id) in struct_output.pocket_assignment.iter().enumerate() {
                if pocket_id > 0 && struct_output.consensus_scores[res_idx] > config.consensus_threshold {
                    pocket_id_to_residues
                        .entry(pocket_id)
                        .or_insert_with(Vec::new)
                        .push(res_idx);
                }
            }

            // Convert each pocket cluster to a Pocket struct
            // MEGA-POCKET PREVENTION: Split clusters with >60 residues
            const MAX_BATCH_POCKET_RESIDUES: usize = 60;

            let mut pockets: Vec<Pocket> = Vec::new();
            for (_, mut residue_indices) in pocket_id_to_residues.into_iter() {
                if residue_indices.is_empty() {
                    continue;
                }

                // If cluster is too large, take only the highest-scoring residues
                if residue_indices.len() > MAX_BATCH_POCKET_RESIDUES {
                    // Sort by consensus score and take top MAX_BATCH_POCKET_RESIDUES
                    residue_indices.sort_by(|&a, &b| {
                        struct_output.consensus_scores[b]
                            .partial_cmp(&struct_output.consensus_scores[a])
                            .unwrap_or(std::cmp::Ordering::Equal)
                    });
                    residue_indices.truncate(MAX_BATCH_POCKET_RESIDUES);
                }

                let mut atom_indices: Vec<usize> = Vec::new();
                let mut centroid = [0.0f64, 0.0, 0.0];
                let mut total_hydro = 0.0;
                let mut total_depth = 0.0;
                let mut total_sasa = 0.0;
                let mut total_flex = 0.0;
                let mut total_cons = 0.0;
                let mut donors = 0usize;
                let mut acceptors = 0usize;

                for &res_idx in &residue_indices {
                    let res = &structure.residues[res_idx];
                    if let Some(res_atom_indices) = residue_atom_map.get(&(res.seq_number, res.chain_id)) {
                        for &atom_idx in res_atom_indices {
                            let atom = &structure.atoms[atom_idx];
                            atom_indices.push(atom_idx);
                            centroid[0] += atom.coord[0];
                            centroid[1] += atom.coord[1];
                            centroid[2] += atom.coord[2];
                            total_hydro += atom.hydrophobicity;
                            total_depth += atom.depth;
                            total_sasa += atom.sasa;
                            total_flex += atom.b_factor;
                            donors += usize::from(atom.is_hbond_donor());
                            acceptors += usize::from(atom.is_hbond_acceptor());
                        }
                    }
                    total_cons += structure.residues[res_idx].conservation_score;
                }

                if atom_indices.is_empty() {
                    continue;
                }

                let count = atom_indices.len() as f64;
                let residue_count = residue_indices.len();
                centroid[0] /= count;
                centroid[1] /= count;
                centroid[2] /= count;

                // Simplified volume (bounding box for speed)
                let volume = pocket::geometry::bounding_box_volume(structure, &atom_indices);
                let enc = pocket::geometry::enclosure_ratio(structure, &atom_indices);

                let avg_consensus = residue_indices.iter()
                    .map(|&i| struct_output.consensus_scores[i])
                    .sum::<f32>() / residue_indices.len() as f32;
                let avg_confidence = residue_indices.iter()
                    .map(|&i| struct_output.confidence[i] as f32)
                    .sum::<f32>() / residue_indices.len() as f32;
                let avg_centrality = residue_indices.iter()
                    .map(|&i| struct_output.centrality[i])
                    .sum::<f32>() / residue_indices.len() as f32;

                let drugg_total = (avg_consensus as f64 * 0.4 + avg_confidence as f64 / 2.0 * 0.3 + avg_centrality as f64 * 0.3).clamp(0.0, 1.0);
                let classification = if drugg_total >= 0.7 {
                    scoring::DrugabilityClass::HighlyDruggable
                } else if drugg_total >= 0.5 {
                    scoring::DrugabilityClass::Druggable
                } else if drugg_total >= 0.3 {
                    scoring::DrugabilityClass::DifficultTarget
                } else {
                    scoring::DrugabilityClass::Undruggable
                };

                let pocket = Pocket {
                    atom_indices,
                    residue_indices,
                    centroid,
                    volume,
                    enclosure_ratio: enc,
                    mean_hydrophobicity: total_hydro / count,
                    mean_sasa: total_sasa / count,
                    mean_depth: total_depth / count,
                    mean_flexibility: total_flex / count,
                    mean_conservation: total_cons / residue_count as f64,
                    persistence_score: avg_centrality as f64,
                    hbond_donors: donors,
                    hbond_acceptors: acceptors,
                    druggability_score: DruggabilityScore {
                        total: drugg_total,
                        classification,
                        components: scoring::Components {
                            volume: volume / 1000.0,
                            hydro: total_hydro / count,
                            enclosure: enc,
                            depth: (total_depth / count).clamp(0.0, 1.0),
                            hbond: (donors + acceptors) as f64 / count.max(1.0),
                            flex: (total_flex / count / 100.0).clamp(0.0, 1.0),
                            cons: total_cons / residue_count as f64,
                            topo: avg_centrality as f64,
                        },
                    },
                    boundary_atoms: Vec::new(),
                    mean_electrostatic: 0.0,
                    gnn_embedding: Vec::new(),
                    gnn_druggability: 0.0,
                };

                if pocket.volume >= 50.0 && pocket.atom_indices.len() >= 5 {
                    pockets.push(pocket);
                }
            }

            // Sort by druggability
            pockets.sort_by(|a, b| b.druggability_score.total.partial_cmp(&a.druggability_score.total).unwrap_or(std::cmp::Ordering::Equal));
            pockets.truncate(20);

            results.push((struct_output.id.clone(), pockets));
        }
        log::debug!("Result conversion: {:?}", convert_back_start.elapsed());

        let (allocs, reuses) = batch_gpu.buffer_pool_stats();
        log::info!(
            "MEGA-BATCH COMPLETE: {} structures in {:?} (buffer allocs: {}, reuses: {})",
            n_structures, total_start.elapsed(), allocs, reuses
        );

        Ok(results)
    }

    /// MEGA-BATCH WITH GROUND TRUTH VALIDATION (v2.0)
    /// Runs GPU-fused pocket detection AND computes AUC-ROC, AUPRC, MCC, F1 on GPU
    #[cfg(feature = "cuda")]
    pub fn predict_batch_with_ground_truth(
        structures: &[ProteinStructure],
        ground_truth: &std::collections::HashMap<String, Vec<usize>>,
    ) -> Result<BatchValidationResult> {
        use prism_gpu::mega_fused_batch::{
            MegaFusedBatchGpu, StructureInput, StructureInputWithGT, PackedBatchWithGT,
            MegaFusedConfig, BatchMetricsOutput, AggregateMetrics,
        };
        use prism_gpu::global_context::GlobalGpuContext;
        use std::collections::HashMap;
        use std::time::Instant;

        let total_start = Instant::now();
        let n_structures = structures.len();

        if n_structures == 0 {
            return Ok(BatchValidationResult {
                pockets: Vec::new(),
                per_structure_metrics: Vec::new(),
                aggregate: AggregateMetrics::default(),
                kernel_time_us: 0,
            });
        }

        log::info!("═══════════════════════════════════════════════════════════════════");
        log::info!("  GPU-FUSED VALIDATION MODE (v2.0)");
        log::info!("  Structures: {}", n_structures);
        log::info!("  Ground truth entries: {}", ground_truth.len());
        log::info!("═══════════════════════════════════════════════════════════════════");

        // 1. Convert structures to StructureInputWithGT
        let mut inputs_with_gt: Vec<StructureInputWithGT> = Vec::with_capacity(n_structures);

        for structure in structures {
            // Use pdb_id if available, otherwise extract from title/filename
            let pdb_id = structure.pdb_id.clone()
                .map(|id| id.to_lowercase())
                .unwrap_or_else(|| {
                    // Fallback: try to extract 4-letter PDB ID from title
                    structure.title.split_whitespace()
                        .find(|s| s.len() == 4 && s.chars().all(|c| c.is_alphanumeric()))
                        .map(|s| s.to_lowercase())
                        .unwrap_or_else(|| structure.title.split_whitespace().next().unwrap_or("unknown").to_lowercase())
                });
            let n_residues = structure.residues.len();
            log::debug!("Structure PDB ID: {} ({} residues)", pdb_id, n_residues);

            // Flatten atoms
            let atoms: Vec<f32> = structure.atoms.iter()
                .flat_map(|a| [a.coord[0] as f32, a.coord[1] as f32, a.coord[2] as f32])
                .collect();

            // Build residue→atom map
            let mut residue_atom_map: HashMap<(i32, char), Vec<usize>> = HashMap::new();
            for (atom_idx, atom) in structure.atoms.iter().enumerate() {
                residue_atom_map
                    .entry((atom.residue_seq, atom.chain_id))
                    .or_insert_with(Vec::new)
                    .push(atom_idx);
            }

            // CA indices
            let ca_indices: Vec<i32> = structure.residues.iter()
                .map(|res| {
                    structure.atoms.iter().position(|a| {
                        a.residue_seq == res.seq_number
                            && a.chain_id == res.chain_id
                            && a.name == "CA"
                    })
                    .map(|i| i as i32)
                    .unwrap_or(-1)
                })
                .collect();

            // Per-residue features
            let conservation: Vec<f32> = structure.residues.iter()
                .map(|r| r.conservation_score as f32)
                .collect();

            let mut bfactor: Vec<f32> = Vec::with_capacity(n_residues);
            let mut burial: Vec<f32> = Vec::with_capacity(n_residues);

            for res in &structure.residues {
                if let Some(res_atom_indices) = residue_atom_map.get(&(res.seq_number, res.chain_id)) {
                    if res_atom_indices.is_empty() {
                        bfactor.push(0.5);
                        burial.push(0.5);
                    } else {
                        let avg_bfactor: f64 = res_atom_indices.iter()
                            .map(|&i| structure.atoms[i].b_factor)
                            .sum::<f64>() / res_atom_indices.len() as f64;
                        bfactor.push((avg_bfactor / 100.0).clamp(0.0, 1.0) as f32);

                        let avg_sasa: f64 = res_atom_indices.iter()
                            .map(|&i| structure.atoms[i].sasa)
                            .sum::<f64>() / res_atom_indices.len() as f64;
                        burial.push((1.0 - (avg_sasa / 150.0).clamp(0.0, 1.0)) as f32);
                    }
                } else {
                    bfactor.push(0.5);
                    burial.push(0.5);
                }
            }

            // Build ground truth mask (convert PDB sequence numbers to 0-indexed residue positions)
            let gt_residue_seq_nums = ground_truth.get(&pdb_id);

            // Create a mapping from PDB residue sequence number to 0-indexed position
            let seq_num_to_idx: HashMap<i32, usize> = structure.residues.iter()
                .enumerate()
                .map(|(idx, res)| (res.seq_number, idx))
                .collect();

            // Convert GT sequence numbers to 0-indexed positions
            let gt_indices: std::collections::HashSet<usize> = gt_residue_seq_nums
                .map(|seq_nums| {
                    seq_nums.iter()
                        .filter_map(|&seq_num| seq_num_to_idx.get(&(seq_num as i32)).copied())
                        .collect()
                })
                .unwrap_or_default();

            let gt_pocket_mask: Vec<u8> = (0..n_residues)
                .map(|i| if gt_indices.contains(&i) { 1 } else { 0 })
                .collect();

            let gt_count = gt_indices.len();
            if gt_count > 0 {
                log::debug!("Structure {}: {} GT residues out of {} (mapped from {} sequence numbers)",
                    pdb_id, gt_count, n_residues,
                    gt_residue_seq_nums.map(|v| v.len()).unwrap_or(0));
            } else if gt_residue_seq_nums.is_some() {
                log::warn!("Structure {}: GT has {} sequence numbers but none mapped to residue positions",
                    pdb_id, gt_residue_seq_nums.map(|v| v.len()).unwrap_or(0));
            }

            let base = StructureInput {
                id: pdb_id.clone(),
                atoms,
                ca_indices,
                conservation,
                bfactor,
                burial,
            };

            inputs_with_gt.push(StructureInputWithGT {
                base,
                gt_pocket_mask,
            });
        }

        // 2. Get batch kernel from GlobalGpuContext
        let global_gpu = GlobalGpuContext::try_get()
            .map_err(|e| anyhow::anyhow!("Batch GPU requires GlobalGpuContext: {}", e))?;

        let ptx_dir = std::env::var("PRISM_PTX_DIR").unwrap_or_else(|_| "target/ptx".to_string());
        let mut batch_gpu = MegaFusedBatchGpu::new(global_gpu.context().device().clone(), std::path::Path::new(&ptx_dir))
            .map_err(|e| anyhow::anyhow!("Failed to load batch kernel: {}", e))?;

        if !batch_gpu.is_metrics_available() {
            anyhow::bail!("v2.0 metrics kernel not loaded - ensure mega_fused_batch.ptx contains mega_fused_pocket_detection_batch_with_metrics");
        }

        let config = MegaFusedConfig::screening();

        // 3. Process in chunks with ground truth
        const MAX_CHUNK_SIZE: usize = 32;
        let n_chunks = (n_structures + MAX_CHUNK_SIZE - 1) / MAX_CHUNK_SIZE;

        let mut all_metrics: Vec<BatchMetricsOutput> = Vec::with_capacity(n_structures);
        let mut total_kernel_time_us = 0u64;

        for (chunk_idx, chunk_inputs) in inputs_with_gt.chunks(MAX_CHUNK_SIZE).enumerate() {
            let chunk_start = Instant::now();

            // Pack with ground truth
            let packed = PackedBatchWithGT::from_structures_with_gt(chunk_inputs)
                .map_err(|e| anyhow::anyhow!("Failed to pack chunk {}: {}", chunk_idx, e))?;

            // Run v2.0 metrics kernel
            let output = batch_gpu.detect_pockets_batch_with_metrics(&packed, &config)
                .map_err(|e| anyhow::anyhow!("Chunk {} metrics kernel failed: {}", chunk_idx, e))?;

            total_kernel_time_us += output.kernel_time_us;
            all_metrics.extend(output.metrics);

            log::info!("Chunk {}/{}: {} structures in {:?} | F1={:.4} MCC={:.4}",
                chunk_idx + 1, n_chunks, chunk_inputs.len(),
                chunk_start.elapsed(), output.aggregate.mean_f1, output.aggregate.mean_mcc);

            std::thread::sleep(std::time::Duration::from_millis(100));
        }

        // 4. Compute final aggregate metrics
        let n = all_metrics.len() as f32;
        let aggregate = if n > 0.0 {
            AggregateMetrics {
                mean_f1: all_metrics.iter().map(|m| m.f1_score).sum::<f32>() / n,
                mean_mcc: all_metrics.iter().map(|m| m.mcc).sum::<f32>() / n,
                mean_auc_roc: all_metrics.iter().map(|m| m.auc_roc).sum::<f32>() / n,
                mean_auprc: all_metrics.iter().map(|m| m.auprc).sum::<f32>() / n,
                mean_precision: all_metrics.iter().map(|m| m.precision).sum::<f32>() / n,
                mean_recall: all_metrics.iter().map(|m| m.recall).sum::<f32>() / n,
            }
        } else {
            AggregateMetrics::default()
        };

        log::info!("═══════════════════════════════════════════════════════════════════");
        log::info!("  GPU-FUSED VALIDATION COMPLETE");
        log::info!("  Structures: {}", n_structures);
        log::info!("  Total kernel time: {}µs", total_kernel_time_us);
        log::info!("  ────────────────────────────────────────────────────────────────");
        log::info!("  MEAN F1:       {:.4}", aggregate.mean_f1);
        log::info!("  MEAN MCC:      {:.4}", aggregate.mean_mcc);
        log::info!("  MEAN AUC-ROC:  {:.4}", aggregate.mean_auc_roc);
        log::info!("  MEAN AUPRC:    {:.4}", aggregate.mean_auprc);
        log::info!("  MEAN PRECISION:{:.4}", aggregate.mean_precision);
        log::info!("  MEAN RECALL:   {:.4}", aggregate.mean_recall);
        log::info!("═══════════════════════════════════════════════════════════════════");

        Ok(BatchValidationResult {
            pockets: Vec::new(), // TODO: convert batch output to pockets if needed
            per_structure_metrics: all_metrics,
            aggregate,
            kernel_time_us: total_kernel_time_us,
        })
    }
}

/// Result of batch validation with ground truth
#[cfg(feature = "cuda")]
pub struct BatchValidationResult {
    pub pockets: Vec<(String, Vec<Pocket>)>,
    pub per_structure_metrics: Vec<prism_gpu::mega_fused_batch::BatchMetricsOutput>,
    pub aggregate: prism_gpu::mega_fused_batch::AggregateMetrics,
    pub kernel_time_us: u64,
}

/// Error types for PRISM-LBS
#[derive(Debug, thiserror::Error)]
pub enum LbsError {
    #[error("IO error: {0}")]
    Io(#[from] std::io::Error),

    #[error("PDB parsing error: {0}")]
    PdbParse(String),

    #[error("Graph construction error: {0}")]
    GraphConstruction(String),

    #[error("Phase execution error: {0}")]
    PhaseExecution(String),

    #[error("GPU error: {0}")]
    Gpu(String),

    #[error("Configuration error: {0}")]
    Config(String),

    #[error("Training error: {0}")]
    Training(String),
}

impl From<anyhow::Error> for LbsError {
    fn from(err: anyhow::Error) -> Self {
        LbsError::Training(err.to_string())
    }
}

/// Merge adjacent pockets with configurable sequential range.
///
/// Kinase ATP sites, substrate channels, and GPCR sites often get split into
/// multiple pockets. This function iteratively merges pockets that are:
/// - Within `merge_distance` Angstroms (centroid-to-centroid)
/// - Share at least `min_shared_residues` residues
/// - Have residues within `seq_range` in sequence number
///
/// Uses iterative merging until convergence to handle chain merging (A→B→C).
fn merge_adjacent_pockets_with_seq(
    pockets: Vec<Pocket>,
    merge_distance: f64,
    min_shared_residues: usize,
    seq_range: i32,
) -> Vec<Pocket> {
    use std::collections::HashSet;

    if pockets.len() < 2 {
        return pockets;
    }

    let mut current_pockets = pockets;
    let max_iterations = 5;  // Prevent infinite loops

    for iteration in 0..max_iterations {
        let start_count = current_pockets.len();

        let mut merged: Vec<Pocket> = Vec::new();
        let mut used = vec![false; current_pockets.len()];

        for i in 0..current_pockets.len() {
            if used[i] {
                continue;
            }

            let mut current = current_pockets[i].clone();
            used[i] = true;

            // Try to merge with other pockets
            for j in (i + 1)..current_pockets.len() {
                if used[j] {
                    continue;
                }

                // Check centroid distance
                let dist = centroid_distance(&current.centroid, &current_pockets[j].centroid);

                // Check shared residues
                let current_res: HashSet<_> = current.residue_indices.iter().collect();
                let other_res: HashSet<_> = current_pockets[j].residue_indices.iter().collect();
                let shared = current_res.intersection(&other_res).count();

                // Check for sequential neighbor residues (within seq_range in sequence)
                let has_sequential_neighbor = current.residue_indices.iter().any(|&r1| {
                    current_pockets[j].residue_indices.iter().any(|&r2| {
                        let diff = (r1 as i32 - r2 as i32).abs();
                        diff > 0 && diff <= seq_range
                    })
                });

                // Max pocket size limit (prevent mega-pockets)
                let combined_residues = current.residue_indices.len() + current_pockets[j].residue_indices.len() - shared;
                const MAX_POCKET_RESIDUES: usize = 80;  // Allow larger pockets (max_pockets=4 controls count)

                // Merge if: close distance AND (sharing residues OR sequential neighbors)
                // Also enforce max size limit
                let should_merge = dist < merge_distance
                    && (shared >= min_shared_residues || has_sequential_neighbor)
                    && combined_residues <= MAX_POCKET_RESIDUES;

                if should_merge {
                    current = merge_two_pockets(current, current_pockets[j].clone());
                    used[j] = true;
                }
            }

            merged.push(current);
        }

        let end_count = merged.len();
        current_pockets = merged;

        // Converged - no more merges possible
        if end_count == start_count {
            log::debug!(
                "Pocket merging (dist={}, seq={}) converged after {} iterations: {} pockets",
                merge_distance, seq_range, iteration + 1, end_count
            );
            break;
        }
    }

    current_pockets
}

/// Calculate Euclidean distance between two centroids
fn centroid_distance(a: &[f64; 3], b: &[f64; 3]) -> f64 {
    ((a[0] - b[0]).powi(2) + (a[1] - b[1]).powi(2) + (a[2] - b[2]).powi(2)).sqrt()
}

/// Merge two pockets into one
fn merge_two_pockets(mut a: Pocket, b: Pocket) -> Pocket {
    use std::collections::HashSet;

    // Calculate weights before moving values
    let a_atom_count = a.atom_indices.len();
    let b_atom_count = b.atom_indices.len();
    let total_atoms = (a_atom_count + b_atom_count) as f64;
    let a_weight = a_atom_count as f64 / total_atoms;
    let b_weight = b_atom_count as f64 / total_atoms;

    // Merge atom indices (deduplicate)
    let mut atom_set: HashSet<_> = a.atom_indices.into_iter().collect();
    atom_set.extend(b.atom_indices);
    a.atom_indices = atom_set.into_iter().collect();

    // Merge residue indices (deduplicate)
    let mut res_set: HashSet<_> = a.residue_indices.into_iter().collect();
    res_set.extend(b.residue_indices);
    a.residue_indices = res_set.into_iter().collect();

    // Merge boundary atoms
    let mut bound_set: HashSet<_> = a.boundary_atoms.into_iter().collect();
    bound_set.extend(b.boundary_atoms);
    a.boundary_atoms = bound_set.into_iter().collect();

    // Weighted average for centroid
    a.centroid = [
        a.centroid[0] * a_weight + b.centroid[0] * b_weight,
        a.centroid[1] * a_weight + b.centroid[1] * b_weight,
        a.centroid[2] * a_weight + b.centroid[2] * b_weight,
    ];

    // Combine volumes (approximate - may overlap)
    a.volume += b.volume * 0.8; // Assume 20% overlap

    // Average other properties
    a.enclosure_ratio = (a.enclosure_ratio + b.enclosure_ratio) / 2.0;
    a.mean_hydrophobicity = (a.mean_hydrophobicity + b.mean_hydrophobicity) / 2.0;
    a.mean_sasa = (a.mean_sasa + b.mean_sasa) / 2.0;
    a.mean_depth = a.mean_depth.max(b.mean_depth);
    a.mean_flexibility = (a.mean_flexibility + b.mean_flexibility) / 2.0;
    a.mean_conservation = (a.mean_conservation + b.mean_conservation) / 2.0;
    a.persistence_score = a.persistence_score.max(b.persistence_score);
    a.hbond_donors += b.hbond_donors;
    a.hbond_acceptors += b.hbond_acceptors;
    a.mean_electrostatic = (a.mean_electrostatic + b.mean_electrostatic) / 2.0;

    // Keep the better GNN score
    if b.gnn_druggability > a.gnn_druggability {
        a.gnn_druggability = b.gnn_druggability;
        a.gnn_embedding = b.gnn_embedding;
    }

    a
}

/// Expand pocket to include residues near existing pocket atoms.
///
/// This works better for elongated/multi-center binding sites by expanding
/// from each pocket atom rather than just the centroid.
///
/// Parameters:
/// - `expansion_radius`: Maximum distance (Å) to expand from pocket atoms
/// - `max_residues`: Cap on total residues to prevent mega-pockets
fn expand_pocket_residues(pocket: &mut Pocket, atoms: &[Atom], expansion_radius: f64, max_residues: usize) {
    use std::collections::HashSet;

    // MEGA-POCKET PREVENTION: Trim oversized pockets BEFORE expansion
    // This fixes issue where initial Voronoi detection creates mega-pockets (e.g., 290 residues)
    // that were just skipped by the old code path
    if pocket.residue_indices.len() > max_residues {
        log::debug!(
            "Trimming mega-pocket from {} to {} residues (using distance to centroid)",
            pocket.residue_indices.len(),
            max_residues
        );

        // Calculate distance to centroid for each residue and keep closest ones
        let centroid = pocket.centroid;
        let mut residue_distances: Vec<(usize, f64)> = pocket.residue_indices.iter()
            .map(|&res_idx| {
                // Find minimum distance from any atom in this residue to centroid
                let min_dist = atoms.iter()
                    .filter(|a| a.residue_seq as usize == res_idx)
                    .map(|a| {
                        let dx = a.coord[0] - centroid[0];
                        let dy = a.coord[1] - centroid[1];
                        let dz = a.coord[2] - centroid[2];
                        (dx * dx + dy * dy + dz * dz).sqrt()
                    })
                    .fold(f64::MAX, |a, b| a.min(b));
                (res_idx, min_dist)
            })
            .collect();

        // Sort by distance (closest first) and keep top max_residues
        residue_distances.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap_or(std::cmp::Ordering::Equal));
        pocket.residue_indices = residue_distances.into_iter()
            .take(max_residues)
            .map(|(idx, _)| idx)
            .collect();
        pocket.residue_indices.sort();

        // Recalculate atom_indices for the trimmed pocket
        let residue_set: HashSet<usize> = pocket.residue_indices.iter().copied().collect();
        pocket.atom_indices.retain(|&atom_idx| {
            atoms.get(atom_idx)
                .map(|a| residue_set.contains(&(a.residue_seq as usize)))
                .unwrap_or(false)
        });
    }

    let current_residues: HashSet<usize> = pocket.residue_indices.iter().copied().collect();
    let mut all_residues = current_residues.clone();
    let initial_count = all_residues.len();

    // Skip expansion if pocket is already at max size (now reached via trimming or natural size)
    if initial_count >= max_residues {
        return;
    }

    // Build set of current pocket atom coordinates
    let pocket_atom_coords: Vec<[f64; 3]> = atoms
        .iter()
        .filter(|a| current_residues.contains(&(a.residue_seq as usize)))
        .map(|a| a.coord)
        .collect();

    // Collect candidate residues with their distances
    let mut candidates: Vec<(usize, f64)> = Vec::new();

    for atom in atoms {
        let res_idx = atom.residue_seq as usize;
        if all_residues.contains(&res_idx) {
            continue;
        }

        // Check distance to nearest pocket atom
        let mut min_dist = f64::MAX;
        for pocket_coord in &pocket_atom_coords {
            let dx = atom.coord[0] - pocket_coord[0];
            let dy = atom.coord[1] - pocket_coord[1];
            let dz = atom.coord[2] - pocket_coord[2];
            let dist = (dx * dx + dy * dy + dz * dz).sqrt();
            if dist < min_dist {
                min_dist = dist;
            }
        }

        if min_dist < expansion_radius {
            // Track best (closest) distance for each residue
            if let Some(existing) = candidates.iter_mut().find(|(r, _)| *r == res_idx) {
                if min_dist < existing.1 {
                    existing.1 = min_dist;
                }
            } else {
                candidates.push((res_idx, min_dist));
            }
        }
    }

    // Sort by distance (closest first) and add up to cap
    candidates.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap());
    let slots_available = max_residues.saturating_sub(all_residues.len());
    for (res_idx, _) in candidates.into_iter().take(slots_available) {
        all_residues.insert(res_idx);
    }

    pocket.residue_indices = all_residues.into_iter().collect();
    pocket.residue_indices.sort();

    let added = pocket.residue_indices.len() - initial_count;
    if added > 0 {
        log::debug!(
            "Pocket expansion: added {} residues (now {}, max {})",
            added,
            pocket.residue_indices.len(),
            max_residues
        );
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_default_config() {
        let config = LbsConfig::default();
        assert!(config.use_gpu);
        assert_eq!(config.top_n, 20);  // Updated from 10 to 20
    }
}
